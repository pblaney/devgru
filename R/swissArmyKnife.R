######################################################################################
#                         ___   ___        ____   ____                               #
#                          | | |     |   /  |     |   | |   |                        #
# }}}}------->>>           + | |-+-  |  +   | +-  |-+-  |   |         <<<-------{{{{ #
#                          | | |     | /    |   | |  \  |   |                        #
#                         ---   ---   /      ---      \  ---                         #
######################################################################################
# ▒▓▓▒▒▒▒▒▒▒▒▓▓▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▓▒▒▒▒▒▒▒▒▒▒▒▒
# ▒▒▒▒▒░▒▒▒▒▓▓▒▒▒▒░░░░░░░░░░░░░░░░░░▒▒░░░░░░░░▒░░░░░░░▒░░░░░░░░░░░░░░░░░░▒▒▒▓▓▓▒▒▒▒▒▒▒
# ▒▒▒▒▒░░░░▒▒▒▒▒░░░░░░░░░░░░░░░░░░░░░▒▒▒▒▒▒▒▒▒▒▒▒▒▒░░░░░░░░░░░▒▒▒▒▒░░░░░░░░▒▒▒▓▓▒▒▒▒▒▒
# ▒▒▒▒▒░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░▒▓▓▓▓▓▓▓▒▒▒▒▒░░░░░░░░░▒▒▒▒▓▓▓▓▒░░░░░░░▒▒▓▓▓▒▒▒▓▓
# ▒▒▒▒▒░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░▒▒▒▓▒▓▓▓▓▓▓▓▓▒▒▒░░░░░░▒▓▓▓▒▒▒▓▓▓▒░░░░░░░▒▒▓▓▓▒▒▒▒
# ▒▒▒▒▒▒░░░░░░░▒▒░░░░░░░░░░░░░░░▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░░░░░▒▓▒░░░░▒▒▓▓▒░░░░░░░░▒▒▒▒▒▒▒
# ▒▒▒▒▒▒░░░░░▒▒▒▒▓▒░░░░░░░░░░░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░▒▒▒░░░░░░▒▓▓▒░░░░░░░░░▒▒▒▒▒▒
# ▒▒▒▒▒░░░░░░▒▓▓▓▓▓▒░░░░░▒▒▒▒░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░░░░░░░░░░░▒▓▓▒░░░░░░░░░▒▒▒▒▒▒
# ▒▒▒▒▒░░░░░░▒▓▓▓▓▓▓░░░░░▒▒▓▓▒▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░░░░░░░▒▒▒▒▓▒░░░░░░░░░░▒▒▒▒▒░
# ▒▒▒▒▒▒▒░░░░░░▒▓▓▓▒▒░░░░░░▒▒▒▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░░▒▒▒▒▓▓▓▓▓▒▒░░░░░░░░░▒▒▒▒▒░
# ▒▒▒▒▒▒▒░░░░░░▒▓▓▓▓▓▒░░░░░░░░░░░▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░░░░░▒▓▓▓▓▓▓▒▒░░░░░░░░░░░▒▒▒▒▒░
# ▒▒▒▒▒▒▒░░░░▒▒▓▓▓▓▓▓▓▒░░░░░░░░░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒▒▒░░░░░░▒▒▓▓▓▓▒▒░░░░░░░░░░░░▒▒▓▒▒▒▒
# ▒▒▒▒▒▒▒░░░▒▒▒▓▓▓▓▓▓▓▓▓▒░░░░░░░░▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░▒▒▓▓▓▓▒▒░░░░░░░░░░▒▒▒▒▓▒▒▒▒
# ▒▒▒▒▒▒▒░░░░░░░░░░▒▒▓▓▓▓▓▒▒▒▒▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▓▒░░░░░░░░░▒▒▓▓▓▒▒░░░░░░░░░▒▒▓▓▓▓▓▒▒▒
# ▒▒▒▒▒▒▒░░░░░░░░░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░░░░░░▒▓▓▓▒░░░░░░░░░░░▒▒▓▓▓▓▒▒
# ▒▒▒▒▒▒▒▒░░░░░░░░░░░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░░░░░░▒▒▓▓▓▒░░░░░░░░░░░░▒▓▓█▒▒
# ▒▒▒▒▒▒▒▒░░░░░░░░░░░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░▒▒░░░░░░░░░░░▒▓▓▒░░░░░░░░░░░▒▓▓▓▒▒
# ▒▒▒▒▒▒▒▒░░░░░░░░░░░░▒▒▒▒░▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒▒▒░░░░░░░░░░░▒▒▓▒▒░░░░░░░░░▒▓▓▓▒▒
# ▒▒▒▒▓▒▒▒░░░░░░░░░░░░░░░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒▒░░░░░░░░░░░░░▒▓▓▒▒░░░░░░░▒▓▓▓▒▒
# ▒▓▒▓▒▒▒▒▒▒▒▒░░░░░░░░░▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░░░░░░▒▓▓▒░░░░░░░▒▓▓▒▒▒▒
# ▒▒▒▒▒▒▒▒▒▓▓▓▓▒░░░░░░▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░░░░░░░░░▒▓▓▒▒░░░░░░▒▒▓▓▒▒
# ▒▒▒▒▓▒▒▒▒▓▓█▓▓▒▒░▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒▒▒▒▒▒▒▒▒▓▓▓▒▒░░░░░▒▒▓▓▒▒▒
# ▒▒▒▓▓▒▒░▒▒▒▓█▓▓▓▓▓▓██▓▓▓▓▓▓▓▓▓▓▒▒▒▒▒▒▒▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░░░░░▒▒▓▒▒▒
# ▒▒▒▒▓▒▒░░▒▒▓▓██████▓▓▓▒▒▒▒▒▒▒▒▒░░░░░░░░░▒▒▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░░░░░░▒▓▓▒▒▒
# ▒▒▒▒▓▒▒▒▒▒▒▓▓██▓▓▓▒▒░░░░░░░░░░░░░░░░▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░░▒▒▓▒▒▒
# ▒▒▒▒▓▒▒▒▒▒▓▓▓▓▓▒▒▒░░░░░░░░░░░░░░░░▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓█▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░░░░░▒▒▒▒▒▒
# ▓▓▒▒▓▓▓▒▒▒▒▒▒▒▒▒░░░░░░░░░░░░░░░░░░▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░░▒▒▒▒▓▒▒▒
# ▒▒▒▒▒▓▓▒▒▒▒▒░░▒░░░░░░░░░░░░░░░░░░░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░░░▒▓▒▓▓▒▒
# ▒▒▒▒▒▓▓▓▓▒▒▒░░░░░░░░░░░░░░░░░▒▒▒▒░░▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░▒▒▓▓▒▒
# ▒▒▒▒▒▓▒▒▒▓▒▒▒░░░░░░░░░░░░░░▒▒▓▓▓▓▓▒▒░░░▒▒▒▓▓▓▓▓▓▓▓▒▒▒░░░░░▒▒▒▓▓▓▓▓▓▓▓▓▓▓▒▒░░░▒▒▒▓▒▒▒
# ▓▒▒▒▓▓▓▒▒▓▒▒▒▒░░▒░░░░░░░░░░▒▒▒▓▓▓▓▓▓▒▒▒▒▒▒▒▒▓▓▓▓▓▓▓▓▒▒░░░░░░░░▒▒▓▓▓▓▓▓▓▒▒▓▒░░░▒▒▓▓▒▒
# ▓▒▒▒▓▓▒▒▓▓▒▒▒▒▒▒▒▒░░░░░░░░░░▒▒▒▒▒▓▓▓▓▓▓▓▓▓▒▓▓▓▓▓▓▓▓▒▒▒░░░░░░░░░░▒▒▓▓▓▓▓▓▒░░░░░▒▒▒▒▒▒
# ▓▒▒▒▓▓▒▒▓▓▓▒▒▒▒▒▒▒▒▒▒▒░░░░░▒▒▒▒▒▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░▒▒▒░░░▒▒▒▓▓▓▓▒▒░░░░▒▒▒▒▒▒
# ▓▒▒▒▓▓▓▒▓▓▒▒▒▒▓▒▒▒▒▒▒▒▒▒░░░▒▒▓▓▒▒▒▒▒▓▓▓▒▒▒▒▒▒▒▓▓▓▓▓▓▒░░░░░░▒▒▒░▒▒▒▒▒▓▓▓▓▓▓▒▒▒░▒▒▒▒▒▒
# ▓▒▒▒▒▓▓▓▓▓▓▓▒▒▓▒▒▒▒▒▒▒▒▒░░░▒░▒▒▒▒▒▒▒▒▒▒▒░░░░░░▒▒▒▓▒▒▒░░░░░░░░░▒▒▒▓▓▓▓▓▓▓▓▓▓▓▒▒▒▒▒▒▒▒
# ▒▓▒▒▒▓▓▓▓▒▒▓▓▓▓▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒░░▒▒░░░░░░░░░░░░░░░▒░▒▒▒▒▒▒▓▓▓▓▓▓▓▒▓▓▓▓▓▓▓▒▒▒▒▒
# ▒▒▒▒▒▓▓▓▓▓▓▓▓▓▓▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒░▒▒▒▒▒▒▒▒▒▒▒░░░░░▒░░░░░░░▒▒▒▒▓▓▓▓▓▒▒▒▒▒▒░▒▒▓▓▓▓▒▒▒▒▒
# ▒▒▒▒▒▒▒▓▓▓▓▓▒▒▒▓▒▓▓▓▓▓▓▒▒▒▓▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒░░░░░░▒▒▒░░░░▒▒▒▒▓▓▒▓▒▒▓▓▓▓▒▒▒▒▒▓▒▒▓▒▒▒▒▒▒
# ▓▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▓▓▓▒▓▓▓▓▒▒▒▓▓▓▓▓▓▒▒▒▒▓▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒
#                                                                                    #
# }}}}------->>>                                                      <<<-------{{{{ #

#' @import gUtils
#' @import GenomicRanges
#' @import GenomeInfoDb
#' @import data.table
#' @import VariantAnnotation
#' @import stringr
#' @import dplyr
#' @import ggplot2
#' @import scales
#' @import paletteer
#' @import patchwork
#' @import ggpubr
#' @import ggside
#' @import stats
#' @import crayon
#' @import cli
#' @import pio
#' @import DESeq2
#' @import fgsea
#' @import R.utils
#' @import fishHook

#' @importFrom pak pkg_install
#' @importFrom librarian shelf
#' @importFrom BSgenome.Hsapiens.UCSC.hg38 Hsapiens
#' @importFrom rtracklayer import
#' @importFrom readr read_delim
#' @importFrom S4Vectors mcols
#' @importFrom Biostrings toString
#' @importFrom doParallel registerDoParallel
#' @importFrom foreach foreach
#' @importFrom foreach `%dopar%`
#' @importFrom paint paint
#' @importFrom reshape2 melt
#' @importFrom purrr as_vector
#' @importFrom ggridges stat_density_ridges
#' @importFrom ggfittext geom_bar_text
#' @importFrom hms hms
#' @importFrom utils packageVersion
#' @importFrom fs path_package
#' @importFrom ggpie ggpie
#' @importFrom tibble column_to_rownames
#' @importFrom SummarizedExperiment colData
#' @importFrom DNAcopy CNA smooth.CNA segment
#' @importFrom ggrepel geom_text_repel
#' @importFrom tidyr drop_na
#' @importFrom BiocParallel MulticoreParam
#' @importFrom easypar run
#' @importFrom gtools mixedsort
#' @importFrom rpart rpart
#' @importFrom gGnome jJ
#' @importFrom grDevices colorRampPalette


# Appease R CMD CHECK misunderstanding of data.table/data.frame/ggplot2 syntax by declaring these 'global' variables
# Split these into multiple rows just for better aesthetics as there are many
x=DeletionRate=FractionCovered=InsertionRate=Mapped=MappedForwardFraction=MappedProperFraction=NULL
MappedReverseFraction=MedianCoverage=MedianInsertSize=Sample=alignment_group=fraction=med_reads=NULL
alignment_group=fraction=med_reads=median_count=tumor_normal=ALT=CALLER=REF=SAMPLE=total_indels=NULL
total_per_caller=total_snvs=gene_biotype=type=gene_name=AD_ALT_TUMOR=AD_TUMOR=AF_TUMOR=DP_TUMOR=NULL
FREQ_TUMOR=PM_TUMOR=TIR_TIER1_TUMOR=nearest_gene=gene_body_hg38=gene_id=condition=expr_mean=NULL
normalized_per_gene_mean_expr=filtered_vs_survived=group_means=rn=gene=log2_fc=neg_log10_p_adj=NULL
p_val_adj=point_label=rank_score=ES=seg.mean=tile_type=ID=arm=num.mark=query.id=subject.id=NULL
tile.id=Final_epgap=Non_telomeric_Loose_Ends=RMSE_of_Coverage_and_CN=Requested_epgap=NULL
Tier_1_Input_Junctions=Tier_1_Output_Junctions=Tier_2_Input_Junctions=Tier_2_Output_Junctions=NULL
Tier_3_Input_Junctions=Tier_3_Output_Junctions=Tumor_Normal_ID=cn=cnmle=copynumber=NULL
p_value_of_Pearson_r=p_value_of_Spearman_Rho=ploidy=purity=tier=verbose=NULL


# Set up the global default genome and number display
.onLoad <- function(libname, pkgname) {
  op <- options()
  op.devgru <- list(
    devgru.ref_genome = "hg38"
  )
  toset <- !(names(op.devgru) %in% names(op))
  if (any(toset)) options(op.devgru[toset])

  Sys.setenv(DEFAULT_BSGENOME = 'BSgenome.Hsapiens.UCSC.hg38::Hsapiens')
  Sys.setenv(DEFAULT_GENOME = 'BSgenome.Hsapiens.UCSC.hg38::Hsapiens')
  options(scipen = 999)

  invisible()
}

#
#
# }}}}------->>> Data for analysis and demos
#
#

#' DNAaseI hypersensitivity sites on hg38
#'
#' DNAaseI hypersensitivity sites in the H562 cell line from UCSC Table Browser
#' hg19 that has been lifted over to hg38 using `rtracklayer::liftOver()`
#'
#' @name example_dnase_hg38
#' @docType data
#' @keywords data
#' @format \code{GRanges}
NULL

#' DNAaseI hypersensitivity sites for KRAS on hg19 as GenomicRanges
#'
#' DNAaseI hypersensitivity sites in the H562 cell line from UCSC Table Browser
#' hg19, subset to the KRAS locus with 1000 bp flank.
#'
#' @name kras_dnase_demo_gr_hg19
#' @docType data
#' @keywords data
#' @format \code{GRanges}
NULL

#' DNAaseI hypersensitivity sites for KRAS on hg38 as GenomicRanges
#'
#' DNAaseI hypersensitivity sites in the H562 cell line from UCSC Table Browser
#' hg38 liftover, subset to the KRAS locus with 1000 bp flank.
#'
#' @name kras_dnase_demo_gr_hg38
#' @docType data
#' @keywords data
#' @format \code{GRanges}
NULL

#' DNAaseI hypersensitivity sites for BRAF on hg19 as data.table
#'
#' DNAaseI hypersensitivity sites in the H562 cell line from UCSC Table Browser
#' hg19, subset to the BRAF locus with 1000 bp flank.
#'
#' @name braf_dnase_demo_dt_hg19
#' @docType data
#' @keywords data
#' @format \code{data.table}
NULL

#' DNAaseI hypersensitivity sites for BRAF on hg38 as data.table
#'
#' DNAaseI hypersensitivity sites in the H562 cell line from UCSC Table Browser
#' hg38 liftover, subset to the BRAF locus with 1000 bp flank.
#'
#' @name braf_dnase_demo_dt_hg38
#' @docType data
#' @keywords data
#' @format \code{data.table}
NULL

#' Collection of genomic regions to exclude from analysis on hg38 as GenomicRanges
#'
#' A convenient single collection of genomic regions suggested to exclude from
#' analysis due to mappability issues, enrichment of duplicated regions,
#' telomeric, centromeric, acrocentric short-arms, and highly heterochromatin/gene
#' desert portions of the chromosomes.
#'
#' Built from UCSC and ENCODE blacklists.
#' See excluderanges (https://github.com/dozmorovlab/excluderanges).
#'
#' @name exclusion_regions_hg38
#' @docType data
#' @keywords data
#' @format \code{GRanges}
NULL

#' Genomic coordinates of each chromosome arm on hg38 as GenomicRanges
#'
#' A convenient single collection of the genomic span of each chromosome arm.
#' The span is described as:
#'                     |  ranges kept  |
#' p-arm         start |<------------->| centromere
#' q-arm    centromere |<------------->| end
#'
#' Note, this data does not include a range across the centromeres, for these
#' see `exclusion_regions_hg38`.
#'
#' @name chromosome_arms_hg38
#' @docType data
#' @keywords data
#' @format \code{GRanges}
NULL

#' dryclean-fragCounter read depth profile on hg38 as GenomicRanges
#'
#' A slice of data from a `dryclean` adjusted `fragCounter` read depth profile
#' of a tumor sample.
#' The demo contains slices from chr19 and chr22.
#'
#' See `fragCounter` (https://github.com/mskilab-org/fragCounter)
#' and `dryclean` (https://github.com/mskilab-org/dryclean)
#'
#' @name read_depth_demo_hg38
#' @docType data
#' @keywords data
#' @format \code{GRanges}
NULL

#' Gene body segments from Ensemble v108 on hg38 as GenomicRanges
#'
#' This genomic ranges contains the gene body segments (UTRs, Exons, Introns)
#' for a single-transcript representation of Ensembl v108 genes on hg38.
#'
#'                          |  gene body schematic  |
#' [5` prime UTR]{Exon}<---Intron--->{Exon}<---Intron--->{Exon}[3` prime UTR]
#'
#' The genes included had the following `gene_biotype`:
#' protein_coding
#' IG_C_gene,IG_D_gene,IG_J_gene,IG_V_gene,
#' TR_C_gene,TR_D_gene,TR_J_gene,TR_V_gene
#' lncRNA,miRNA
#'
#' The transcript for protein-coding genes were determined using MANE Select &
#' MANE Plus Clinical v1.4 annotations
#'
#' Built from
#' * Ensembl v108 GTF (https://ftp.ensembl.org/pub/release-108/gtf/homo_sapiens/Homo_sapiens.GRCh38.108.gtf.gz)
#' * MANE v1.4 summary file (https://ftp.ncbi.nlm.nih.gov/refseq/MANE/MANE_human/release_1.4/MANE.GRCh38.v1.4.summary.txt.gz)
#'
#' @name gene_body_hg38
#' @docType data
#' @keywords data
#' @format \code{GRanges}
NULL

#' RNA-seq counts matrix on hg38 as data.table
#'
#' Bulk RNA-seq data from RPMI-8226 and U-266 human myeloma cell lines that have
#' been processed to transcript counts matrix.
#' There are 3 replicates of each HMCL for use in DESeq2 differential gene
#' expression analysis.
#'
#' @name hmcl_counts_demo_dt_hg38
#' @docType data
#' @keywords data
#' @format \code{data.table}
NULL

#' Condition labels for associated RNA-seq counts matrix as data.table
#'
#' Simple labels for RPMI-8226 and U-266 human myeloma cell lines that have
#' been processed to transcript counts matrix.
#'
#' @name hmcl_conditions_demo_dt_hg38
#' @docType data
#' @keywords data
#' @format \code{data.table}
NULL



#
#
# }}}}------->>> CLI for talking the user through the package
#
#

#' @name cli_pio_colorscheme
#' @title Set the color scheme options for pio CLI text in devgru
#'
#' @description
#' Quickly set the options for pio package CLI text output.
#'
#' @examples
#' cli_pio_colorscheme()
#'
#' @export
cli_pio_colorscheme <- function () {
  options(pio.header_bg_colour = crayon::bgBlack)
  options(pio.header_fg_colour = crayon::cyan)
  options(pio.title_sep_colour = crayon::cyan)
  options(pio.title_fg_colour = crayon::cyan)
  options(pio.string_bg_colour = crayon::bgBlack)
  options(pio.string_fg_colour = crayon::cyan)
}

#' @name cli_stopwatch_start
#' @title Verbose CLI output to designate a workflow start
#'
#' @description
#' Display to the user the workflow has begun, the function that launched it, and
#' start the stopwatch to track execution time,
#'
#' @param package What is the package of the function, default: devgru
#' @param function_name What is the function name
#'
#' @examples
#' process_start <- cli_stopwatch_start(package = "devgru", function_name = "workflow_demo_func")
#' process_start
#'
#' @returns CLI message and start time of process run
#' @export
cli_stopwatch_start <- function(package = "devgru", function_name) {
  # Time stamp start
  cli::cli_rule("{crayon::green('Start')}")
  cli::cli_text("{crayon::cyan({package})} :: {.emph {.pkg {function_name}()}} ",
                as.character(Sys.time()))
  # Stopwatch start
  stopwatch_start <- proc.time()
  return(stopwatch_start)
}

#' @name cli_stopwatch_end
#' @title Verbose CLI output to designate a workflow end
#'
#' @description
#' Display to the user the workflow has ended, stop the stopwatch, and display execution time.
#'
#' @param package What is the package of the function, default: devgru
#' @param function_name What is the function name
#' @param stopwatch_start What was the start time of the stopwatch, typically captured
#'  and passed along by `cli_stopwatch_start()`, see examples
#'
#' @examples
#' process_start <- cli_stopwatch_start(package = "devgru",
#'                                      function_name = "workflow_demo_func")
#' process_end <- cli_stopwatch_end(package = "devgru",
#'                                  function_name = "workflow_demo_func",
#'                                  stopwatch_start = process_start)
#'
#' @export
cli_stopwatch_end <- function(package = "devgru", function_name, stopwatch_start) {
  # Time stamp stop
  cli::cli_rule("{crayon::red('Stop')}")
  cli::cli_text("{crayon::cyan({package})} :: {.emph {.pkg {function_name}()}} ",
                as.character(Sys.time()))
  stopwatch_end <- proc.time() - stopwatch_start

  # Convert to human table of hours,minutes,seconds
  hms_table <- stringr::str_split(string = hms::hms(stopwatch_end[3]), pattern = ":", simplify = T)
  colnames(hms_table) <- c("hours","minutes","seconds")
  cli::cli_alert_info("Duration {crayon::white(clisymbols::symbol$ellipsis)}")
  paint::paint(as.data.table(hms_table))
}


#' @name function_cli_intro
#' @title Verbose CLI output for extended and rich description of steps along a
#'  complex workflow, typically used in a pipeline
#'
#' @description
#' Display to the user the main package, the function being executed, and the parameters
#' passed to the function.
#'
#' @param package What is the package of the function, default: devgru
#' @param function_name What is the function name
#' @param ... What parameters were used in the function
#'
#' @examples
#' # For demo purposes, set these variables
#' parameter_x <- 100
#' parameter_y <- "demo"
#'
#' # In practice, these variables are set within the function being called as in below:
#' # workflow_demo_func <- function(parameter_x, parameter_y)
#' # then the function_cli_intro is called within the function
#'
#' function_cli_intro(package = "devgru",
#'                    function_name = "workflow_demo_func",
#'                    parameter_x, parameter_y)
#'
#' @export
function_cli_intro <- function(package = "devgru", function_name, ...) {
  # Show package
  cli_pio_colorscheme()
  pio::pioHdr(package, paste0("v",utils::packageVersion(package)))
  cli::cli_rule()
  cat("\n")
  # Show function
  cli::cli_alert(text = "Launching {.emph {.pkg {function_name}()}} {crayon::white(clisymbols::symbol$ellipsis)}")
  cat("\n")
  # show params if provided
  params <- list(...)
  params_names <- lapply(substitute(list(...))[-1], deparse)
  if(length(params) != 0) {
    # Construct the parameter CLI
    params_string <- c()
    for(i in 1:length(params)) {
      params_string <- append(x = params_string,
                              values = paste0("{crayon::green('", params_names[i], "')} = ", params[i]))
    }
    cli::cli_text("*****************************  {crayon::green('PARAMS')}  *****************************")
    cli::cli_ul(params_string)
    cli::cli_text("*****************************************************************")
    cat("\n")
  }
}

#' @name kit_loadout
#' @title Build the devgru environment by installing/loading packages
#'
#' @description
#' Single command to install, if needed, and load all packages used in the devgru kit.
#'
#' @param update_kit Update all packages even if already installed, default: FALSE
#'
#' @examples
#' # Quick start devgru environment
#' # kit_loadout()
#'
#' # Update the suite of packages used in the kit
#' # kit_loadout(update_kit = T)
#'
#' @export
kit_loadout <- function(update_kit = F) {
  process_start <- cli_stopwatch_start(function_name = "kit_loadout")
  logo_viz <- "
                   ___   ___        ____   ____
                    | | |     |   /  |     |   | |   |
 }}}}------->>>     + | |-+-  |  +   | +-  |-+-  |   |    <<<-------{{{{
                    | | |     | /    |   | |  \\  |   |
                   ---   ---   /      ---      \\  ---
"
  # Packages for loadout
  loadout <- c("BSgenome.Hsapiens.UCSC.hg38", "GenomicRanges", "GenomeInfoDb",
               "data.table", "mskilab-org/gUtils", "VariantAnnotation",
               "rtracklayer", "Biostrings", "S4Vectors", "dplyr",
               "stringr", "readr", "ggplot2", "ggsci", "paletteer", "scico",
               "flextable", "mclust", "parallel", "doParallel", "foreach",
               "R.utils")

  # The set of packages used to work on GenomicRanges objects
  gr_core_pkgs <- data.frame("GenomicRanges Core" = c("BSgenome.Hsapiens.UCSC.hg38","GenomicRanges",
                                                      "GenomeInfoDb","data.table","mskilab-org/gUtils",
                                                      "VariantAnnotation","rtracklayer","Biostrings",
                                                      "S4Vectors"))
  # The set of packages used to add more functionality on top to GenomicRanges objects
  util_core_pkgs <- data.frame("Utility Core" = c("dplyr","stringr","readr","ggplot2","ggsci",
                                                  "paletteer","scico","flextable","mclust","parallel",
                                                  "doParallel","foreach","R.utils"))
  # Output the logo
  cat(logo_viz)
  # CLI to show the packages in the kit
  cat("\n")
  cli::cli_alert_info("Building the {.pkg devgru} kit {crayon::white(clisymbols::symbol$ellipsis)}")
  cli::cli_alert_info("Loadout currently includes:")
  options(paint_max_width = 1000)
  paint::paint(gr_core_pkgs)
  paint::paint(util_core_pkgs)
  # Load the packages with librarian
  if(update_kit) {
    pak::pkg_install(pkg = loadout, upgrade = update_kit)
  }
  librarian::shelf(loadout, update_all = F, quiet = T)
  cat("\n")
  cli_stopwatch_end(function_name = "kit_loadout",
                    stopwatch_start = process_start)
}



#
#
# }}}}------->>> Tools for surveying the GenomicRanges
#
#

#' @name gr_refactor_seqs
#' @title Refactor seqinfo, seqnames, seqlengths, seqlevels of GenomicRanges object for easy harmony
#'
#' @description
#' Single command to refactor all seq details of a GenomicRanges object to easily harmonize with any other GenomicRanges object.
#' By default, this package uses the autosome (1-22) and sex chromosomes (X,Y) of hg38, see `gUtils::hg_seqlengths()`
#' Users can adjust this using the `new_levels` parameter.
#'
#' @param input_gr GenomicRanges object to refactor
#' @param new_levels Named vector object used as the template for new seq details, see `gUtils::hg_seqlengths()` for example
#'
#' @examples
#' # Converting between reference genomes is complicated and proper seqinfo is hard
#' # to achieve without many lines of code, this function helps alleviate the issue
#'
#' # Look at seqinfo from a hg19 dataset
#' GenomeInfoDb::seqinfo(kras_dnase_demo_gr_hg19)
#'
#' # Look at seqinfo after lift over to hg38
#' GenomeInfoDb::seqinfo(example_dnase_hg38)
#'
#' # Use gr_refactor_seqs to fix the inconsistencies
#' GenomeInfoDb::seqinfo(gr_refactor_seqs(example_dnase_hg38))
#'
#' @returns GenomicRanges object with updated seqinfo, seqnames, seqlengths, seqlevels
#' @export
gr_refactor_seqs <- function(input_gr, new_levels = gUtils::hg_seqlengths()) {
  # First, make sure we match input GR 'chr' notation with the desired seqs
  if(length(grep(x = names(new_levels), pattern = "^chr")) > 0) {
    gr <- gUtils::gr.chr(input_gr)
  } else {
    gr <- gUtils::gr.nochr(input_gr)
  }

  # Now start to reset seqnames
  gr <- GenomeInfoDb::dropSeqlevels(x = gr,
                                    value = GenomeInfoDb::seqlevels(gr)[!GenomeInfoDb::seqlevels(gr) %in% names(new_levels)[1:24]],
                                    pruning.mode = "coarse")

  # Now start to reset seqnames
  gr@seqnames@values <- factor(x = gr@seqnames@values,
                               levels =  names(new_levels)[1:24][GenomeInfoDb::seqlevels(gr) %in% names(new_levels)[1:24]])

  # Sort the new seqinfo
  gr@seqinfo <- GenomeInfoDb::sortSeqlevels(gr@seqinfo, X.is.sexchrom = T)

  # Now ensure seqinfo matches seqnames
  gr@seqinfo <- GenomeInfoDb::Seqinfo(seqnames = names(new_levels)[1:24],
                                      seqlengths = new_levels[1:24])

  # Final sort to ensure ranges are properly sorted by genomic coordinate
  gr <- GenomicRanges::sort.GenomicRanges(gr, ignore.strand = TRUE)

  # And complete the remaining seqinfo columns for genome and isCircular
  GenomeInfoDb::genome(gr) <- "GRCh38"
  GenomeInfoDb::isCircular(gr) <- rep(FALSE,24)
  return(gr)
}

#' @name dt_to_gr
#' @title Convert data.table to GenomicRanges Object
#'
#' @description
#' Single command to smartly convert a data.table object to a GenomicRanges object by
#' wrapping `gr_refactor_seqs()` around the `gUtils::dt2gr()` to avoid seqinfo conflicts
#' and apply proper sorting.
#'
#' @param input_dt data.table object that minimally contains columns like chromosome start, and end position
#'  that describe the genomic coordinates of the range
#'
#' @examples
#' # Converting from data.table to GenomicRanges can be easily done with gUtils::dt2gr()
#' # however this single command conversion leaves some loose ends with the seqinfo
#'
#' # Look at the original data.table
#' braf_dnase_demo_dt_hg38
#' # Now convert to GRanges
#' dt_to_gr(braf_dnase_demo_dt_hg38)
#' # Check the seqinfo
#' GenomeInfoDb::seqinfo(dt_to_gr(braf_dnase_demo_dt_hg38))
#'
#' # Compared to the old way
#' # Conversion looks fine
#' gUtils::dt2gr(braf_dnase_demo_dt_hg38)
#' # However the seqinfo will conflict with other hg38 GRanges
#' GenomeInfoDb::seqinfo(gUtils::dt2gr(braf_dnase_demo_dt_hg38))
#'
#' @returns GenomicRanges object with input columns and updated seqinfo, seqnames, seqlengths, seqlevels
#' @export
dt_to_gr <- function(input_dt) {
  # Wrap the dt2gr function with the gr_refactor_seqs function
  gr <- gr_refactor_seqs(input_gr = gUtils::dt2gr(input_dt, seqlengths = gUtils::hg_seqlengths()[1:24]),
                         new_levels = gUtils::hg_seqlengths()[1:24])
  return(gr)
}

#' @name gr_sanitycheck
#' @title Check if input is a GenomicRanges object, plus optional sanity check of column names
#'
#' @description
#' Simple check if the input is a GenomicRanges object, plus includes an additional functionality
#' to perform a smart, transparent sanity check of expected column names.
#'
#' @param query_gr Suspected GenomicRanges-like object to test
#' @param expected_cols Vector of character strings to check for consistency in
#'  columns of query GenomicRanges, default: NULL
#'
#' @examples
#' # Not a GR
#' gr_sanitycheck(query_gr = braf_dnase_demo_dt_hg38)
#' # Just a GR
#' gr_sanitycheck(query_gr = kras_dnase_demo_gr_hg38)
#' # GR with correct columns
#' gr_sanitycheck(query_gr = kras_dnase_demo_gr_hg38,
#'                expected_cols = c("signalValue","pValue","biospecimen","gene"))
#' # GR with less columns than expected
#' gr_sanitycheck(query_gr = kras_dnase_demo_gr_hg38[,-3],
#'                expected_cols = c("signalValue","pValue","biospecimen","gene"))
#'
#' @returns TRUE or FALSE
#' @export
gr_sanitycheck <- function(query_gr, expected_cols = NULL) {
  # Generic check if query is a GR obj
  # No constraint on expected number of columns
  if(is.null(expected_cols)) {
    if(inherits(query_gr, "GenomicRanges")) {
      return(TRUE)
    } else {
      return(FALSE)
    }
    # Specific check if query is a GR obj
    # Must have expected number of columns
    # Should only be used for defined workflows
  } else if(!is.null(expected_cols)) {
    # First check if GR, then add constraints
    if(inherits(query_gr, "GenomicRanges")) {
      # Check if columns are equal
      if(length(colnames(S4Vectors::mcols(query_gr))) == length(expected_cols)) {
        # Check if columns are same as expected
        if(all.equal(target = expected_cols, current = colnames(S4Vectors::mcols(query_gr)))) {
          return(TRUE)
        } else {
          pio::pioDisp(gUtils::gr2dt(query_gr))
          cli::cli_alert_danger(all.equal(target = expected_cols, current = colnames(S4Vectors::mcols(query_gr))))
          return(FALSE)
        }
        # Columns are not equal
      } else if(length(colnames(S4Vectors::mcols(query_gr))) > length(expected_cols)) {
        extra_cols <- colnames(S4Vectors::mcols(query_gr))[which(!colnames(S4Vectors::mcols(query_gr)) %in% expected_cols)]
        pio::pioDisp(gUtils::gr2dt(query_gr))
        cli::cli_alert_danger("Input GenomicRanges object had more columns than expected - extra columns: {crayon::red({extra_cols})}")
        return(FALSE)
      } else if(length(colnames(S4Vectors::mcols(query_gr))) < length(expected_cols)) {
        missing_cols <- expected_cols[which(!expected_cols %in% colnames(S4Vectors::mcols(query_gr)))]
        pio::pioDisp(gUtils::gr2dt(query_gr))
        cli::cli_alert_danger("Input GenomicRanges object had less columns than expected - missing columns: {crayon::red({missing_cols})}")
        return(FALSE)
      }
    } else {
      return(FALSE)
    }
  }
}

#' @name dt_sanitycheck
#' @title Check if input is a data.table object, plus optional sanity check of column names
#'
#' @description
#' Simple check if the input is a data.table object, plus includes an additional functionality
#' to perform a smart, transparent sanity check of expected column names.
#'
#' @param query_dt Suspected data.table-like object to test
#' @param expected_cols Vector of character strings to check for consistency in
#'  columns of query data.table, default: NULL
#'
#' @examples
#' # Not a DT
#' dt_sanitycheck(query_dt = kras_dnase_demo_gr_hg38)
#' # Just a DT
#' dt_sanitycheck(query_dt = braf_dnase_demo_dt_hg38)
#' # DT with correct columns
#' dt_sanitycheck(query_dt = braf_dnase_demo_dt_hg38,
#'                expected_cols = c("seqnames","start","end","strand","signalValue",
#'                                  "pValue","biospecimen","gene"))
#' # DT with less columns than expected
#' dt_sanitycheck(query_dt = braf_dnase_demo_dt_hg38[,-7],
#'                expected_cols = c("seqnames","start","end","strand","signalValue",
#'                                  "pValue","biospecimen","gene"))
#'
#' @returns TRUE or FALSE
#' @export
dt_sanitycheck <- function(query_dt, expected_cols = NULL) {
  # Generic check if query is a DT obj
  # No constraint on expected number of columns
  if(is.null(expected_cols)) {
    if(inherits(query_dt, "data.table")) {
      return(TRUE)
    } else {
      return(FALSE)
    }
    # Specific check if query is a DT obj
    # Must have expected number of columns
    # Should only be used for defined workflows
  } else if(!is.null(expected_cols)) {
    # First check if DT, then add constraints
    if(inherits(query_dt, "data.table")) {
      # Check if columns are equal
      if(length(colnames(query_dt)) == length(expected_cols)) {
        # Check if columns are same as expected
        if(all.equal(target = expected_cols, current = colnames(query_dt))) {
          return(TRUE)
        } else {
          pio::pioDisp(query_dt)
          cli::cli_alert_danger(all.equal(target = expected_cols, current = colnames(query_dt)))
          return(FALSE)
        }
        # Columns are not equal
      } else if(length(colnames(query_dt)) > length(expected_cols)) {
        extra_cols <- colnames(query_dt)[which(!colnames(query_dt) %in% expected_cols)]
        pio::pioDisp(query_dt)
        cli::cli_alert_danger("Input data.table object had more columns than expected - extra columns: {crayon::red({extra_cols})}")
        return(FALSE)
      } else if(length(colnames(query_dt)) < length(expected_cols)) {
        missing_cols <- expected_cols[which(!expected_cols %in% colnames(query_dt))]
        pio::pioDisp(query_dt)
        cli::cli_alert_danger("Input data.table object had less columns than expected - missing columns: {crayon::red({missing_cols})}")
        return(FALSE)
      }
    } else {
      return(FALSE)
    }
  }
}

# TODO: add more intelligent setting of boundaries by storing the values of the
#       chromosome arms and finding these boundaries for each chromosome and arm in a GR
#' @name gr_flank
#' @title Precise addition of flanking to GenomicRanges with boundary-aware options
#'
#' @description
#' Precise addition of flanks to the start and/or end of a GenomicRanges object with the option
#' of setting a boundary for the flanks, helpful to account for boundaries like chromosome arms.
#'
#' Note, the boundaries are compared directly to the new flanked start/end and do not currently
#' take the chromosome into account automatically. Thus, this function is best applied in on
#' per chromosome basis.
#'
#' If the flank exceeds the boundary, the new flanked start/end will set at the boundary.
#'
#' @param input_gr GenomicRanges object to add flanks to
#' @param start_flank Amount of flank (in bp) to be added to the start of the ranges, default: NULL
#' @param end_flank Amount of flank (in bp) to be added to the end of the ranges, default: NULL
#' @param start_flank_boundary The genomic coordinate the start of the flanked GenomicRanges should
#'  to not exceed, default: NULL
#' @param end_flank_boundary The genomic coordinate the end of the flanked GenomicRanges should
#'  to not exceed, default: NULL
#'
#' @examples
#' # The gene NOTCH2 is close to the p-arm centromere on chr1
#' notch2 <- gUtils::parse.gr("chr1:119911553-120069662")
#' notch2
#' chr1_p_arm <- gUtils::`%Q%`(chromosome_arms_hg38, seqnames == "chr1" & arm == "p")
#' chr1_p_arm
#' GenomicRanges::end(chr1_p_arm)
#'
#' # If sampling data around this locus in a 3 Mb window, it's important to not
#' # extend into/beyond the centromere so we need to set this boundary
#' gr_flank(input_gr = notch2,
#'          start_flank = 3e6,
#'          end_flank = 3e6,
#'          start_flank_boundary = GenomicRanges::start(chr1_p_arm),
#'          end_flank_boundary = GenomicRanges::end(chr1_p_arm))
#'
#' @returns GenomicRanges object with updated start/end coordinates
#' @export
gr_flank <- function(input_gr, start_flank = NULL, end_flank = NULL, start_flank_boundary = NULL, end_flank_boundary = NULL) {
  # Check the input object. If data.table, continue on. If not, convert
  if(gr_sanitycheck(query_gr = input_gr)) {
    input_dt <- gUtils::gr2dt(input_gr)
  } else if(dt_sanitycheck(query_dt = input_gr)) {
    input_dt <- input_gr
  }

  # Check user has set one of the flank values
  if(is.null(start_flank) & is.null(end_flank)) {
    stop(cli::cli_alert_danger("Must set either {crayon::cyan('start_flank')} or {crayon::cyan('end_flank')} {crayon::white(clisymbols::symbol$ellipsis)}"))
  }

  # First, add the flank to the start of the DT obj to get the potential new loci value
  # this can end up being a negative number
  # Catch this behavior here and enforce a boundary if detected
  flanked_start <- input_dt$start - start_flank

  # If flanked start point is within the boundary
  if(!is.null(start_flank_boundary) & flanked_start >= start_flank_boundary) {
    new_start <- flanked_start

  # if flanked start is outside the boundary, set the new start to this edge
  } else if(!is.null(start_flank_boundary) & flanked_start < start_flank_boundary) {
    new_start <- start_flank_boundary

  # if boundary is not set, keep flanked start but must apply trim to keep on chromosome scale
  } else if(is.null(start_flank_boundary)) {
    new_start <- flanked_start
  }

  # Apply same process for the end of the GR obj
  flanked_end <- input_dt$end + end_flank

  # If flanked end point is within the boundary
  if(!is.null(end_flank_boundary) & flanked_end <= end_flank_boundary) {
    new_end <- flanked_end

  # if flanked end is outside the boundary, set the new end to this edge
  } else if(!is.null(end_flank_boundary) & flanked_end > end_flank_boundary) {
    new_end <- end_flank_boundary

  # if boundary is not set, keep flanked start but must apply trim to keep on chromosome scale
  } else if(is.null(end_flank_boundary)) {
    new_end <- flanked_end
  }

  # Now update the values
  input_dt$start <- new_start
  input_dt$end <- new_end

  # Convert back to GR obj
  # Apply the trim if unbound
  if(is.null(start_flank_boundary) | is.null(end_flank_boundary)) {
    flanked_gr <- GenomicRanges::trim(dt_to_gr(input_dt))
  } else {
    flanked_gr <- dt_to_gr(input_dt)
  }
  return(flanked_gr)
}

#' @name gr_to_seg
#' @title Convert segmentation GenomicRanges object to a data.table with standardized columns and format
#'
#' @description
#' Converts a segmentation GenomicRanges object into a data.table object then extracts the
#' appropriate columns and renames the columns to match the expected format.
#'
#' The input GenomicRanges is typically generated from `get_dryclean_segmentation()` workflow
#' or other `DNAcopy` CBS algorithm runs.
#'
#' @param input_gr Segmentation GenomicRanges object to convert to data.table
#' @param exp_colnames Expected column names for CBS segmentation input GenomicRanges
#'
#' @examples
#' # Convert output from `get_dryclean_segmentation()` workflow
#' # dryclean_seg <- get_dryclean_segmentation(
#' # path_to_dryclean_profile = "read_depth_demo_hg38.rds",
#' # cpus = 4)
#'
#' # gr_to_seg(dryclean_seg)
#'
#' @returns data.table
#' @export
gr_to_seg <- function(input_gr, exp_colnames = c("ID","num.mark","seg.mean")) {
  # Sanity check of columns in input GR
  if(!gr_sanitycheck(query_gr = input_gr, expected_cols = exp_colnames)) {
    stop(cli::cli_alert_danger("Check input"))
  }

  seg <- gUtils::gr2dt(input_gr) %>%
    dplyr::select(ID,seqnames,start,end,num.mark,seg.mean) %>%
    dplyr::rename("chrom" = seqnames, "loc.start" = start, "loc.end" = end)
  return(seg)
}






#
#
# }}}}------->>> Complex function workflows
#
#

#' @name chrompar
#' @title Scaffold function around `easypar` to run workflows in parallel by chromosome
#'
#' @description
#' A scaffold function to be used within other complex workflow functions that provides
#' easy API to `easypar` functionality and executes a function in parallel by chromosome
#'
#' The scaffold takes a function where the input can be subset by chromosome and the
#' expected output is either a data.table or GenomicRanges object
#'
#' @param par_function The function that will be executed in parallel by chromosome, written
#'  as the function name without the `()` a the end
#' @param par_chromosomes The set of chromosomes to execute in parallel, non-duplicated values
#'  and can be any chromosomes as long as present in input data
#' @param ... The input parameters that will be passed to `par_function` for execution, these
#'  must be provided in the order expected by `par_function`
#' @param run_in_par Run the jobs in parallel and not sequentially, default: TRUE
#' @param par_cpus Number of CPUs to use for parallel execution, `easypar` will safeguard against using
#'  all available CPUs
#' @param par_packages Vector of character strings designating special packages needed for
#'  executing the `par_function`
#'
#' @examples
#' # Run as part of the `get_dryclean_segmentation()` workflow using
#' # `get_cbs_per_chromosome()` as the par_function
#' # final_cbs_segmentation <- chrompar(
#' # par_function = get_cbs_per_chromosome,
#' # par_chromosomes = chrom_iter_list,
#' # par_cpus = threads,
#' # seqnames_nona, foreground_cov_nona, start_nona, sample_id)
#'
#' @returns GenomicRanges object with properly sorted genomic coordinates
#' @export
chrompar <- function(par_function, par_chromosomes, ..., run_in_par = T, par_cpus = NULL, par_packages = NULL) {
  # Function CLI
  cli::cli_alert_info(text = "Launching {.emph {.pkg {as.character(substitute(par_function))}()}} in parallel using chromosomes {crayon::white(clisymbols::symbol$ellipsis)}")
  cat("\n")
  cli::cli_text("****************")
  cli::cli_ul(par_chromosomes, .close = T)
  cli::cli_text("****************")
  cat("\n")

  # Build the parameters for the parallel run
  # Add the chromosome to each set of inputs provided
  par_params <- list()
  for(i in 1:length(par_chromosomes)) {
    par_params[[i]] <- c(par_chromosomes[i], list(...))
  }

  # Set the cores to user defined limit otherwise keep ratio
  if(!is.null(par_cpus)) {
    par_cores_ratio <- par_cpus / parallel::detectCores()
  } else {
    par_cores_ratio <- 0.8
  }

  # Run easypar by chromosome
  par_out_list <- easypar::run(FUN = par_function, PARAMS = par_params, parallel = run_in_par, cores.ratio = par_cores_ratio,
                               outfile = NULL, progress_bar = F, silent = F, packages = par_packages, filter_errors = F)

  # Combine the output as sorted GR object
  cat("\n")
  cli::cli_alert_success("Parallel jobs completed. Merging per chromosome output and sorting {crayon::white(clisymbols::symbol$ellipsis)}")
  par_out <- data.table::rbindlist(par_out_list)
  par_out_gr <- dt_to_gr(par_out)

  return(par_out_gr)
}

#' @name get_cbs_per_chromosome
#' @title Single chromosome run circular binary segmentation (CBS) algorithm on read depth profile
#'
#' @description
#' Run CBS algorithm using DNAcopy on a per-chromosome basis on read depth profile. This
#' allows for parallel computation of the segmentation, rapidly reducing run time.
#' There should be no `NA`s in the columns or `0`s in the `signal` column.
#'
#' Note, this function was designed to be run as part of the `get_dryclean_segmentation()`
#' workflow. Also, see `chrompar()` for executing in parallel.
#'
#' @param chrom_for_cbs The chromosome to run CBS algorithm on
#' @param chromosome_names A vector of chromosome strings, equivalent to the seqnames
#'  column. Must contain at least the `chrom_for_cbs`
#' @param signal A vector of read depth signal to be used as input, equivalent to
#'  the foreground or read ratio column. These values will be `log`ged before use in CBS
#' @param position A vector of the genomic position of the signal measurement, equivalent
#'  to the start column
#' @param sample_id A string used to populate the ID column in the data.table
#'
#' @examples
#' # For this example, there are no NAs or zeros in the `signal`
#' # Check for these and may need to filter them out
#' read_depth_demo_hg38
#'
#' # Example of what the input looks like for
#' # chromosome_names
#' head(as.character(GenomicRanges::seqnames(read_depth_demo_hg38)))
#' # signal
#' head(as.double(GenomicRanges::values(read_depth_demo_hg38)[, "foreground"]))
#' # position
#' head(GenomicRanges::start(read_depth_demo_hg38))
#'
#' @returns data.table of CBS segmentation values per chromosome
#' @export
get_cbs_per_chromosome <- function(chrom_for_cbs, chromosome_names, signal, position, sample_id) {
  # Function CLI
  cli::cli_text("{clisymbols::symbol$pointer} {.emph {crayon::green({chrom_for_cbs})}}")

  # Grab chromosome specific data for run the DNAcopy CBS workflow
  idx_per_chrom <- which(chromosome_names == chrom_for_cbs)
  log_signal_per_chrom <- log(signal)[idx_per_chrom]
  chromosome_names_per_idx <- chromosome_names[idx_per_chrom]
  position_per_chrom <- position[idx_per_chrom]

  # Run DNAcopy CBS workflow
  cna_per_chrom <- DNAcopy::CNA(genomdat = log_signal_per_chrom,
                                chrom = chromosome_names_per_idx,
                                maploc = position_per_chrom,
                                data.type = 'logratio')

  # For improved smoothing in output dryclean-based profile
  # # smooth.DNA call
  # increase smooth.region size 10 ==> 25
  # decrease outlier.SD.scale threshold for identifying outliers 4 ==> 3.5
  # decrease smooth.SD.scale threshold 2 ==> 1.75
  # # segment call
  # increase min.width to account for small bins of dryclean 2 ==> 5
  # increase kmax 25 ==> 40
  # increase nmin 200 ==> 250
  # added undo.splits ==> sdundo
  # added undo.SD ==>
  cna_segmentation_per_chrom <- DNAcopy::segment(x = DNAcopy::smooth.CNA(x = cna_per_chrom,
                                                                         smooth.region = 25,
                                                                         outlier.SD.scale = 3.5,
                                                                         smooth.SD.scale = 1.75),
                                                 alpha = 1e-5,
                                                 min.width = 5,
                                                 kmax = 40,
                                                 nmin = 250,
                                                 undo.splits = "sdundo",
                                                 undo.SD = 3,
                                                 verbose = 0)

  cna_segmentation_per_chrom_dt <- data.table::as.data.table(cna_segmentation_per_chrom$output)
  cna_segmentation_per_chrom_dt$ID <- sample_id

  # Return output per-chromosome CBS DT
  return(cna_segmentation_per_chrom_dt)
}

#' @name get_dryclean_segmentation
#' @title Generate a segmentation file from a dryclean fragCounter read depth profile
#'
#' @description
#' Given dryclean processed fragCounter read depth profile, run DNAcopy's CBS algorithm
#' in a parallel manner to produce a segmentation file that is compatible with GISTIC2.0.
#'
#' @param path_to_dryclean_profile Path to dryclean fragCounter read depth profile, .rds file
#'  output obtained directly from `dryclean` run
#' @param cpus Number of CPUs to use for parallel execution, default: 1
#' @param random_seed Numeric value to use as random seed for consistent results
#' @param verbose Output CLI during workflow, default: TRUE
#' @param exp_colnames Expected column names for dryclean fragCounter read depth profile
#'  input data.table
#'
#' @examples
#' # Demo dryclean fragCounter read depth profile
#' read_depth_demo_hg38
#'
#' # Execute the full workflow
#' # dryclean_seg <- get_dryclean_segmentation(
#' # path_to_dryclean_profile = "read_depth_demo_hg38.rds",
#' # cpus = 4)
#'
#' @returns data.table object with required GISTIC2.0 columns
#' @export
get_dryclean_segmentation <- function(path_to_dryclean_profile, cpus = 1, random_seed = 999, verbose = T,
                                      exp_colnames = c("background.log","foreground.log","input.read.counts",
                                                       "median.chr","foreground","background","log.reads",
                                                       "germline.status")) {
  # Main Workflow Function CLI
  # Verbose tracing
  if(verbose) {
    function_cli_intro(package = "devgru",
                       function_name = "get_dryclean_segmentation",
                       path_to_dryclean_profile, cpus, random_seed, exp_colnames)
  }
  process_start <- cli_stopwatch_start(package = "devgru",
                                       function_name = "get_dryclean_segmentation")

  # Read in dryclean fragCounter coverage
  cli::cli_alert_info("Reading {.file {path_to_dryclean_profile}} {crayon::white(clisymbols::symbol$ellipsis)}")
  sample_id <- basename(stringr::str_remove(string = path_to_dryclean_profile, pattern = "\\..*dryclean.*rds"))
  dryclean_frag_cov <- readRDS(file = path_to_dryclean_profile)
  # Check if input if dryclean GR obj
  if(gr_sanitycheck(query_gr = dryclean_frag_cov, expected_cols = exp_colnames)) {
    cli::cli_alert_success("Success")
  } else {
    stop(cli::cli_alert_danger("Check input"))
  }

  # Grab the drycleaned fragCounter foreground read coverage values
  foreground_cov <- as.double(GenomicRanges::values(dryclean_frag_cov)[, "foreground"])

  # Add very small constant value to move zero values to non-zero values before segmentation
  zero_idx <- which(foreground_cov == 0)
  if(length(zero_idx) > 0) {
    small_const <- .Machine$double.eps
    foreground_cov <- foreground_cov + small_const
    cli::cli_alert_info("{crayon::cyan(length(zero_idx))} coverage data points have zero value, adding small constant value {crayon::cyan(small_const)} to prevent log error")
  }

  # Sub-Workflow CLI
  pio::pioTit(paste0("Circular Binary Segmentation (CBS) with DNAcopy v", utils::packageVersion("DNAcopy")))
  cat("\n")

  # Grab index of all non-NA drycleaned foreground read covearge
  idx <- which(!is.na(foreground_cov))
  foreground_cov_nona <- foreground_cov[idx]
  seqnames_nona <- as.character(GenomicRanges::seqnames(dryclean_frag_cov))[idx]
  start_nona <- GenomicRanges::start(dryclean_frag_cov)[idx]
  chrom_iter_list <- gtools::mixedsort(unique(seqnames_nona))

  # Parallel execution of CBS per chromosome and merging to single DT object
  final_cbs_segmentation <- chrompar(par_function = get_cbs_per_chromosome, par_chromosomes = chrom_iter_list, par_cpus = cpus,
                                     seqnames_nona, foreground_cov_nona, start_nona, sample_id)

  # Return the DT of CBS output for easy downstream use
  cli::cli_alert_success("Segmentation finished")
  cli_stopwatch_end(package = "devgru",
                    function_name = "get_dryclean_segmentation",
                    stopwatch_start = process_start)
  return(final_cbs_segmentation)
}

#' @name get_imputed_gaps_per_chromosome
#' @title Single chromosome run imputation of small, zero coverage gaps in CBS segmentation
#'
#' @description
#' Run imputation of small, zero coverage gaps in CBS segmentation using partition regression
#' of signal in neighborhood adjacent to the gap.
#' The gaps are typically small, less than 500 bp on average and inter spaced among large
#' segments of continuous, homogeneous signal. The gap signal is far less than expected
#' for real deletions, even homozygous events
#' Imputation greatly improves the foreground signal in downstream tools like JaBbA and GISTIC.
#'
#' Note, this function was designed to be run as part of the `get_segmentation_gap_imputation()`
#' workflow. Also, see `chrompar()` for executing in parallel.
#'
#' @param chrom_for_imputation The chromosome to run gap imputation algorithm on
#' @param gapless_segmentation_whitelist GenomicRanges object of segmentation after removing blacklist regions and gaps
#' @param segmentation_gaps GenomicRanges object of gaps from the original segmentation
#' @param threshold Threshold of segmentation signal to determine a gap, default: -4.95
#' @param structural_variant_breakpoints GenomicRanges object of individual breakpoints from sample SVs
#' @param sample_id Name of sample
#' @param make_plots Generate diagnostic plots of imputation results? default: FALSE
#' @param path_for_plots Path to directory to hold diagnostic plot small PNGs (~80 KB per plot)
#'
#' @returns data.table with gap imputed segmentation
#' @export
get_imputed_gaps_per_chromosome <- function(chrom_for_imputation, gapless_segmentation_whitelist, segmentation_gaps, threshold = -4.95,
                                            structural_variant_breakpoints = NULL, sample_id, make_plots = F, path_for_plots) {
  # Function CLI
  cli::cli_text("{clisymbols::symbol$pointer} {.emph {crayon::green({chrom_for_imputation})}}")

  # Grab chromosome specific data for run the partition regression imputation workflow
  gapless_whitelist_seg_per_chrom <- gapless_segmentation_whitelist %Q% (seqnames == chrom_for_imputation)
  gaps_per_chrom <- segmentation_gaps %Q% (seqnames == chrom_for_imputation)
  cli::cli_text("{crayon::red(length(gaps_per_chrom))} {clisymbols::symbol$arrow_right} Gaps to be imputed on {crayon::green({chrom_for_imputation})}")

  if(!is.null(structural_variant_breakpoints)) {
    sv_bps_per_chrom <- structural_variant_breakpoints %Q% (seqnames == chrom_for_imputation)
  }

  # Read in the chromosome arms regions
  chromosome_arms <- (function(...)get(utils::data(...,envir = new.env())))("chromosome_arms_hg38")

  # Loop through the gaps, find the founder segments that will be used to impute the gaps
  imputed_gaps_per_chrom <- data.table::data.table()
  for(i in 1:length(gaps_per_chrom)) {
    # For convenience, set the gap of interest
    goi <- gaps_per_chrom[i]

    # To ensure gaps will only be imputed using values from the same arm, check which arm the gap is located on
    gap_arm <- gUtils::gr.findoverlaps(query = goi,
                                       subject = chromosome_arms,
                                       scol = "arm")
    if(gap_arm$arm == "p") {
      arm_boundaries <- c(GenomicRanges::start(chromosome_arms %Q% (seqnames == chrom_for_imputation & arm == "p")),
                          GenomicRanges::end(chromosome_arms %Q% (seqnames == chrom_for_imputation & arm == "p")))
    } else if(gap_arm$arm == "q") {
      arm_boundaries <- c(GenomicRanges::start(chromosome_arms %Q% (seqnames == chrom_for_imputation & arm == "q")),
                          GenomicRanges::end(chromosome_arms %Q% (seqnames == chrom_for_imputation & arm == "q")))
    }

    # Calculate the padding for each gap, total padding will be 1.5 the size of the gap
    padding <- round(x = GenomicRanges::width(goi) * 1.5,
                     digits = 0)

    # Grab the neighborhood values around gap as the founder segments
    founder_segment <- gUtils::gr.findoverlaps(query = gr_flank(input_gr = goi,
                                                                start_flank =  padding / 2,
                                                                end_flank = padding / 2,
                                                                start_flank_boundary = arm_boundaries[1],
                                                                end_flank_boundary = arm_boundaries[2]),
                                               subject = gapless_whitelist_seg_per_chrom %Q% (seg.mean > threshold),
                                               scol = "seg.mean")

    # Check here if the founder segment exists as expected, the padding could be too small and
    # not provide neighborhood values. If so, increase the padding
    while(length(founder_segment) == 0) {
      # Increase padding
      cli::cli_alert_info("Previous padding {crayon::red({padding})} bp on {crayon::green({chrom_for_imputation})} not large enough {clisymbols::symbol$arrow_right} Increasing by 3x {crayon::white(clisymbols::symbol$ellipsis)}")
      padding <- round(x = padding * 3,
                       digits = 0)
      founder_segment <- gUtils::gr.findoverlaps(query = gr_flank(input_gr = goi,
                                                                  start_flank =  padding / 2,
                                                                  end_flank = padding / 2,
                                                                  start_flank_boundary = arm_boundaries[1],
                                                                  end_flank_boundary = arm_boundaries[2]),
                                                 subject = gapless_whitelist_seg_per_chrom %Q% (seg.mean > threshold),
                                                 scol = "seg.mean")
    }

    # Tile the founder segment used for imputation and add the the corresponding seg.mean to each tile
    partition_reg_data <- gUtils::gr.findoverlaps(query = gUtils::gr.tile(gr = founder_segment, width = 100),
                                                  subject = founder_segment,
                                                  scol = "seg.mean")
    # Add label for diagnostic plotting
    partition_reg_data$tile_type <- "founder"

    # Fit the data with a partition regression
    partition_reg_fit <- rpart::rpart(data = gUtils::gr2dt(partition_reg_data), formula = seg.mean ~ start)

    # If SV BPs are provided, check for overlap here as they will be used to provide
    # a more accurate location of segmentation jump
    goi_sv_bp_overlap <- NULL
    if(!is.null(structural_variant_breakpoints)) {
      goi_sv_bp_overlap <- gUtils::gr.findoverlaps(query = goi,
                                                   subject = sv_bps_per_chrom)
    }

    # SV BP workflow
    # must check if there is an overlap, otherwise use the standard approach
    if(!is.null(goi_sv_bp_overlap) & length(goi_sv_bp_overlap) > 0) {
      # Break the original gap into disjointed segments using the SV breakpoints
      new_goi <- gUtils::gr.breaks(bps = goi_sv_bp_overlap, query = goi)

      # For this approach, the new gaps will not be tiled and will individually be fit predicted
      imputed_sv_gaps <- GenomicRanges::GRanges()
      for(j in 1:length(new_goi)) {
        # Grab each SV gap
        sv_gap <- new_goi[j]

        sv_gap_rpart_pred <- stats::predict(partition_reg_fit, newdata = gUtils::gr2dt(sv_gap))

        # Add the predicted seg.mean to the tiles
        sv_gap$seg.mean <- as.numeric(sv_gap_rpart_pred)
        sv_gap$tile_type <- paste0("imputed gap", j)

        # Add each imputed SV gap to a set
        imputed_sv_gaps <- gUtils::grbind(imputed_sv_gaps, sv_gap)
      }

      # Visualize the gap imputation with a diagnostic plot
      if(make_plots == T) {
        diagnostic_plot <- geom_gap_imputation(original_gap = goi,
                                               imputed_gap_gr = gUtils::grbind(partition_reg_data, imputed_sv_gaps),
                                               sv_bp = goi_sv_bp_overlap)
        ggplot2::ggsave(filename = paste0("impute_", stringr::str_replace(string = gUtils::gr.string(goi), pattern = ":", replacement = "_"), ".png"),
                        plot = diagnostic_plot,
                        path = path_for_plots,
                        width = 125,
                        height = 75,
                        units = "mm",
                        device = "png")
      }

      # Final prep before adding the imputed gaps to the final imputed set
      # Need to update the num.mark column to reflect it being a split of the original
      imputed_sv_gaps_dt <- gUtils::gr2dt(imputed_sv_gaps) %>%
        dplyr::rename("oldnum.mark" = num.mark) %>%
        dplyr::mutate("num.mark" = goi$num.mark / length(imputed_sv_gaps)) %>%
        dplyr::select(seqnames,start,end,strand,width,query.id,subject.id,ID,num.mark,seg.mean)

      # Add to final set
      imputed_gaps_per_chrom <- gUtils::rrbind(imputed_gaps_per_chrom,
                                               imputed_sv_gaps_dt)

      # No SV BP workflow
    } else {
      # tile the gap segment to impute at intervals across the gap
      tiled_gap <- gUtils::gr.tile(gr = gaps_per_chrom[i], width = 100)

      # Use the fit partition regression to predict the values at each tile across the gap
      gap_rpart_pred <- stats::predict(partition_reg_fit, newdata = gUtils::gr2dt(tiled_gap))

      # Add the predicted seg.mean to the tiles
      tiled_gap$seg.mean <- as.numeric(gap_rpart_pred)
      # For plotting
      tiled_gap$tile_type <- "imputed gap"

      # Visualize the gap imputation with a diagnostic plot
      if(make_plots == T & sum(GenomicRanges::width(goi)) > 25000) {
        diagnostic_plot <- geom_gap_imputation(original_gap = goi,
                                               imputed_gap_gr = gUtils::grbind(partition_reg_data, tiled_gap))
        ggplot2::ggsave(filename = paste0("impute_", stringr::str_replace(string = gUtils::gr.string(goi), pattern = ":", replacement = "_"), ".png"),
                        plot = diagnostic_plot,
                        path = path_for_plots,
                        width = 125,
                        height = 75,
                        units = "mm",
                        device = "png")
      }

      # Final prep before adding the imputed gaps to the final imputed set
      # Reduce the tiled gap to the minimum set of contiguous segments based on the change in seg.mean
      imputed_tiled_gap <- gUtils::gr.reduce(tiled_gap, by = "seg.mean")

      # Convert imputed gaps to DT and make last adjustments below
      # also needs sample ID
      # num.mark, calculate by dividing the original num.mark but total new segments
      # subject.id
      imputed_tiled_gap_dt <- gUtils::gr2dt(imputed_tiled_gap) %>%
        dplyr::mutate("ID" = sample_id,
                      "num.mark" = goi$num.mark / length(imputed_tiled_gap)) %>%
        dplyr::rename("subject.id" = tile.id) %>%
        dplyr::select(seqnames,start,end,strand,width,query.id,subject.id,ID,num.mark,seg.mean)

      # Add to final set
      imputed_gaps_per_chrom <- gUtils::rrbind(imputed_gaps_per_chrom,
                                               imputed_tiled_gap_dt)
    }
  }

  # Return the final imputed DT
  return(imputed_gaps_per_chrom)
}

#' @name get_segmentation_gap_imputation
#' @title Generate gap imputed segmentation from CBS output
#'
#' @description
#' Given CBS segmentation with small, zero signal gaps, run neighbrohood-based partition
#' regression gap imputation in a parallel manner to produce a gap imputed segmentation file
#' that is provides cleaner foreground signal in JaBbA and GISTIC.
#'
#' @param path_to_dryclean_segmentation Path to dryclean CBS segmentation
#' @param threshold_for_imputation Threshold for determining gaps for imputation, default: -4.95
#' @param path_to_structural_variants Path to structural variants called for sample, optional
#' @param cpus Number of CPUs to use for parallel execution, default: 1
#' @param make_diagnostic_plots Generate diagnostic plots for each imputed gap, default: FALSE
#' @param path_to_diagnostic_plots_dir Path to directory to place diagnostic plot PNGs
#' @param exp_colnames Expected column names for segmentation input data.table
#' @param verbose Output CLI during workflow, default: TRUE
#'
#' @examples
#' # Execute the full workflow
#' # full_imp_test <- get_segmentation_gap_imputation(
#' # path_to_dryclean_segmentation = "sample.dryclean.fragcounter.cbs.seg",
#' # threshold_for_imputation = -4.95,
#' # path_to_structural_variants = "sample.hq.union.consensus.somatic.sv.bedpe",
#' # cpus = 2,
#' # make_diagnostic_plots = T,
#' # path_to_diagnostic_plots_dir = "impute_qc_plots/")
#'
#' @returns GenomicRanges object with gap imputed segmentation
#' @export
get_segmentation_gap_imputation <- function(path_to_dryclean_segmentation, threshold_for_imputation = -4.95,
                                            path_to_structural_variants = NULL, cpus = 1, make_diagnostic_plots = FALSE,
                                            path_to_diagnostic_plots_dir = NULL, exp_colnames = c("ID","chrom","loc.start","loc.end","num.mark","seg.mean"),
                                            verbose = T) {
  # Main Workflow Function CLI
  # Verbose tracing
  if(verbose) {
    function_cli_intro(package = "devgru",
                       function_name = "get_segmentation_gap_imputation",
                       path_to_dryclean_segmentation, threshold_for_imputation, path_to_structural_variants, cpus, exp_colnames)
  }
  process_start <- cli_stopwatch_start(package = "devgru",
                                       function_name = "get_segmentation_gap_imputation")

  # Read in dryclean CBS segmentation
  cli::cli_alert_info("Reading {.file {path_to_dryclean_segmentation}} {crayon::white(clisymbols::symbol$ellipsis)}")
  sample_id <- basename(stringr::str_remove(string = path_to_dryclean_segmentation, pattern = "\\..*dryclean.*seg"))
  dryclean_segmentation <- data.table::fread(file = path_to_dryclean_segmentation,
                                             sep = "\t",
                                             header = T)
  # Check if input if dryclean CBS segmentation DT obj
  if(dt_sanitycheck(query_dt = dryclean_segmentation, expected_cols = exp_colnames)) {
    cli::cli_alert_success("Success")
  } else {
    stop(cli::cli_alert_danger("Check input"))
  }

  if(!is.null(path_to_structural_variants)) {
    if(file.exists(path_to_structural_variants)) {
      structural_variants <- gGnome::jJ(rafile = path_to_structural_variants,
                                        chr.convert = F,
                                        hg = "hg38",
                                        keep.features = T,
                                        seqlengths = gUtils::hg_seqlengths()[1:24])
      # convert to BPs
      sbv_bps <- gUtils::grl.unlist(structural_variants$grl)
    } else {
      stop(cli::cli_alert_danger("Could not locate {.file {path_to_structural_variants}}, check path"))
    }

  } else {
    # No SVs provided
    sbv_bps <- NULL
  }

  # Read in the exclusion regions
  exclusion_regions <- (function(...)get(utils::data(...,envir = new.env())))("exclusion_regions_hg38")

  # Get the whitelist regions
  dryclean_segmentation_whitelist <- gUtils::gr.setdiff(query = dt_to_gr(dryclean_segmentation),
                                                        subject = exclusion_regions)

  # Extract the gaps from the whitelist regions
  gaps_to_impute <- dryclean_segmentation_whitelist %Q% (seg.mean <= threshold_for_imputation)

  # Get the gapless whitelist regions
  dryclean_segmentation_whitelist_gapless <- gUtils::gr.setdiff(query = dryclean_segmentation_whitelist,
                                                                subject = gaps_to_impute)

  # Get the list of chromosomes to iterate over
  chrom_iter_list <- gtools::mixedsort(unique(as.character(GenomeInfoDb::seqnames(gaps_to_impute))))

  # Sub-Workflow CLI
  pio::pioTit(paste0("Partition Regression imputation with rpart v", utils::packageVersion("rpart")))
  cat("\n")

  # Parallel execution of partition regression per chromosome and merging to single GR object
  final_imputed_gaps <- chrompar(par_function = get_imputed_gaps_per_chromosome, par_chromosomes = chrom_iter_list,
                                 par_cpus = cpus, par_packages = c("gUtils", "devgru"),
                                 dryclean_segmentation_whitelist_gapless, gaps_to_impute, threshold_for_imputation,
                                 sbv_bps, sample_id, make_diagnostic_plots, path_to_diagnostic_plots_dir)

  # Combine the imputed gaps with the whitelist gapless regions to make final set
  final_imputed_segmentation <- GenomicRanges::sort(gUtils::grbind(dryclean_segmentation_whitelist_gapless,
                                                                   final_imputed_gaps))

  # Return the GR of imputed gaps output for easy downstream use
  cli::cli_alert_success("Imputation finished")
  cli_stopwatch_end(package = "devgru",
                    function_name = "get_segmentation_gap_imputation",
                    stopwatch_start = process_start)

  return(final_imputed_segmentation)
}


#' @name get_deseq2_diff_expr
#' @title Run DESeq2 differential expression analysis on RNA-seq count data
#'
#' @description
#' Run the DESeq2 differential gene expression analysis workflow from input file
#' counts matrix and conditional labels.
#'
#' The workflow will read in standard output count matrix from `featureCounts`,
#' run DGE analysis between the two conditions provided in the formula string and
#' conditions label file.
#'
#' The counts matrix should contain a column with either the gene symbols (i.e. HUGO)
#' or Ensembl IDs (i.e. ENSG###). The final output gene set will be mapped to Ensembl
#' v108. See `gene_body_hg38` for more info.
#'
#' The `formula_string` should be a character string of the desired comparison in
#' standard `y ~ x` format. Both `x` and `y` should be present in the conditions
#' label file. This formula also handle covariates which should be included before
#' `x`. For example, `y ~ age - BMI + x`. The covariates should also be present in
#' the conditions label file as separate columns.
#'
#' The counts will be filtered to remove genes with little to no expression across
#' all samples using a minimum threshold for mean expression of a gene. This filter
#' can be deactivated by setting `min_transcripts = 0`. The results of this applied
#' filter will be captured in QC plots.
#'
#' The final output will be a list that includes: the full DESeq2 object, a quilt
#' plot of QC diagnostics after filtering, the DGE results as a tidy data.table,
#' and a transcripts per million (TPM) counts data.table.
#'
#' @param counts_file_path Path to the counts matrix file
#' @param condition_file_path Path to the conditions file
#' @param gene_universe GenomicRanges object with genes to include for DGE analysis, default: `gene_body_hg38`
#' @param gene_symbol_column The column name that contains HUGO gene symbols
#' @param ensembl_id_column The column name that contains Ensembl gene IDs
#' @param formula_string A character string of the formula of desired comparison
#' @param min_transcripts The minimum threshold for mean transcript counts per gene, default: 10
#' @param verbose Output CLI during workflow, default: TRUE
#'
#' @examples
#' # dge_demo <- get_deseq2_diff_expr(
#' # counts_file_path = fs::path_package("extdata", "hmcl_counts.hg38.txt.gz", package = "devgru"),
#' # condition_file_path = fs::path_package("extdata", "hmcl_conditions.hg38.txt", package = "devgru"),
#' # gene_universe = gene_body_hg38,
#' # gene_symbol_column = "#GENE",
#' # ensembl_id_column = NULL,
#' # formula_string = "U266 ~ RPMI8226",
#' # min_transcripts = 10)
#'
#' # Look at the output
#' # Full DESeq2 object
#' # dge_demo$deseq2_obj
#'
#' # Diagnostic plots after simple filtering
#' # dge_demo$diagnostic_plots
#'
#' # DGE results as DT
#' # dge_demo$deseq2_results_dt
#'
#' # Per gene TPM as DT
#' # dge_demo$deseq2_tpm_dt
#'
#' @returns List object with Full DESeq2 object, diagnostic plots, DGE log fold change results data.table, per gene TPM results data.table
#' @export
get_deseq2_diff_expr <- function(counts_file_path, condition_file_path, gene_universe = gene_body_hg38, gene_symbol_column = NULL,
                                 ensembl_id_column = NULL, formula_string, min_transcripts = 10, verbose = T) {
  # Main Workflow Function CLI
  # Verbose tracing
  if(verbose) {
    function_cli_intro(package = "devgru",
                       function_name = "get_deseq2_diff_expr",
                       counts_file_path, condition_file_path, gene_symbol_column,
                       ensembl_id_column, formula_string, min_transcripts)
  }
  process_start <- cli_stopwatch_start(package = "devgru",
                                       function_name = "get_deseq2_diff_expr")

  # Sub-Workflow CLI
  pio::pioTit(paste0("Differential Gene Expression Analysis with DESeq2 v", utils::packageVersion("DESeq2")))
  cat("\n")
  cli::cli_text("{crayon::white('==================')}")
  cli::cli_text("{crayon::cyan({clisymbols::symbol$arrow_down})} {crayon::cyan({'DOWN'})} {crayon::cyan({clisymbols::symbol$arrow_down})} {crayon::white({clisymbols::symbol$square})}{crayon::white({clisymbols::symbol$square})} {crayon::red({clisymbols::symbol$arrow_up})} {crayon::red({'UP'})} {crayon::red({clisymbols::symbol$arrow_up})}")
  cli::cli_text("{crayon::white('==================')}")
  cat("\n")

  # Read in all raw counts input file, remove any rows with empty or NA cells for gene symbol/Ensembl ID if provided
  # then map the provided Ensembl IDs to the hg38 reference using gene universe
  cli::cli_text("{crayon::green('Gene Universe')} {clisymbols::symbol$arrow_right} used for final gene symbol mapping {crayon::white(clisymbols::symbol$ellipsis)}")
  paint::paint(gUtils::gr2dt(gene_universe))
  cat("\n")

  cli::cli_alert_info("Reading {.file {counts_file_path}} {crayon::white(clisymbols::symbol$ellipsis)}")
  if(!is.null(gene_symbol_column) & is.null(ensembl_id_column)) {
    cli::cli_text("{crayon::green({gene_symbol_column})} {clisymbols::symbol$arrow_right} name of column with HUGO gene symbols")
    full_counts <- data.table::fread(file = counts_file_path,
                                     sep = "\t",
                                     header = T) %>%
      dplyr::rename("gene_name" = dplyr::all_of(gene_symbol_column)) %>%
      dplyr::filter(gene_name %in% unique(gene_universe$gene_name) & !gene_name %in% c("",NA))

  } else if(is.null(gene_symbol_column) & !is.null(ensembl_id_column)) {
    # TODO: Likely need to modify this for use with different gene_universes
    cli::cli_text("{crayon::green({ensembl_id_column})} {clisymbols::symbol$arrow_right} name of column with Ensembl gene IDs")
    full_counts <-  data.table::fread(file = counts_file_path,
                                      sep = "\t",
                                      header = T) %>%
      dplyr::rename("gene_id" = dplyr::all_of(ensembl_id_column)) %>%
      dplyr::inner_join(y = gUtils::gr2dt(gene_universe) %>%
                          dplyr::select(gene_id, gene_name) %>%
                          dplyr::distinct(),
                        by = "gene_id") %>%
      dplyr::filter(!gene_name %in% c("",NA))

  } else if(!is.null(gene_symbol_column) & !is.null(ensembl_id_column)) {
    # Only provide one or the other, best practice is ensembl_id_column if hg19 or gene_symbol_column if hg38
    stop(cli::cli_alert_danger("Please provide either {crayon::green('gene_symbol_column')} or {crayon::green('ensembl_id_column')} but not both"))

  } else if(is.null(gene_symbol_column) & is.null(ensembl_id_column)) {
    # Only provide one or the other, best practice is ensembl_id_column if hg19 or gene_symbol_column if hg38
    stop(cli::cli_alert_danger("Must provide either {crayon::green('gene_symbol_column')} or {crayon::green('ensembl_id_column')}"))
  }
  cli::cli_alert_success("Success")
  cat("\n")

  # Use the formula to determine the final counts matrix and conditions DT
  cli::cli_alert_info("Differential Expression Design: {.emph {crayon::green({formula_string})}}")
  y_condition <- all.vars(formula(formula_string))[1] # first element is always the 'y' condition
  x_condition <- dplyr::last(all.vars(formula(formula_string)[[3]])) # last element is always the 'x' condition

  # Collect the provided covariates and build the expected columns for the conditions DT
  if(length(all.vars(formula(formula_string))) > 2) {
    # these are any other variables provided after excluding the x condition
    covars <- all.vars(formula(formula_string)[[3]])[-length(all.vars(formula(formula_string)[[3]]))]
    cli::cli_alert_info("Covariates: {.emph {crayon::green({covars})}}")
    condition_cols <- c("sample","condition",covars)
  } else {
    condition_cols <- c("sample","condition")
  }

  # Build conditions from file or DT
  if(is.character(condition_file_path)) {
    full_conditions <- data.table::fread(file = condition_file_path,
                                         sep = "\t",
                                         header = T)

  } else if(is.data.frame(condition_file_path)){
    full_conditions <- data.table::as.data.table(x = condition_file_path)
  }

  # Sanity check here that the conditions DT has correct column names
  # should be sample, condition, type, plus any covariates in the formula
  if(dt_sanitycheck(query_dt = full_conditions, expected_cols = condition_cols)) {
    cli::cli_alert_success("Success")
    cat("\n")
  } else {
    stop(cli::cli_alert_danger("Check input conditions and formula string for consistency"))
  }

  # Now build the final formula-specific conditions matrix
  formula_conditions <- full_conditions %>%
    dplyr::filter(condition %in% c(y_condition, x_condition)) %>%
    dplyr::select(all_of(condition_cols))

  # Factorize condition matrix variables
  formula_conditions$condition <- factor(formula_conditions$condition,
                                         levels = c(x_condition, y_condition))

  # Now build the final formula-specific counts matrix
  formula_counts <- full_counts %>%
    dplyr::select(gene_name, all_of(formula_conditions$sample))

  # Final conversion to matrix format
  formula_conditions <- tibble::column_to_rownames(formula_conditions,
                                                   var = "sample")
  formula_counts <- tibble::column_to_rownames(formula_counts,
                                               var = "gene_name")

  # Simple hard filter first to remove genes with little expression across all samples
  # Remove all genes with mean expression across all samples lower than minimum threshold
  per_gene_mean_expr <- formula_counts %>%
    dplyr::mutate("expr_mean" = round(rowSums(formula_counts) / ncol(formula_counts),
                                     digits = 0)) %>%
    dplyr::select(expr_mean) %>%
    purrr::as_vector() %>%
    as.numeric()

  # Create diagnostic QC plots for simple hard filter
  per_gene_expr_qc <- data.table::data.table("normalized_per_gene_mean_expr" = log10(per_gene_mean_expr + 1),
                                             "is_filtered" = log10(per_gene_mean_expr + 1) < log10(min_transcripts + 1))
  per_gene_expr_qc <- per_gene_expr_qc %>%
    dplyr::mutate("filtered_vs_survived" = dplyr::case_when(is_filtered == T ~ "Filtered",
                                                            is_filtered == F ~ "Survived"))
  per_gene_expr_qc$filtered_vs_survived <- factor(per_gene_expr_qc$filtered_vs_survived,
                                                  levels = c("Survived","Filtered"))

  # Filter out any low expression genes identified
  filtered_formula_counts <- formula_counts[!per_gene_expr_qc$is_filtered,]

  # Build the DESeq2 data set from the counts and conditions matrix
  formula_design <- paste0("~ ", stringr::str_remove(string = as.character(formula(formula_string)[3]),
                                                     pattern = "(|)") %>%
                             stringr::str_replace(pattern = x_condition, replacement = "condition"))

  cli::cli_text("{crayon::green('Conditions')} {clisymbols::symbol$arrow_right} final conditions data {crayon::white(clisymbols::symbol$ellipsis)}")
  paint::paint(formula_conditions)
  cat("\n")

  cli::cli_text("{crayon::green('Counts')} {clisymbols::symbol$arrow_right} final filtered transcript count data {crayon::white(clisymbols::symbol$ellipsis)}")
  paint::paint(filtered_formula_counts)
  cat("\n")

  # Run DESeq2
  deseq2_dataset <- DESeq2::DESeqDataSetFromMatrix(countData = filtered_formula_counts,
                                                   colData = formula_conditions,
                                                   design = formula(formula_design))
  deseq2_obj <- DESeq2::DESeq(object = deseq2_dataset)

  # Visualize the gap imputation with a diagnostic plot
  cli::cli_alert_info("Generating diagnostic QC plots {crayon::white(clisymbols::symbol$ellipsis)}")
  # Historgram of Log10(counts + 1) for all genes with threshold
  normalized_expr_histogram <- ggplot2::ggplot(per_gene_expr_qc) +
    ggplot2::geom_histogram(ggplot2::aes(x = normalized_per_gene_mean_expr), fill = "gray", color = "black", bins = 50) +
    ggplot2::geom_vline(xintercept = log10(min_transcripts + 1), color = "orange", linewidth = 1.5, linetype = "dashed") +
    ggplot2::scale_y_continuous(expand = c(0.02,0.02)) +
    ggplot2::labs(x = expression("Log"[10]*"(transcript counts + 1)"),
                  y = "Number of genes") +
    ggplot2::theme(panel.background = element_rect(fill = "transparent"),
                   panel.border = element_rect(fill = "transparent"))

  # Pie chart of percentage of genes filtered vs survived
  pct_surv_vs_filter <- ggpie::ggpie(data = per_gene_expr_qc,
                                     group_key = "filtered_vs_survived",
                                     count_type = "full",
                                     label_info = "all",
                                     label_size = 5,
                                     label_pos = "out",
                                     label_type = "horizon",
                                     fill_color = paletteer::paletteer_d("ggthemes::wsj_red_green")) +
    theme(legend.position = "none")

  # JitterViolinBox of Log10(counts + 1) for all genes with threshold
  normalized_expr_surv_vs_filter <-ggplot2::ggplot(per_gene_expr_qc, aes(x = filtered_vs_survived, y = normalized_per_gene_mean_expr)) +
    ggplot2::geom_jitter(aes(color = filtered_vs_survived), alpha = 0.4, width = 0.10, size = 2.5) +
    ggplot2::geom_violin(fill = "black", alpha = 0.4, scale = "width") +
    ggplot2::geom_boxplot(fill = "white", outliers = F, alpha = 0.5, width = 0.5) +
    ggplot2::annotate(geom = "point",
                      x = levels(per_gene_expr_qc$filtered_vs_survived),
                      y = per_gene_expr_qc %>%
                        dplyr::group_by(filtered_vs_survived) %>%
                        dplyr::summarise("group_means" = mean(normalized_per_gene_mean_expr)) %>%
                        dplyr::select(group_means) %>%
                        purrr::as_vector() %>%
                        as.numeric(),
                      size = 5,
                      color = "cyan",
                      alpha = 0.75) +
    ggplot2::labs(x = NULL,
                  y = "Mean expression per gene") +
    ggplot2::scale_color_manual(name = "Gene", values = paletteer::paletteer_d("ggthemes::wsj_red_green")) +
    ggplot2::theme(legend.position = "bottom",
                   panel.background = element_rect(fill = "transparent"),
                   panel.border = element_rect(fill = "transparent"))

  # Combine the diagnostics QC plots
  diagnostic_plot <- patchwork::wrap_plots(list(normalized_expr_histogram, normalized_expr_surv_vs_filter,patchwork::plot_spacer(),pct_surv_vs_filter),
                                           nrow = 2)
  cli::cli_alert_success("Success")
  cat("\n")

  # Run the log fold change shrink transform to get the results
  cli::cli_text("{crayon::green('Log fold change shrinkage')} {clisymbols::symbol$arrow_right} used to shrink excessive variability in log fold change estimates across samples in lowly expressed genes {crayon::white(clisymbols::symbol$ellipsis)}")
  # Log fold change shrinkage to more accurately visualize and then rank the results
  deseq2_lfc_shrink_results <- DESeq2::lfcShrink(dds = deseq2_obj,
                                                 coef = 2,
                                                 type = "apeglm")

  # Extract the improved LFC values
  cli::cli_alert_info("Converting DESeq2 differential expression results to data.table {crayon::white(clisymbols::symbol$ellipsis)}")
  deseq2_lfc_shrink_results_dt <- data.table::data.table("gene" = rownames(deseq2_lfc_shrink_results),
                                                         "base_mean" = round(deseq2_lfc_shrink_results$baseMean, digits = 2),
                                                         "log2_fc" = round(deseq2_lfc_shrink_results$log2FoldChange, digits = 4),
                                                         "p_val" = deseq2_lfc_shrink_results$pvalue,
                                                         "p_val_adj" = deseq2_lfc_shrink_results$padj)

  # Calculate the transcripts per million (TPM)
  # Conversion from DESeq2 calculated FPKM (fragment counts normalized per kilobase of feature length per million mapped fragments)
  # originally from Igor Dolgalev: https://github.com/igordot/sns/blob/main/scripts/dge-deseq2.R
  # In-depth explanation described below
  # https://www.novogene.com/us-en/resources/blog/how-to-choose-normalization-methods-tpm-rpkm-fpkm-for-mrna-expression/
  # First need to add gene lengths (used to generate FPKM values), calculated as the sum of all exons lengths
  cli::cli_alert_info("Calculating transcripts per million (TPM) results to data.table {crayon::white(clisymbols::symbol$ellipsis)}")
  gene_lengths <- gUtils::gr2dt(gene_universe) %>%
    dplyr::filter(segment == "exon" & gene_name %in% rownames(deseq2_obj)) %>%
    dplyr::group_by(gene_name) %>%
    dplyr::summarise("basepairs" = sum(width)) %>%
    dplyr::arrange(match(gene_name, rownames(deseq2_obj)))

  mcols(deseq2_obj)$basepairs <- gene_lengths$basepairs

  fpkm_matrix <- DESeq2::fpkm(deseq2_obj, robust = FALSE)
  deseq2_tpm_results <- apply(fpkm_matrix, 2, function(x) { exp(log(x) - log(sum(x)) + log(1e6)) })
  deseq2_tpm_results_dt <- data.table::as.data.table(deseq2_tpm_results, keep.rownames = T) %>%
    dplyr::rename("gene" = rn)

  # Return the DESeq2 for downstream use
  cli::cli_alert_success("Differential expression analysis finished")
  cli_stopwatch_end(package = "devgru",
                    function_name = "get_deseq2_diff_expr",
                    stopwatch_start = process_start)

  deseq2_output_list <- list("deseq2_obj" = deseq2_obj,
                             "diagnostic_plots" = diagnostic_plot,
                             "deseq2_results_dt" = deseq2_lfc_shrink_results_dt,
                             "deseq2_tpm_dt" = deseq2_tpm_results_dt
  )
  return(deseq2_output_list)
}

#' @name get_fgsea_pathway_enrichment
#' @title Run fgsea gene set enrichment analysis on DESeq2 differential gene expression output
#'
#' @description
#' Run fgsea pathway enrichment workflow from DESeq2 DGE analysis with `get_deseq2_diff_expr()`
#' using pathway gene set GMT file of interest.
#'
#' @param deseq2_diff_expr_output DESeq2 object, works directly from `get_deseq2_diff_expr()` output
#' @param pathways GMT file with desired pathway gene sets to test for enrichment
#' @param cpus number of cpus for reading in data, used by `fgsea::fgseaMultilevel()`, default: 1
#' @param verbose Output CLI during workflow, default: TRUE
#'
#' @examples
#' # Run the DESeq2 DGE workflow
#' # dge_demo <- get_deseq2_diff_expr(
#' # counts_file_path = fs::path_package("extdata", "hmcl_counts.hg38.txt.gz", package = "devgru"),
#' # condition_file_path = fs::path_package("extdata", "hmcl_conditions.hg38.txt", package = "devgru"),
#' # gene_universe = gene_body_hg38,
#' # gene_symbol_column = "#GENE",
#' # ensembl_id_column = NULL,
#' # formula_string = "U266 ~ RPMI8226",
#' # min_transcripts = 10)
#'
#' # Get enrichment against B cell specific pathways from ImmuneSigDB
#' # get_fgsea_pathway_enrichment(
#' # deseq2_diff_expr_output = dge_demo,
#' # pathways = "c7.bcell.immunesigdb.v2025.1.Hs.symbols.gmt",
#' # cpus = 2)
#'
#' @returns list object with ranked genes vector and enrichment results data.table
#' @export
get_fgsea_pathway_enrichment <- function(deseq2_diff_expr_output, pathways, cpus = 1, verbose = T) {
  # Main Workflow Function CLI
  # Verbose tracing
  if(verbose) {
    function_cli_intro(package = "devgru",
                       function_name = "get_fgsea_pathway_enrichment",
                       pathways, cpus)
  }
  process_start <- cli_stopwatch_start(package = "devgru",
                                       function_name = "get_fgsea_pathway_enrichment")

  # Sub-Workflow CLI
  pio::pioTit(paste0("Gene Set Enrichment Analysis with fgsea v", utils::packageVersion("fgsea")))
  cat("\n")

  # Check pathway input, if list object, continue ahead. If GMT file path, read in
  cli::cli_alert_info("Reading {.file {pathways}} {crayon::white(clisymbols::symbol$ellipsis)}")
  if(file.exists(pathways) & tools::file_ext(pathways) == "gmt") {
    pathway_list <- fgsea::gmtPathways(pathways)
  }
  cli::cli_alert_success("Success")
  cat("\n")

  cli::cli_text("{crayon::green('Pathways')} {clisymbols::symbol$arrow_right} gene sets to test {crayon::white(clisymbols::symbol$ellipsis)}")
  pio::pioDisp(data.table::data.table("pathways" = names(pathway_list)))
  cat("\n")

  # Create ranked list of genes based on the sign of the logFC and the -log10 p-adj
  ranked_genes <- deseq2_diff_expr_output$deseq2_results_dt %>%
    dplyr::mutate("rank_score" = sign(log2_fc) * -log10(p_val_adj + .Machine$double.eps * 10^-299)) %>%
    dplyr::arrange(dplyr::desc(rank_score)) %>%
    tidyr::drop_na() %>%
    dplyr::select(gene, rank_score)

  # Create named vector to test for enrichment of pathways with fgsea
  rank_set <- ranked_genes$rank_score
  names(rank_set) <- ranked_genes$gene

  # Run fgsea with standard parameters
  pathway_analysis <- fgsea::fgseaMultilevel(pathways = pathway_list,
                                             stats = rank_set,
                                             scoreType = "std",
                                             minSize = 10,
                                             maxSize = 500,
                                             BPPARAM = BiocParallel::MulticoreParam(cpus),
                                             nPermSimple = 1000)

  # Output list of ranked genes and pathway enrichment DT
  cat("\n")
  cli::cli_alert_success("Gene set enrichment analysis finished")
  cli_stopwatch_end(package = "devgru",
                    function_name = "get_fgsea_pathway_enrichment",
                    stopwatch_start = process_start)

  enrichment_output <- list("ranked_genes" = rank_set,
                            "enrichment_results_dt" = pathway_analysis)
  return(enrichment_output)
}

#' @name get_jabba_qc_diagnostic
#' @title Run diagnostic workflow of after JaBbA run to help evaluate quality of graph
#'
#' @description
#' A simple rework to the JaBbA:::QCStats function for more specific local use cases
#' Provides a text file and quilt-like plot with metrics on convergence, RSME of copy number
#' estimates, purity, ploidy, loose ends, and junctions.
#'
#' @param tumor_normal_id The name of the tumor/normal pair with completed `JaBbA` run
#' @param jabba_workdir_path Path to the  completed `JaBbA` run work directory
#' @param verbose Output CLI during workflow, default: TRUE
#'
#' @examples
#' # get_jabba_qc_diagnostic(
#' # tumor_normal_id = "CG15-2647-T_vs_190585-N",
#' # jabba_workdir_path = "jAbBa/CG15-2647-T_vs_190585-N_jabba_workdir/")
#'
#' @returns data.table of QC metrics and quilt-like ggplot
#' @export
get_jabba_qc_diagnostic <- function(tumor_normal_id, jabba_workdir_path, verbose = T) {
  # Main Workflow Function CLI
  # Verbose tracing
  if(verbose) {
    function_cli_intro(package = "devgru",
                       function_name = "get_jabba_qc_diagnostic",
                       tumor_normal_id, jabba_workdir_path)
  }
  process_start <- cli_stopwatch_start(package = "devgru",
                                       function_name = "get_jabba_qc_diagnostic")

  # Sub-Workflow CLI
  pio::pioTit(paste0("QC metric summary of genome graph built with JaBbA v", utils::packageVersion("JaBbA")))
  cat("\n")

  # A copy of internal function JaBbA:::QCstats() with some
  # adjustment for functionality
  if(!dir.exists(jabba_workdir_path)) {
    stop(cli::cli_alert_danger("Could not locate {.file {jabba_workdir_path}}, check path"))
  }

  # Run arguments
  JaBba_Args <- readRDS(paste0(jabba_workdir_path, "cmd.args.rds"))
  # Output genome graph
  output_gg <- readRDS(paste0(jabba_workdir_path, "jabba.gg.rds"))
  # Output metrics on convergence stats
  opt.report <- readRDS(paste0(jabba_workdir_path, "opt.report.rds"))
  # Output karyograph fit stats
  kar <- readRDS(paste0(jabba_workdir_path, "karyograph.rds"))
  # Output loose ends
  loose <- length(readRDS(paste0(jabba_workdir_path, tumor_normal_id, ".jabba.loose_ends.rds")))
  # Input/Output junction tiers
  input_Jtiers <- table(readRDS(paste0(jabba_workdir_path, tumor_normal_id, ".nochr.junctions.bedpe.rds"))$tier)
  output_Jtiers <- table(output_gg$edges[type == 'ALT']$dt$tier)
  # Input/Output copy number segments
  input_segs <- length(readRDS(paste0(jabba_workdir_path, tumor_normal_id, ".nochr.dryclean.fragcounter.cbs.imp.seg.rds")))
  output_segs <- nrow(output_gg$nodes$dt)
  # Correlations between output copy number and maximum likelihood estimates
  corr_sp <- cor.test(kar$segstats$cnmle[!is.na(kar$segstats$cn)],
                      kar$segstats$cn[!is.na(kar$segstats$cn)],
                      method = "spearman")
  corr_pe <- cor.test(kar$segstats$cnmle[!is.na(kar$segstats$cn)],
                      kar$segstats$cn[!is.na(kar$segstats$cn)],
                      method = "pearson")
  # Root mean squared error between output copy number and MLE
  rmse <- sqrt(sum((kar$segstats$cnmle-kar$segstats$cn)^2,
                   na.rm = TRUE))
  # Output ep gap value of convergance
  fep <- readRDS(paste0(jabba_workdir_path, "jabba.raw.rds"))$epgap

  # Combine all metrics to single table
  qc_stats_dt <- data.table::data.table("stat" = c("Tumor_Normal_ID",
                                                   "Tier_1_Input_Junctions",
                                                   "Tier_2_Input_Junctions",
                                                   "Tier_3_Input_Junctions",
                                                   "Tier_1_Output_Junctions",
                                                   "Tier_2_Output_Junctions",
                                                   "Tier_3_Output_Junctions",
                                                   "Number_of_Segments_Input",
                                                   "Number_of_Segments_Output",
                                                   "Non_telomeric_Loose_Ends",
                                                   "Requested_epgap",
                                                   "Final_epgap",
                                                   "Converged",
                                                   "Spearman_Rho_of_Coverage_and_CN",
                                                   "p_value_of_Spearman_Rho",
                                                   "Pearson_r_of_Coverage_and_CN",
                                                   "p_value_of_Pearson_r",
                                                   "RMSE_of_Coverage_and_CN",
                                                   "purity",
                                                   "ploidy"),
                                        "value" = c(tumor_normal_id,
                                                    ifelse("1" %in% names(input_Jtiers), input_Jtiers[[1]], "0"),
                                                    ifelse("2" %in% names(input_Jtiers), input_Jtiers[[2]], "0"),
                                                    ifelse("3" %in% names(input_Jtiers), input_Jtiers[[3]], "0"),
                                                    ifelse("1" %in% names(output_Jtiers), output_Jtiers[[1]], "0"),
                                                    ifelse("2" %in% names(output_Jtiers), output_Jtiers[[2]], "0"),
                                                    ifelse("3" %in% names(output_Jtiers), output_Jtiers[[3]], "0"),
                                                    input_segs,
                                                    output_segs,
                                                    loose,
                                                    JaBba_Args$epgap,
                                                    fep,
                                                    ifelse(JaBba_Args$epgap > fep,"TRUE","FALSE"),
                                                    signif(as.vector(corr_sp$estimate), digits = 4),
                                                    signif(as.vector(corr_sp$p.value), digits = 4),
                                                    signif(as.vector(corr_pe$estimate), digits = 4),
                                                    signif(as.vector(corr_pe$p.value), digits = 4),
                                                    signif(rmse, digits = 4),
                                                    JaBba_Args$purity,
                                                    JaBba_Args$ploidy))

  # Save the QC stats table
  cli::cli_alert_info("Writing qc_stats.txt to {.file {jabba_workdir_path}} {crayon::white(clisymbols::symbol$ellipsis)}")
  data.table::fwrite(x = qc_stats_dt,
                     file = paste0(jabba_workdir_path, "qc_stats.txt"),
                     sep = "\t",
                     col.names = T)
  cli::cli_alert_success("Success")
  cat("\n")

  # Save the QC stats plots
  diagnostic_plot <- geom_jabba_stats(path_to_stats_dt = paste0(jabba_workdir_path, "qc_stats.txt"),
                                      karyograph_dt = data.table::data.table("cn" = kar$segstats$cn,
                                                                             "cnmle" = kar$segstats$cnmle))
  cli::cli_alert_success("Success")
  ggplot2::ggsave(filename = "qc_summary.png",
                  plot = diagnostic_plot,
                  path = jabba_workdir_path,
                  width = 300,
                  height = 300,
                  units = "mm",
                  device = "png")

  cli::cli_alert_success("QC summary finished")
  cli_stopwatch_end(package = "devgru",
                    function_name = "get_jabba_qc_diagnostic",
                    stopwatch_start = process_start)
}











# TODO: NEED TO MAKE SURE THIS WORKS
#' @name get_qc_diagnostics_alignment
#' @title Generate diagnostic plots for alignment QC checks using Alfred summary files
#'
#' @description
#' Single command to generate a comprehensive set of diagnostic plots that assist in
#' performing QC checks of tumor/normal read alignment of various sequencing protocol flavors
#' using Alfred summary files.
#'
#' @param path_to_tumor_dir Path to directory of tumor sample Alfred summary files
#' @param path_to_normal_dir Path to directory of normal sample Alfred summary files
#' @param seq_protocol Type of sequencing protocol for display purposes, default: WGS
#'
#' @returns Patchwork 'quilt'-like plot of ggplots
#' @export
get_qc_diagnostics_alignment <- function(path_to_tumor_dir = NULL, path_to_normal_dir = NULL, seq_protocol = "WGS") {

  # Set figure base theme
  ggplot2::theme_set(
    ggplot2::theme_gray() +
      ggplot2::theme(axis.line = ggplot2::element_line(linewidth = 0.5,  color = "black"),
                     panel.background = ggplot2::element_rect(fill = NA, linewidth = rel(14)),
                     panel.grid.minor = ggplot2::element_line(color = NA),
                     axis.text = ggplot2::element_text(size = 12,  color = "black"),
                     axis.title = ggplot2::element_text(size = 14),
                     axis.ticks = ggplot2::element_line(linewidth = 0.75),
                     title = ggplot2::element_text(size = 16)))

  # User provides paths to directory with T/N Alfred alignment QC summary files
  if(!is.null(path_to_tumor_dir) & !is.null(path_to_normal_dir)) {
    # Read in and aggregate the tumor/normal alfred QC summary files
    message("Aggregate input QC summary metrics ...")
    tumor_alfreds <- aggregate_these(path_to_files = path_to_tumor_dir,
                                     pattern_to_grab = "*.alfred.qc.summary.txt",
                                     delim = "\t",
                                     has_header = T,
                                     add_uniq_id = F)
    tumor_alfreds$tumor_normal <- "Tumor"
    message("Found ", dplyr::n_distinct(tumor_alfreds$Sample), " tumor samples ...")

    normal_alfreds <- aggregate_these(path_to_files = path_to_normal_dir,
                                      pattern_to_grab = "*.alfred.qc.summary.txt",
                                      delim = "\t",
                                      has_header = T,
                                      add_uniq_id = F)
    normal_alfreds$tumor_normal <- "Normal"
    message("Found ", dplyr::n_distinct(normal_alfreds$Sample), " normal samples ...")

  } else if(is.null(path_to_tumor_dir) & !is.null(path_to_normal_dir)) {
    stop(message = "Must provide path to directories of tumor and normal Alfred QC summary files ...")

  } else if(!is.null(path_to_tumor_dir) & is.null(path_to_normal_dir)) {
    stop(message = "Must provide path to directories of tumor and normal Alfred QC summary files ...")
  }

  # Sanity check if there is no match between normal/tumor samples
  message("Quick view of samples for sanity cross-check ...")
  paint::paint(df = data.frame("Tumor" = tumor_alfreds$Sample))
  paint::paint(df = data.frame("Normal" = normal_alfreds$Sample))

  # Combine the SNV+InDel QC metrics
  message("Merging tumor and normal alignment metrics ...")
  alfred_metrics <- gUtils::rrbind(tumor_alfreds, normal_alfreds)

  # boxplot of total mapped reads
  message("Generating diagnostic plots ...")
  fraction_fwd_rev_melt <- alfred_metrics %>%
                            dplyr::select(Sample, MappedForwardFraction, MappedReverseFraction, tumor_normal) %>%
                            reshape2::melt(id.vars = c("Sample", "tumor_normal"),
                                           value.name = "fraction",
                                           variable.name = "alignment_group")

  mapped_reads_plt <- ggplot2::ggplot(alfred_metrics) +
    ggplot2::geom_boxplot(ggplot2::aes(x = tumor_normal, y = Mapped, fill = tumor_normal), alpha = 0.6, width = 0.3) +
    ggplot2::scale_fill_manual(name = "Sample\nType", values = c("skyblue", "darkred")) +
    ggplot2::geom_jitter(ggplot2::aes(x = tumor_normal, y = Mapped, color = round(MappedProperFraction * 100, digits = 1)), alpha = 0.5, size = 3, width = 0.2) +
    ggplot2::scale_color_gradientn(name = "Percent\nMapped", colors = paletteer::paletteer_c("grDevices::Inferno", 10)) +
    ggplot2::scale_y_continuous(labels = scales::label_comma(scale = 1e-6),
                       limits = c(min(alfred_metrics$Mapped) - min(alfred_metrics$Mapped) * 0.10,
                                  max(alfred_metrics$Mapped) + max(alfred_metrics$Mapped) * 0.10),
                       expand = c(0.02,0.02)) +
    ggside::geom_xsidecol(data = fraction_fwd_rev_melt,
                          ggplot2::aes(x = tumor_normal, y = fraction, group = alignment_group),
                          position = "dodge", width = 0.5, just = 0.3,
                          fill = dplyr::case_when(fraction_fwd_rev_melt$alignment_group == "MappedForwardFraction" ~ "#009292",
                                           fraction_fwd_rev_melt$alignment_group == "MappedReverseFraction" ~ "#490092"), color = "black") +
    ggside::geom_xsidehline(yintercept = 0.45, color = "cyan") +
    ggside::scale_xsidey_continuous(labels = scales::label_percent()) +
    ggplot2::labs(x = NULL,
                  y = "Reads (millions)") +
    ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 0, vjust = 0.95, hjust = 0.5),
                   panel.border = ggplot2::element_rect(fill = NA),
                   ggside.panel.scale = .25) +
    ggplot2::annotate(geom = "text",
                      x = c(0.85, 1.15, 1.85, 2.15),
                      y = max(alfred_metrics$Mapped) + max(alfred_metrics$Mapped) * 0.10,
                      label = c("Fwd", "Rev", "Fwd", "Rev"),
                      color = c("#009292", "#490092","#009292", "#490092")) +
    ggplot2::annotate(geom = "text",
                      x = c(0.60, 2.40),
                      y = alfred_metrics %>%
                             dplyr::group_by(tumor_normal) %>%
                             dplyr::reframe(med_reads = stats::median(Mapped)) %>%
                             dplyr::select(med_reads) %>%
                             purrr::as_vector(),
                      label = round(alfred_metrics %>%
                                       dplyr::group_by(tumor_normal) %>%
                                       dplyr::reframe(med_reads = stats::median(Mapped)) %>%
                                       dplyr::select(med_reads) %>%
                                       purrr::as_vector() %>%
                                       as.numeric(),
                                    digits = -6) / 1e6)

  # boxplots of read fractions
  all_fractions <- data.table("group" = c("DuplicateFraction", "SecondaryAlignmentFraction", "SupplementaryAlignmentFraction", "UnmappedFraction"),
                              "Duplicate" = as.numeric(alfred_metrics$DuplicateFraction),
                              "Secondary" = as.numeric(alfred_metrics$SecondaryAlignmentFraction),
                              "Supplementary" = as.numeric(alfred_metrics$SupplementaryAlignmentFraction),
                              "Unmapped" = as.numeric(alfred_metrics$UnmappedFraction)) %>%
    reshape2::melt(id.vars = "group",
                   value.name = "fraction",
                   variable.name = "alignment_group")

  median_fractions_by_group <- all_fractions %>%
                                dplyr::group_by(alignment_group) %>%
                                dplyr::summarise(median_frac = stats::median(fraction))

  read_fracs_plt <- ggplot2::ggplot(data = all_fractions) +
    ggplot2::geom_boxplot(ggplot2::aes(x = alignment_group, y = fraction * 100, fill = alignment_group), alpha = 0.6, width = 0.4, outliers = F) +
    ggplot2::scale_fill_manual(name = "Alignment\nType", values = paletteer::paletteer_d("ggsci::hallmarks_light_cosmic")[1:5]) +
    ggplot2::geom_jitter(ggplot2::aes(x = alignment_group, y = fraction * 100, color = alignment_group), alpha = 0.4, size = 2.5, width = 0.3) +
    ggplot2::scale_color_manual(name = "Alignment\nType", values = paletteer::paletteer_d("ggsci::hallmarks_light_cosmic")[1:5]) +
    ggplot2::scale_y_continuous(expand = c(0.02,0.02)) +
    ggplot2::labs(x = NULL,
                  y = "Reads (%)") +
    ggplot2::theme(axis.text.x =  ggplot2::element_text(angle = 33, vjust = 0.60, hjust = 0.5, size = 9),
                    legend.position = "right",
                    panel.border =  ggplot2::element_rect(fill = NA))

  all_reads <- data.table("group" = c("DuplicateMarked", "SecondaryAlignments", "SupplementaryAlignments", "Unmapped"),
                          "Duplicate" = as.numeric(alfred_metrics$DuplicateMarked),
                          "Secondary" = as.numeric(alfred_metrics$SecondaryAlignments),
                          "Supplementary" = as.numeric(alfred_metrics$SupplementaryAlignments),
                          "Unmapped" = as.numeric(alfred_metrics$Unmapped)) %>%
    reshape2::melt(id.vars = "group",
                   value.name = "count",
                   variable.name = "alignment_group")

  median_fractions_by_group <- all_reads %>%
                                dplyr::group_by(alignment_group) %>%
                                dplyr::summarise(median_count = stats::median(as.numeric(count)))

  read_counts_plt <- ggplot2::ggplot(data = all_reads) +
    ggplot2::geom_col(data = median_fractions_by_group,
             ggplot2::aes(x = alignment_group, y = median_count, fill = alignment_group), alpha = 0.3, width = 0.4, color = "black") +
    ggplot2::scale_fill_manual(name = "Alignment\nType", values = paletteer::paletteer_d("ggsci::hallmarks_light_cosmic")[1:5]) +
    ggplot2::geom_jitter(ggplot2::aes(x = alignment_group, y = count, color = alignment_group), alpha = 0.4, size = 2.5, width = 0.3) +
    ggplot2::scale_color_manual(name = "Alignment\nType", values = paletteer::paletteer_d("ggsci::hallmarks_light_cosmic")[1:5]) +
    ggplot2::scale_y_reverse(labels = scales::label_comma(scale = 1e-6),expand = c(0.02,0.02)) +
    ggplot2::scale_x_discrete(position = "top") +
    ggplot2::labs(x = NULL,
                  y = "Reads (millions)") +
    ggplot2::theme(axis.text.x = ggplot2::element_blank(),
                   legend.position = "none",
                   panel.border = ggplot2::element_rect(fill = NA))

  # First combo plot of read metrics
  read_mets_plt <- patchwork::wrap_plots(list(read_fracs_plt, read_counts_plt), ncol = 1, guides = "collect")

  # Coverage
  coverage_dist_plt <- ggplot2::ggplot(alfred_metrics) +
    ggridges::stat_density_ridges(ggplot2::aes(x = MedianCoverage, y = tumor_normal, fill = 0.5 - abs(0.5 - ggplot2::after_stat(ecdf))),
                                  alpha = 0.5,
                                  calc_ecdf = TRUE,
                                  bandwidth = 3,
                                  geom = "density_ridges_gradient",
                                  scale = 2) +
    ggplot2::scale_fill_gradientn(name = "Tail prob.\nCoverage", colors = paletteer::paletteer_c("grDevices::Turku", n = 10)) +
    ggplot2::scale_x_continuous(expand = c(0.03,0.03), limits = c(min(alfred_metrics$MedianCoverage),max(alfred_metrics$MedianCoverage) + 5)) +
    ggside::geom_xsidepoint(ggplot2::aes(x = MedianCoverage, y = tumor_normal, color = tumor_normal),
                            position = "jitter", alpha = 0.5, show.legend = F, na.rm = T) +
    ggplot2::scale_color_manual(values = c("skyblue", "darkred")) +
    ggplot2::labs(x = "Coverage",
                  y = NULL) +
    ggplot2::theme(panel.border = ggplot2::element_rect(fill = NA))

  # Insert size distribution
  insert_dist_plt <- ggplot2::ggplot(alfred_metrics) +
    ggridges::stat_density_ridges(ggplot2::aes(x = MedianInsertSize, y = tumor_normal, fill = 0.5 - abs(0.5 - ggplot2::after_stat(ecdf))),
                                  alpha = 0.5,
                                  calc_ecdf = TRUE,
                                  bandwidth = 10,
                                  geom = "density_ridges_gradient",
                                  scale = 2) +
    ggplot2::scale_fill_gradientn(name = "Insert\nSize", colors = paletteer::paletteer_c("grDevices::Lajolla", n = 10)) +
    ggplot2::scale_x_continuous(expand = c(0.03,0.03), limits = c(min(alfred_metrics$MedianInsertSize),max(alfred_metrics$MedianInsertSize) + 5)) +
    ggside::geom_xsidepoint(ggplot2::aes(x = MedianInsertSize, y = tumor_normal, color = tumor_normal),
                            position = "jitter", alpha = 0.5, show.legend = F, na.rm = T) +
    ggplot2::scale_color_manual(values = c("skyblue", "darkred")) +
    ggplot2::labs(x = "Insert Size (bp)",
                  y = NULL) +
    ggplot2::theme(panel.border = ggplot2::element_rect(fill = NA),
                    axis.text.y = ggplot2::element_blank())

  # Second combo plot of coverage and insert size distribution
  cov_insrt_plt <- patchwork::wrap_plots(list(coverage_dist_plt, insert_dist_plt), ncol = 2, nrow = 1, guides = "collect")

  # Text table of summary metrics
  # TODO: add outlier sample flagging
  tumor_table_metrics <- alfred_metrics %>% dplyr::filter(tumor_normal == "Tumor")
  normal_table_metrics <- alfred_metrics %>% dplyr::filter(tumor_normal == "Normal")
  outtable <- data.table(placeholder = c("Tumor", "Normal"),
                         "Coverage" = c(stringr::str_c(round(mean(tumor_table_metrics$MedianCoverage), digits = 1), " (", range(tumor_table_metrics$MedianCoverage)[1], "-", range(tumor_table_metrics$MedianCoverage)[2], ")"),
                                        stringr::str_c(round(mean(normal_table_metrics$MedianCoverage), digits = 1), " (", range(normal_table_metrics$MedianCoverage)[1], "-", range(normal_table_metrics$MedianCoverage)[2], ")")),
                         "Insert Size" = c(stringr::str_c(round(mean(tumor_table_metrics$MedianInsertSize), digits = 1), " (", range(tumor_table_metrics$MedianInsertSize)[1], "-", range(tumor_table_metrics$MedianInsertSize)[2], ")"),
                                           stringr::str_c(round(mean(normal_table_metrics$MedianInsertSize), digits = 1), " (", range(normal_table_metrics$MedianInsertSize)[1], "-", range(normal_table_metrics$MedianInsertSize)[2], ")")),
                         "Read Length" = c(stringr::str_split(string = unique(tumor_table_metrics$MedianReadLength), pattern = ":",simplify = T)[,1],
                                           stringr::str_split(string = unique(normal_table_metrics$MedianReadLength), pattern = ":",simplify = T)[,1]))
  colnames(outtable)[1] <- paste0(seq_protocol, " mean(range)")
  metrics_summary_table <- ggpubr::ggtexttable(t(outtable), theme = ggpubr::ttheme("light"))

  # Histograms of target bed mapped fraction, insertion and deletion detection rate
  target_frac_plt <- ggplot2::ggplot(alfred_metrics) +
    ggplot2::geom_histogram(ggplot2::aes(x = FractionCovered, group = tumor_normal, fill = tumor_normal),
                            position = "dodge", binwidth = 0.05,  color = "black", alpha = 0.6) +
    ggplot2::scale_x_continuous(limits = c(0,1), expand = c(0.02,0.02), breaks = scales::breaks_width(width = 0.1)) +
    ggplot2::scale_y_continuous(expand = c(0.02,0.02)) +
    ggplot2::scale_fill_manual(values = c("skyblue", "darkred")) +
    ggplot2::labs(x = "Fraction of target covered",
                  y = "Count of samples per bin") +
    ggplot2::theme(panel.border = ggplot2::element_rect(fill = NA),
                   legend.position = "none")

  ins_rate_plt <- ggplot2::ggplot(alfred_metrics) +
    ggplot2::geom_histogram(ggplot2::aes(x = InsertionRate, group = tumor_normal, fill = tumor_normal),
                   position = "stack", binwidth = 0.000005, color = "black", alpha = 0.6) +
    ggplot2::scale_y_continuous(expand = c(0.02,0.02)) +
    ggplot2::scale_fill_manual(values = c("skyblue", "darkred")) +
    ggplot2::labs(x = "Insertion rate",
                  y = "Count of samples per bin") +
    ggplot2::theme(panel.border = ggplot2::element_rect(fill = NA),
                   legend.position = "none")

  del_rate_plt <- ggplot2::ggplot(alfred_metrics) +
    ggplot2::geom_histogram(ggplot2::aes(x = DeletionRate, group = tumor_normal, fill = tumor_normal),
                            position = "stack", binwidth = 0.000005, color = "black", alpha = 0.6) +
    ggplot2::scale_y_continuous(expand = c(0.02,0.02)) +
    ggplot2::scale_fill_manual(values = c("skyblue", "darkred")) +
    ggplot2::labs(x = "Deletion rate",
                  y = "Count of samples per bin") +
    ggplot2::theme(panel.border = ggplot2::element_rect(fill = NA),
                   legend.position = "none")

  # Third combo plot of histograms
  hist_combo_plot <- target_frac_plt / ins_rate_plt / del_rate_plt + patchwork::plot_layout(axes = "collect_y")

  # Final quilt plot of all QC plots
  read_combo_plt <- (patchwork::plot_spacer() + metrics_summary_table + patchwork::plot_spacer()) / (mapped_reads_plt + hist_combo_plot + read_mets_plt) / cov_insrt_plt + patchwork::plot_layout(ncol = 1, nrow = 3, heights = c(0.66, 1, 1))
  return(read_combo_plt)
}


# TODO: NEED TO MAKE SURE THIS WORKS
#' @name get_qc_diagnostics_snvindel
#' @title Generate diagnostic plots for SNV & InDel variant calling QC checks
#'
#' @description
#' Single command to generate a comprehensive set of diagnostic plots that assist in
#' performing QC checks of SNVs & InDels called from MGP1000 using union consensus.
#' Can be used as both a first pass of unfiltered variants to see consensus skew as
#' well as used after filtering to show changes in calling metrics.
#'
#' @param path_to_snv_dir Path to directory of MGP1000 union consensus SNVs
#' @param path_to_indel_dir Path to directory of MGP1000 union consensus InDels
#' @param snv_indel_obj Data.table object with merged SNVs & InDels, used in place of paths to directories
#' @param plot_sample_names Output plots to include sample names on y-axis, default: TRUE
#' @param include_caveman Add caveman to consensus list if used in SNV variant calling, default: FALSE
#'
#' @returns Patchwork 'quilt'-like plot of ggplots
#' @export
get_qc_diagnostics_snvindel <- function(path_to_snv_dir = NULL, path_to_indel_dir = NULL, snv_indel_obj = NULL, plot_sample_names = T, include_caveman = F) {

  # Set figure base theme
  ggplot2::theme_set(
    ggplot2::theme_gray() +
      ggplot2::theme(axis.line = ggplot2::element_line(linewidth = 0.5,  color = "black"),
                     panel.background = ggplot2::element_rect(fill = NA, linewidth = rel(14)),
                     panel.grid.minor = ggplot2::element_line(color = NA),
                     axis.text = ggplot2::element_text(size = 12,  color = "black"),
                     axis.title = ggplot2::element_text(size = 14),
                     axis.ticks = ggplot2::element_line(linewidth = 0.75),
                     title = ggplot2::element_text(size = 16)))

  # User provides either paths to directory with SNVs and InDel or a single DT obj with both SNV+InDels
  if(!is.null(path_to_snv_dir) & !is.null(path_to_indel_dir) & is.null(snv_indel_obj)) {
    # Aggregate all SNV and InDel union-consensus files
    message("Aggregate input mutations ...")
    snvs <- aggregate_these(path_to_files = path_to_snv_dir,
                            pattern_to_grab = "*.hq.union.consensus.somatic.snv.txt.gz",
                            delim = "\t",
                            has_header = T,
                            cpus = 1,
                            add_uniq_id = F)

    indels <- aggregate_these(path_to_files = path_to_indel_dir,
                              pattern_to_grab = "*.hq.union.consensus.somatic.indel.txt.gz",
                              delim = "\t",
                              has_header = T,
                              cpus = 1,
                              add_uniq_id = F)

    # If user already aggregated, split DT obj into SNVs and InDels
  } else if(is.null(path_to_snv_dir) & is.null(path_to_indel_dir) & !is.null(snv_indel_obj)) {
    # Aggregate all SNV and InDel union-consensus files
    message("Read in aggregated mutations ...")
    snvs <- snv_indel_obj %>% dplyr::filter(stringr::str_length(REF) == 1 & stringr::str_length(ALT) == 1)
    indels <- dplyr::setdiff(x = snv_indel_obj, y = snvs)

  } else {
    stop(message = "Must provide either path to directories of SNVs and InDels or SNV+InDel aggregated data.table ...")
  }

  # Get count of all SNVs and InDels per sample by caller
  message("Counting mutations per sample by caller ...")
  snvs_by_caller <- snvs %>%
    dplyr::group_by(SAMPLE) %>%
    dplyr::count(CALLER) %>%
    dplyr::ungroup() %>%
    dplyr::mutate(total_snvs = sum(n)) %>%
    dplyr::arrange(dplyr::desc(total_snvs))

  indels_by_caller <- indels %>%
    dplyr::group_by(SAMPLE) %>%
    dplyr::count(CALLER) %>%
    dplyr::ungroup() %>%
    dplyr::mutate(total_indels = sum(n)) %>%
    dplyr::arrange(dplyr::desc(total_indels))

  # Factor the caller list for consistent plotting
  if(include_caveman) {
    snv_caller_levels <- c("caveman","mutect","strelka","varscan",
                           "caveman,mutect","caveman,strelka","caveman,varscan",
                           "mutect,strelka","mutect,varscan","strelka,varscan",
                           "caveman,mutect,strelka","caveman,mutect,varscan",
                           "caveman,strelka,varscan","mutect,strelka,varscan",
                           "caveman,mutect,strelka,varscan")
  } else if(!include_caveman) {
    snv_caller_levels <- c("mutect","strelka","varscan",
                           "mutect,strelka", "mutect,varscan","strelka,varscan",
                           "mutect,strelka,varscan")
  }

  snvs_by_caller$CALLER <- factor(snvs_by_caller$CALLER,
                                  levels = snv_caller_levels)

  indels_by_caller$CALLER <- factor(indels_by_caller$CALLER,
                                    levels = c("mutect","strelka","svaba","varscan",
                                               "mutect,strelka","mutect,svaba","mutect,varscan",
                                               "strelka,svaba","strelka,varscan","svaba,varscan",
                                               "mutect,strelka,svaba","mutect,strelka,varscan","mutect,svaba,varscan",
                                               "strelka,svaba,varscan","mutect,strelka,svaba,varscan"))

  # Build SNVs per sample by caller plot
  message("Generating diagnostic plots ...")
  snvs_per_sample_by_caller <- ggplot2::ggplot(snvs_by_caller) +
    ggplot2::geom_col(ggplot2::aes(x = SAMPLE, y = n, fill = CALLER), position = "stack") +
    ggplot2::scale_fill_manual(name = "Callers", values = paletteer::paletteer_d("ggsci::default_jama")) +
    ggplot2::scale_y_reverse(expand = c(0.01,0.01), labels = scales::label_comma()) +
    ggplot2::scale_x_discrete(position = "top") +
    ggplot2::coord_flip() +
    ggplot2::labs(title = "SNVs",
         x = NULL,
         y = "Count") +
    ggplot2::theme(legend.position = "left",
                    plot.title = ggplot2::element_text(hjust = 0.5),
                    panel.border = ggplot2::element_rect(fill = NA),
                    legend.key.size = ggplot2::unit("1.5", "mm"),
                    legend.title = ggplot2::element_text(size = 11))
  # Sample names or not on Y axis
  if(plot_sample_names) {
    snvs_per_sample_by_caller <- snvs_per_sample_by_caller + ggplot2::theme(axis.text.y = element_text(size = 8))

  } else if(!plot_sample_names) {
    snvs_per_sample_by_caller <- snvs_per_sample_by_caller + ggplot2::theme(axis.text.y = element_blank())
  }

  # Build counts of total by caller
  caller_by_snvs <- ggplot2::ggplot(data = snvs_by_caller %>%
                                             dplyr::group_by(CALLER) %>%
                                             dplyr::summarise(total_per_caller = round((sum(n) / sum(snvs_by_caller$n)) * 100, digits = 1)),
                                    ggplot2::aes(x = CALLER, y = total_per_caller, fill = CALLER, label = total_per_caller)) +
                    ggplot2::geom_col() +
                    ggfittext::geom_bar_text(min.size = 1) +
                    ggplot2::scale_fill_manual(name = "Callers", values = paletteer::paletteer_d("ggsci::default_jama")) +
                    ggplot2::scale_y_reverse(expand = c(0.02,0.02), labels = scales::label_percent(scale = 1), position = "right") +
                    ggplot2::scale_x_discrete(position = "top") +
                    ggplot2::labs(x = "Percentage of\ncalled mutations",
                                  y = NULL) +
                    ggplot2::theme(axis.text.x = ggplot2::element_blank(),
                                    axis.ticks.x.top = ggplot2::element_blank(),
                                    legend.position = "none",
                                    panel.border = ggplot2::element_rect(fill = NA))

  # Build InDels per sample by caller plot
  indels_per_sample_by_caller <- ggplot2::ggplot(indels_by_caller) +
    ggplot2::geom_col(ggplot2::aes(x = SAMPLE, y = n, fill = CALLER), position = "stack") +
    ggplot2::scale_fill_manual(name = "Callers", values = paletteer_d("colorBlindness::paletteMartin")) +
    ggplot2::scale_y_continuous(expand = c(0.01,0.01), labels = scales::label_comma(), position = "left") +
    ggplot2::scale_x_discrete(position = "bottom") +
    ggplot2::coord_flip() +
    ggplot2::labs(title = "InDels",
                   x = NULL,
                   y = "Count") +
    ggplot2::theme(legend.position = "right",
                    plot.title = ggplot2::element_text(hjust = 0.5),
                    axis.text.y = ggplot2::element_blank(),
                    panel.border = ggplot2::element_rect(fill = NA),
                    legend.key.size = ggplot2::unit("1.5", "mm"),
                    legend.title = ggplot2::element_text(size = 11))

  # Build counts of total by caller
  caller_by_indels <- ggplot2::ggplot(data = indels_by_caller %>%
                                               dplyr::group_by(CALLER) %>%
                                               dplyr::summarise(total_per_caller = round((sum(n) / sum(indels_by_caller$n)) * 100, digits = 1)),
                                      ggplot2::aes(x = CALLER, y = total_per_caller, fill = CALLER, label = total_per_caller)) +
                        ggplot2::geom_col() +
                        ggfittext::geom_bar_text(min.size = 1) +
                        ggplot2::scale_fill_manual(name = "Callers", values = paletteer::paletteer_d("colorBlindness::paletteMartin")) +
                        ggplot2::scale_y_reverse(expand = c(0.02,0.02), labels = scales::label_percent(scale = 1), position = "left") +
                        ggplot2::scale_x_discrete(position = "top") +
                        ggplot2::labs(x = "Percentage of\ncalled mutations",
                                      y = NULL) +
                        ggplot2::theme(axis.text.x = ggplot2::element_blank(),
                                        axis.ticks.x.top = ggplot2::element_blank(),
                                        legend.position = "none",
                                        panel.border = ggplot2::element_rect(fill = NA))

  # Final combo QC diagnostic plot
  snvindel_qc_diagnostic_plot <- (snvs_per_sample_by_caller / caller_by_snvs) | (indels_per_sample_by_caller / caller_by_indels)
  return(snvindel_qc_diagnostic_plot)
}






#' @name get_vaf
#' @title Quick pull or explicitly calculate the VAF for mutation records of various flavors
#'
#' @description
#' Given a data.table or GenomicRanges VCF object, quickly extract or explicitly calculate the VAF for all mutations.
#' For clarity, the read support for the VAF will be extracted as well.
#' Currently supports somatic SNV/InDel VCFs from Mutect, Strelka, Varscan, SvABA, CaVEMan.
#'
#' @param vcf_obj VCF file in data.table or GenomicRanges format
#' @param caller Name of the caller that generated input VCF to be converted, supported: mutect, strelka, varscan, svaba, caveman
#' @param mut_type Type of mutations within VCF, supported: snv, indel
#'
#' @returns data.table object with read support and VAF per record
#' @export
get_vaf <- function(vcf_obj, caller, mut_type) {

  # First, check the VCF object. If data.table, continue on. If not, convert
  if(!"data.table" %in% class(vcf_obj) & "GRanges" %in% class(vcf_obj)) {
    mut_records <- gUtils::gr2dt(vcf_obj)

  } else if("data.table" %in% class(vcf_obj)) {
    mut_records <- vcf_obj

  } else {
    # Problem if input VCF object is not correct class
    stop(message = "\nInput VCF object needs to be either data.table or GRanges class")
  }

  if(caller == "mutect") {
    # Mutect SNVs and InDels
    # VAF is reported as AF ["Allele fractions of alternate alleles in the tumor"]
    # ALT depth is reported as AD ["Allelic depths for the ref and alt alleles in the order listed"]
    # Total depth is reported as DP ["Approximate read depth (reads with MQ=255 or with bad mates are filtered)"]
    mut_alt_depth <- mut_records[, AD_ALT_TUMOR]
    mut_total_depth <- mut_records[, DP_TUMOR]
    mut_vaf <- round(mut_records[, AF_TUMOR], digits = 4)

  } else if(caller == "varscan") {
    # VarScan SNVs and InDels
    # VAF is reported as FREQ ["Variant allele frequency"]
    # ALT depth is reported as AD ["Depth of variant-supporting bases (reads2)"]
    # Total depth is reported as DP ["Read Depth"]
    mut_alt_depth <- mut_records[, AD_TUMOR]
    mut_total_depth <- mut_records[, DP_TUMOR]
    mut_vaf <- round(as.numeric(stringr::str_remove(string = mut_records[, FREQ_TUMOR], pattern = "%")) / 100, digits = 4)

  } else if(caller == "strelka" & mut_type == "snv") {
    # Strelka SNVs
    # Does not directly report VAF
    # ALT depth is reported as read support per nucleotide tier AU, CU, TU, GU ["Number of 'A/C/G/T' alleles used in tiers 1,2"]
    # Total depth is reported as depth DP ["Read depth for tier1 (used+filtered)"]
    # The VAF will be calculated as: [AU_TIER1, CU_TIER1, TU_TIER1, GU_TIER1] / DP

    # To get the correct ALT depth, need to loop through the records to build
    mut_alt_depth <- rep(NA, nrow(mut_records))
    mut_total_depth <- mut_records[, DP_TUMOR]
    mut_vaf <- rep(NA, nrow(mut_records))

    for(i in 1:nrow(mut_records)) {
      # Get the ALT depth
      mut_alt_depth[i] <- as.data.frame(mut_records[i,])[,colnames(mut_records[i,]) == paste0(mut_records$ALT[i], "U_TIER1_TUMOR")]

      # Calculate the VAF
      mut_vaf[i] <- round(mut_alt_depth[i] / mut_total_depth[i], digits = 4)
    }

  } else if(caller == "strelka" & mut_type == "indel") {
    # Strelka InDels
    # Does not directly report VAF
    # ALT depth is reported as indel tier read support TIR ["Reads strongly supporting indel allele for tiers 1,2"]
    # Total depth is reported as depth DP ["Read depth for tier1 (used+filtered)"]
    # The VAF will be calculated as: TIR_TIER1 / DP
    mut_alt_depth <- mut_records[, TIR_TIER1_TUMOR]
    mut_total_depth <- mut_records[, DP_TUMOR]
    mut_vaf <- round(mut_alt_depth / mut_total_depth, digits = 4)

  } else if(caller == "svaba" & mut_type == "indel") {
    # SvABA InDels
    # Does not directly report VAF
    # ALT depth is reported as allele depth AD ["Allele depth: Number of reads supporting the variant"]
    # Total depth is reported as depth DP ["Depth of coverage: Number of reads covering site."]
    # The VAF will be calculated as: AD / DP
    mut_alt_depth <- mut_records[, AD_TUMOR]
    mut_total_depth <- mut_records[, DP_TUMOR]
    mut_vaf <- round(mut_alt_depth / mut_total_depth, digits = 4)

  } else if(caller == "caveman" & mut_type == "snv") {
    # CaVEMan SNVs
    # VAF is reported as proportion of mut allele PM ["Proportion of mutant allele presenting reads (ALT field) seen by CaVEMan"]
    # ALT depth is reported as read support per nucleotide per strand FAZ, FCZ, FGZ, FTZ, RAZ, RCZ, RGZ, RTZ
    # Total depth is not directly reported

    # To get the correct ALT and total depth, need to loop through the records to build
    mut_alt_depth <- rep(NA, nrow(mut_records))
    mut_total_depth <- rep(NA, nrow(mut_records))
    mut_vaf <- mut_records[, PM_TUMOR]

    for(i in 1:nrow(mut_records)) {
      # Get all nucleotide read depth on both strands
      fwd_alt_depth <- as.data.frame(mut_records[i,])[,colnames(mut_records[i,]) == paste0("F", mut_records$ALT[i], "Z_TUMOR")]
      rev_alt_depth <- as.data.frame(mut_records[i,])[,colnames(mut_records[i,]) == paste0("R", mut_records$ALT[i], "Z_TUMOR")]
      fwd_ref_depth <- as.data.frame(mut_records[i,])[,colnames(mut_records[i,]) == paste0("F", mut_records$REF[i], "Z_TUMOR")]
      rev_ref_depth <- as.data.frame(mut_records[i,])[,colnames(mut_records[i,]) == paste0("R", mut_records$REF[i], "Z_TUMOR")]

      # Calculate the ALT and total read depth
      mut_alt_depth[i] <- sum(fwd_alt_depth, rev_alt_depth)
      mut_total_depth[i] <- sum(fwd_alt_depth, rev_alt_depth, fwd_ref_depth, rev_ref_depth)
    }

  } else {
    # Problem if there is no proper combo of caller and mut_type
    stop(message = "\ncaller and mut_type provided do not match possible combos. See function description")
  }

  # Create final DT of read depth and VAF for each mutation record
  mut_vaf_and_reads <- data.table(alt_depth = mut_alt_depth,
                                  total_depth = mut_total_depth,
                                  vaf = mut_vaf)

  # Output the VAF for the mutation record
  return(mut_vaf_and_reads)
}


#' @name get_maf_lite
#' @title Convert SNV & InDel mutation table to MAF-lite format
#'
#' @description
#' Read in multiple MGP1000 union consensus SNV & InDel mutation tables, filter based on consensus threshold
#' or sample/gene, merge all tables, calculate VAF, and prepare for downstream use in maf2maf or maf2vcf.
#' The bare minimum for a MAF is Chromosome, Start_Position, Reference_Allele, Tumor_Seq_Allele2, Tumor_Sample_Barcode
#' but will also include Matched_Norm_Sample_Barcode.
#'
#' @param path_to_snv_dir Path to directory of MGP1000 union consensus SNVs
#' @param path_to_indel_dir Path to directory of MGP1000 union consensus InDels
#' @param snv_consensus_filter Threshold consensus filter for SNVs
#' @param indel_consensus_filter Threshold consensus filter for InDels
#' @param strict_samples Samples that will be filtered with `*_consensus_filter``+1`
#' @param discovery_genes Gene set vector used for discovery with `*_consensus_filter``=0`
#' @param return_type Output either the converted maf-lite format table or data.table of standard format mutation table, supported: maf.lite, data.table
#'
#' @returns data.table like in either maf-lite or standard format
#' @export
get_maf_lite <- function(path_to_snv_dir, path_to_indel_dir, snv_consensus_filter = 2, indel_consensus_filter = 2,
                         strict_samples = NULL, discovery_genes = NULL, return_type = "maf.lite") {

  # First, check if return type is properly set
  if(!return_type %in% c("maf.lite", "data.table")) {
    stop(message = "\nInvalid return type, please specify either 'maf.lite' or 'data.table'")
  }

  # Aggregate all SNV and InDel union-consensus files
  # Perform sanity checks on patients and samples
  message("Aggregate input mutations ...")
  snvs <- aggregate_these(path_to_files = path_to_snv_dir,
                          pattern_to_grab = "*.hq.union.consensus.somatic.snv.txt.gz",
                          delim = "\t",
                          has_header = T,
                          cpus = 1,
                          add_uniq_id = F)
  message("Found ", dplyr::n_distinct(snvs$SAMPLE), " samples from ", dplyr::n_distinct(snvs$PATIENT), " patients with SNVs ...")

  indels <- aggregate_these(path_to_files = path_to_indel_dir,
                            pattern_to_grab = "*.hq.union.consensus.somatic.indel.txt.gz",
                            delim = "\t",
                            has_header = T,
                            cpus = 1,
                            add_uniq_id = F)
  message("Found ", dplyr::n_distinct(indels$SAMPLE), " samples from ", dplyr::n_distinct(indels$PATIENT), " patients with InDels ...")

  # Sanity check if there is no overlap in samples/patients or if there is a missing sample/patient
  if(length(dplyr::setdiff(x = indels$SAMPLE, y = snvs$SAMPLE)) == 0) {
    message("No difference in set of samples between SNVs and InDels ...")

  } else if(length(dplyr::setdiff(x = indels$SAMPLE, y = snvs$SAMPLE)) > 0) {
    message("Warning: Detected ", length(dplyr::setdiff(x = indels$SAMPLE, y = snvs$SAMPLE)), " samples in InDel sample set NOT in SNV sample set ...")
    setdiff_samples <- indels$SAMPLE[which(!indels$SAMPLE %in% unique(snvs$SAMPLE))]
    paint::paint(df = data.frame("Missing_Samples" = setdiff_samples))
    message("Recommend inspection ...")
  }

  # Now filter the data based on desired conditions
  message("Beginning filtering for high-quality variants ...")
  hq_snvs <- NULL
  hq_indels <- NULL

  # Standard consensus filtering, no special cases
  if(is.null(strict_samples) & is.null(discovery_genes)) {
    message("Maintaining SNVs with consensus >= ", snv_consensus_filter,  " ...")
    message("Maintaining InDels with consensus >= ", indel_consensus_filter,  " ...")

    hq_snvs <- snvs %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= snv_consensus_filter - 1)
    hq_indels <- indels %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= indel_consensus_filter - 1)

    # Standard consensus filtering, plus special case to keep all muts for genes of interest
  } else if(is.null(strict_samples) & !is.null(discovery_genes)) {
    message("Maintaining SNVs with consensus >= ", snv_consensus_filter,  " ...")
    message("Maintaining InDels with consensus >= ", indel_consensus_filter,  " ...")
    message("Special case filter to maintain all calls for genes of interest ...")
    paint::paint(df = data.frame("Discovery_Genes" = discovery_genes))

    consensus_non_discovery_snvs <- snvs %>%
      dplyr::filter(!nearest_gene %in% discovery_genes) %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= snv_consensus_filter - 1)
    discovery_gene_snvs <- snvs %>%
      dplyr::filter(nearest_gene %in% discovery_genes)
    hq_snvs <- gUtils::rrbind(consensus_non_discovery_snvs, discovery_gene_snvs)

    consensus_non_discovery_indels <- indels %>%
      dplyr::filter(!nearest_gene %in% discovery_genes) %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= indel_consensus_filter - 1)
    discovery_gene_indels <- indels %>%
      dplyr::filter(nearest_gene %in% discovery_genes)
    hq_indels <- gUtils::rrbind(consensus_non_discovery_indels, discovery_gene_indels)

    # Standard consensus filtering, plus special case to strictly filter specific samples
  } else if(!is.null(strict_samples) & is.null(discovery_genes)) {
    message("Maintaining SNVs with consensus >= ", snv_consensus_filter,  " ...")
    message("Maintaining InDels with consensus >= ", indel_consensus_filter,  " ...")
    message("Special case filter to strictly filter specific samples with +1 to consensus filters ...")
    paint::paint(df = data.frame("Strict_Samples" = strict_samples))

    consensus_non_strict_snvs <- snvs %>%
      dplyr::filter(!SAMPLE %in% strict_samples) %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= snv_consensus_filter - 1)
    strict_sample_snvs <- snvs %>%
      dplyr::filter(SAMPLE %in% strict_samples) %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= snv_consensus_filter)
    hq_snvs <- gUtils::rrbind(consensus_non_strict_snvs, strict_sample_snvs)

    consensus_non_strict_indels <- indels %>%
      dplyr::filter(!SAMPLE %in% strict_samples) %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= indel_consensus_filter - 1)
    strict_sample_indels <- indels %>%
      dplyr::filter(SAMPLE %in% strict_samples) %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= indel_consensus_filter)
    hq_indels <- gUtils::rrbind(consensus_non_strict_indels, strict_sample_indels)

    # Standard consensus filtering, plus special case to keep all muts for genes of interest and to strictly filter specific samples
  } else if(!is.null(strict_samples) & !is.null(discovery_genes)) {
    message("Maintaining SNVs with consensus >= ", snv_consensus_filter,  " ...")
    message("Maintaining InDels with consensus >= ", indel_consensus_filter,  " ...")
    message("Special case filter to maintain all calls for genes of interest ...")
    paint::paint(df = data.frame("Discovery_Genes" = discovery_genes))
    message("Special case filter to strictly filter specific samples with +1 to consensus filters ...")
    paint::paint(df = data.frame("Strict_Samples" = strict_samples))

    consensus_non_discovery_strict_snvs <- snvs %>%
      dplyr::filter(!SAMPLE %in% strict_samples) %>%
      dplyr::filter(!nearest_gene %in% discovery_genes) %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= snv_consensus_filter - 1)
    discovery_gene_snvs <- snvs %>%
      dplyr::filter(!SAMPLE %in% strict_samples) %>%
      dplyr::filter(nearest_gene %in% discovery_genes)
    strict_sample_snvs <- snvs %>%
      dplyr::filter(SAMPLE %in% strict_samples) %>%
      dplyr::filter(!nearest_gene %in% discovery_genes) %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= snv_consensus_filter)
    hq_snvs <- gUtils::rrbind(consensus_non_discovery_strict_snvs, discovery_gene_snvs, strict_sample_snvs)

    consensus_non_discovery_strict_indels <- indels %>%
      dplyr::filter(!SAMPLE %in% strict_samples) %>%
      dplyr::filter(!nearest_gene %in% discovery_genes) %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= indel_consensus_filter - 1)
    discovery_gene_indels <- indels %>%
      dplyr::filter(!SAMPLE %in% strict_samples) %>%
      dplyr::filter(nearest_gene %in% discovery_genes)
    strict_sample_indels <- indels %>%
      dplyr::filter(SAMPLE %in% strict_samples) %>%
      dplyr::filter(!nearest_gene %in% discovery_genes) %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= indel_consensus_filter)
    hq_indels <- gUtils::rrbind(consensus_non_discovery_strict_indels, discovery_gene_indels, strict_sample_indels)
  }

  # Combine HQ SNVs and InDels
  message("Filter complete, merging to single SNV+InDel DT ...")
  hq_muts <- gUtils::rrbind(hq_snvs, hq_indels)

  # Calculate the read depth information for the MAF-like file
  message("Calculate VAF for normal samples ...")

  # Edge Case: Strelka does not directly report AD for SNVs so it will be determined for normal as [AU_TIER1, CU_TIER1, TU_TIER1, GU_TIER1]
  # However, AD is output for InDels as TIR_TIER1_NORMAL
  strelka_normal_alt_depth <- rep(NA, nrow(hq_muts))
  # To get the correct ALT depth, need to loop through the records and differentiate between SNVs and InDels
  for(i in 1:nrow(hq_muts)) {
    # Check if SNV or InDel
    if(stringr::str_length(hq_muts$ALT[i]) == 1 & stringr::str_length(hq_muts$REF[i]) == 1) {
      strelka_normal_alt_depth[i] <- as.data.frame(hq_muts[i,])[,colnames(hq_muts[i,]) == paste0("STRELKA_", hq_muts$ALT[i], "U_TIER1_NORMAL")]
    } else {
      strelka_normal_alt_depth[i] <-  hq_muts$STRELKA_TIR_TIER1_NORMAL[i]
    }
  }
  # Now add calculated Strelka normal ALT depth to mutation table
  hq_muts$STRELKA_alt_depth_normal <- strelka_normal_alt_depth

  normal_read_colnames <- which(c("MUTECT_DP_NORMAL", "STRELKA_DP_NORMAL", "VARSCAN_DP_NORMAL", "SVABA_DP_NORMAL") %in% colnames(hq_muts))
  normal_read_metrics <- hq_muts %>%
    dplyr::select(c("MUTECT_DP_NORMAL", "STRELKA_DP_NORMAL", "VARSCAN_DP_NORMAL", "SVABA_DP_NORMAL")[normal_read_colnames])
  dp_mean <- round(rowMeans(x = normal_read_metrics, na.rm = T), digits = 0)

  alt_read_colnames <- which(c("MUTECT_AD_ALT_NORMAL","STRELKA_alt_depth_normal", "VARSCAN_AD_NORMAL", "SVABA_AD_NORMAL") %in% colnames(hq_muts))
  alt_read_metrics <- hq_muts %>%
    dplyr::select(c("MUTECT_AD_ALT_NORMAL","STRELKA_alt_depth_normal", "VARSCAN_AD_NORMAL", "SVABA_AD_NORMAL")[alt_read_colnames])
  alt_mean <- round(rowMeans(x = alt_read_metrics, na.rm = T), digits = 0)

  ref_mean <- dp_mean - alt_mean

  # Now build the MAF-like DT for conversion with maftools
  hq_muts_maf_lite_dt <- data.table::data.table("Chromosome" = hq_muts$seqnames,
                                                "Start_Position" = hq_muts$start,
                                                "Reference_Allele" = hq_muts$REF,
                                                "Tumor_Seq_Allele2" = hq_muts$ALT,
                                                "Tumor_Sample_Barcode" = hq_muts$TUMOR,
                                                "Matched_Norm_Sample_Barcode" = hq_muts$NORMAL,
                                                "Tumor_Total_Read_Depth" = hq_muts$total_depth_mean,
                                                "Tumor_Variant_Allele_Depth" = hq_muts$alt_read_depth_mean,
                                                "Tumor_Reference_Allele_Depth" = hq_muts$total_depth_mean - hq_muts$alt_read_depth_mean,
                                                "Normal_Total_Read_Depth" = dp_mean,
                                                "Normal_Variant_Read_Depth" = alt_mean,
                                                "Normal_Reference_Allele_Depth" = ref_mean)
  # Final output
  if(return_type == "maf.lite") {
    message("MAF-lite generated ...")
    paint::paint(hq_muts_maf_lite_dt)
    return(hq_muts_maf_lite_dt)

  # return the non-transformed post-filtered mutation table for QC
  } else if(return_type == "data.table") {
    message("Mutation table generated ...")
    paint::paint(hq_muts)
    return(hq_muts)
  }
}


#' @name get_corrected_cnv_profile
#' @title Read in CNV profile data.table of various flavors and extract a corrected profile
#'
#' @description
#' Given a data.table or GenomicRanges CNV object, extract the corrected CNV profile.
#' Any segment with a non-rounded value within 0.2 of the next integer value is rounded to that value.
#' The output will data.table will contain 6 columns: sample, seqnames, start, end, total, minor
#' The `sample` is either user-provided or row count placeholder
#' Currently supports CNV calls from Battenberg and FACETS
#'
#' @param cnv_obj CNV file in data.table or GenomicRanges format
#' @param caller Name of caller that generated input CNV to be converted, supported: Battenberg and FACETS
#' @param sample_id Unique identifier to add to output, default: NULL
#'
#' @returns data.table object with corrected CNV segments
#' @export
get_corrected_cnv_profile <- function(cnv_obj, caller, sample_id = NULL) {

  # First, check the CNV object. If data.table, continue on. If not, convert
  if(!"data.table" %in% class(cnv_obj) & "GRanges" %in% class(cnv_obj)) {
    cnv_dt <- gUtils::gr2dt(cnv_obj)

  } else if("data.table" %in% class(cnv_obj)) {
    cnv_dt <- cnv_obj

  } else {
    # Problem if input CNV object is not correct class
    stop(message = "\nInput CNV object needs to be either data.table or GRanges class")
  }

  # Create ID string for sample column
  sample_string <- dplyr::case_when(is.null(sample_id) ~ paste0("sample_X_", caller),
                                    !is.null(sample_id) ~ as.character(sample_id))

  # Case 1: FACETS directly reports total and minor copy number,
  #         only consideration is the occasional NA for minor allele as a result of low het count
  if(caller == "facets") {
    corrected_profile <- data.table::data.table("sample" = rep(sample_string, nrow(cnv_dt)),
                                                "seqnames" = cnv_dt$seqnames,
                                                "start" = cnv_dt$start,
                                                "end" = cnv_dt$end,
                                                "total" = cnv_dt$tcn.em,
                                                "minor" = dplyr::case_when(is.na(cnv_dt$lcn.em) ~ 0,
                                                                          !is.na(cnv_dt$lcn.em) ~ cnv_dt$lcn.em))

    # TODO: this will be depreciated when issues with Battenberg are addressed
    # Case 2: Battenberg (fit.cnv) reports both total and major/minor alleles in rounded and non-rounded format
  } else if(caller == "battenberg.fit") {

    # First, need to account for negative non-rounded values
    bb_cnv_dt <- cnv_dt

    # Get the correct value of the minor allele, is occasionally negative
    corrected_minor_allele <- pmax(bb_cnv_dt$minor_allele_nonrounded, 0)

    # Loop through the Battenberg minor allele segments
    rounded_bb_minor <- c()
    for(i in 1:length(corrected_minor_allele)) {
      # Gather clonally rounded minor alleles
      rounded_bb_minor[i] <- dplyr::case_when(corrected_minor_allele[i] < 0.2 ~ 0,
                                              between(x = corrected_minor_allele[i], left = 0.2, right = 0.8) ~ corrected_minor_allele[i],
                                              between(x = corrected_minor_allele[i], left = 0.8, right = 1.2) ~ 1,
                                              between(x = corrected_minor_allele[i], left = 1.2, right = 1.8) ~ corrected_minor_allele[i],
                                              between(x = corrected_minor_allele[i], left = 1.8, right = 2.2) ~ 2,
                                              between(x = corrected_minor_allele[i], left = 2.2, right = 2.8) ~ corrected_minor_allele[i],
                                              between(x = corrected_minor_allele[i], left = 2.8, right = 3.2) ~ 3,
                                              between(x = corrected_minor_allele[i], left = 3.2, right = 3.8) ~ corrected_minor_allele[i],
                                              between(x = corrected_minor_allele[i], left = 3.8, right = 4.2) ~ 4,
                                              between(x = corrected_minor_allele[i], left = 4.2, right = 4.8) ~ corrected_minor_allele[i],
                                              between(x = corrected_minor_allele[i], left = 4.8, right = 5.2) ~ 5,
                                              between(x = corrected_minor_allele[i], left = 5.2, right = 5.8) ~ corrected_minor_allele[i],
                                              between(x = corrected_minor_allele[i], left = 5.8, right = 6.2) ~ 6,
                                              between(x = corrected_minor_allele[i], left = 6.2, right = 6.8) ~ corrected_minor_allele[i],
                                              corrected_minor_allele[i] >= 6.8 ~ round(x = corrected_minor_allele[i], digits = 0))
    }

    # Get the correct value of the minor allele, is occasionally negative
    corrected_major_allele <- pmax(bb_cnv_dt$major_allele_nonrounded, 0)

    # Now calculate the correct non-rounded total copy number
    corrected_total_cn <- corrected_major_allele + corrected_minor_allele

    # Loop through the Battenberg total CN segments
    rounded_bb_total_cn <- c()
    for(i in 1:length(corrected_total_cn)) {
      # Gather clonally rounded minor alleles
      rounded_bb_total_cn[i] <- dplyr::case_when(corrected_total_cn[i] < 0.2 ~ 0,
                                                 between(x = corrected_total_cn[i], left = 0.2, right = 0.8) ~ corrected_total_cn[i],
                                                 between(x = corrected_total_cn[i], left = 0.8, right = 1.2) ~ 1,
                                                 between(x = corrected_total_cn[i], left = 1.2, right = 1.8) ~ corrected_total_cn[i],
                                                 between(x = corrected_total_cn[i], left = 1.8, right = 2.2) ~ 2,
                                                 between(x = corrected_total_cn[i], left = 2.2, right = 2.8) ~ corrected_total_cn[i],
                                                 between(x = corrected_total_cn[i], left = 2.8, right = 3.2) ~ 3,
                                                 between(x = corrected_total_cn[i], left = 3.2, right = 3.8) ~ corrected_total_cn[i],
                                                 between(x = corrected_total_cn[i], left = 3.8, right = 4.2) ~ 4,
                                                 between(x = corrected_total_cn[i], left = 4.2, right = 4.8) ~ corrected_total_cn[i],
                                                 between(x = corrected_total_cn[i], left = 4.8, right = 5.2) ~ 5,
                                                 between(x = corrected_total_cn[i], left = 5.2, right = 5.8) ~ corrected_total_cn[i],
                                                 between(x = corrected_total_cn[i], left = 5.8, right = 6.2) ~ 6,
                                                 between(x = corrected_total_cn[i], left = 6.2, right = 6.8) ~ corrected_total_cn[i],
                                                 corrected_total_cn[i] >= 6.8 ~ round(x = corrected_total_cn[i], digits = 0))
    }

    corrected_profile <- data.table::data.table("sample" = rep(sample_string, nrow(cnv_dt)),
                                                "seqnames" = cnv_dt$seqnames,
                                                "start" = cnv_dt$start,
                                                "end" = cnv_dt$end,
                                                "total" = rounded_bb_total_cn,
                                                "minor" = rounded_bb_minor)
    }

  # Return the final profile
  return(corrected_profile)
}





#
#
# }}}}------->>> Reader functions
#
#

#' @name read_gtf_file
#' @title Read in a GTF file, such as one from Ensembl, and convert to GenomicRanges object
#'
#' @description
#' Read in a GTF file which contains a number of columns and convert it to a GenomicRanges object with refactored seq details.
#' The GTF file can be either zipped or unzipped.
#'
#' @param gtf_file_path Path to GTF file
#' @param seq_lengths Named vector object used as the template for new seq details, see `gUtils::hg_seqlengths()` for example
#'
#' @returns GenomicRanges object with GTF columns and updated seqinfo, seqnames, seqlengths, seqlevels
#' @export
read_gtf_file <- function(gtf_file_path, seq_lengths = gUtils::hg_seqlengths()) {

  gtf_gr <- rtracklayer::import(gtf_file_path)

  # Sort out seqinfo/levels/lengths mess
  gtf_gr <- gr_refactor_seqs(input_gr = gtf_gr, new_levels = seq_lengths)
  return(gtf_gr)
}

#' @name get_genes_shortcut
#' @title Shortcut to get only protein coding genes from GTF file and convert to GenomicRanges object
#'
#' @description
#' Read in a GTF file, subset to protein coding genes, and convert it to a GenomicRanges object with refactored seq details.
#' The GTF file can be either zipped or unzipped.
#'
#' @param gtf_file_path Path to GTF file
#' @param seq_lengths Named vector object used as the template for new seq details, see `gUtils::hg_seqlengths()` for example
#'
#' @returns GenomicRanges object with GTF columns and updated seqinfo, seqnames, seqlengths, seqlevels
#' @export
get_genes_shortcut <- function(gtf_file_path, seq_lengths = gUtils::hg_seqlengths()) {

  gtf_gr <- read_gtf_file(gtf_file_path = gtf_file_path, seq_lengths = seq_lengths)

  # Subset to protein coding biotype and non-NA gene symbols
  genes <- gtf_gr %Q% (gene_biotype == "protein_coding" & type == "gene" & !is.na(gene_name))
  return(genes)
}

#' @name read_maf_file
#' @title Read MAF file and convert to GenomicRanges object
#'
#' @description
#' Read in a MAF file which contains a number of columns and convert it to a GenomicRanges object with refactored seq details.
#' The MAF file can be either zipped or unzipped.
#' For more specific MAFtools operations, see `maftools::read.maf()`
#'
#' @param maf_file_path Path to MAF file
#' @param cpus number of cpus for reading in data, used by `data.table::fread()`, default: 2
#' @param seq_lengths Named vector object used as the template for new seq details, see `gUtils::hg_seqlengths()` for example
#'
#' @returns GenomicRanges object with MAF columns and updated seqinfo, seqnames, seqlengths, seqlevels
#' @export
read_maf_file <- function(maf_file_path, cpus = 2, seq_lengths = gUtils::hg_seqlengths()) {

  # Set available threads
  doParallel::registerDoParallel(cores = cpus)

  # Read in MAF with extra speed
  maf_dt <- data.table::fread(input = maf_file_path,
                              sep = "\t",
                              header = TRUE,
                              stringsAsFactors = FALSE,
                              nThread = cpus)
  maf_gr <- dt_to_gr(maf_dt)

  # Sort out seqinfo/levels/lengths mess
  maf_gr <- gr_refactor_seqs(input_gr = maf_gr, new_levels = seq_lengths)
  return(maf_gr)
}

#' @name read_bed_file
#' @title Read in a BED file, with or without header, and convert to GenomicRanges object
#'
#' @description
#' Read in a BED file and convert it to a GenomicRanges object with refactored seq details.
#' Expects the first 3 columns as chromosome, start, end; However column names are not necessary
#' The BED file can be either zipped or unzipped.
#'
#' @param bed_file_path Path to BED file
#' @param has_header Does BED file have header line
#' @param additional_col_names Names for additional columns in BED file, beyond first three
#' @param cpus number of cpus for reading in data, used by `data.table::fread()`, default: 1
#' @param seq_lengths Named vector object used as the template for new seq details, see `gUtils::hg_seqlengths()` for example
#'
#' @returns GenomicRanges object with BED columns, if present, and updated seqinfo, seqnames, seqlengths, seqlevels
#' @export
read_bed_file <- function(bed_file_path, has_header = FALSE, additional_col_names = NULL, cpus = 1, seq_lengths = gUtils::hg_seqlengths()) {

  # Set available threads
  doParallel::registerDoParallel(cores = cpus)

  # Read in file with options to account for various combinations of header/columns
  # Case 1: no header
  if(has_header == F) {
    bed_dt <- data.table::fread(input = bed_file_path,
                                sep = "\t",
                                header = has_header,
                                stringsAsFactors = FALSE,
                                nThread = cpus)

    # Subcase condition 1: only 3 columns
    if(ncol(bed_dt) == 3 & is.null(additional_col_names)) {
      colnames(bed_dt) <- c("chr", "start", "end")
    # Subcase condition 2: more than 3 columns, no additional names given
    } else if(ncol(bed_dt) > 3 & is.null(additional_col_names)) {
      colnames(bed_dt)[1:3] <- c("chr", "start", "end")
    # Subcase condition 3: more than 3 columns, additional names given
    } else if(ncol(bed_dt) > 3 & !is.null(additional_col_names)) {
      colnames(bed_dt) <- c("chr", "start", "end", additional_col_names)
    }

  # Case 2: has a header
  } else if(has_header == T) {
    bed_dt <- data.table::fread(input = bed_file_path,
                                sep = "\t",
                                header = has_header,
                                stringsAsFactors = FALSE,
                                nThread = cpus)

    # Subcase condition 1: only 3 columns
    if(ncol(bed_dt) == 3 & is.null(additional_col_names)) {
      colnames(bed_dt) <- c("chr", "start", "end")
      # Subcase condition 2: more than 3 columns
    } else if(ncol(bed_dt) > 3 & is.null(additional_col_names)) {
      colnames(bed_dt)[1:3] <- c("chr", "start", "end")
    }
  }

  # Edge Case: Check for use of 23/24 for chrX/chrY
  chromosome_set <- unique(bed_dt$chr)
  if(23 %in% chromosome_set) {
    message("Chromosome `23` detected ...\nConverting to `chrX` ...")
    bed_dt$chr <- dplyr::recode(bed_dt$chr, `23` = "X", .default = as.character(bed_dt$chr))
  }
  if(24 %in% chromosome_set) {
    message("Chromosome `24` detected ...\nConverting to `chrY` ...")
    bed_dt$chr <- dplyr::recode(bed_dt$chr, `24` = "Y", .default = as.character(bed_dt$chr))
  }

  bed_gr <- dt_to_gr(bed_dt)

  # Sort out seqinfo/levels/lengths mess
  bed_gr <- gr_refactor_seqs(input_gr = bed_gr, new_levels = seq_lengths)
  return(bed_gr)
}

#' @name read_vcf_file
#' @title Read in a VCF file and convert to GenomicRanges object
#'
#' @description
#' Read in a VCF file and convert it to a GenomicRanges object with refactored seq details.
#' Currently supports conversion of somatic SNV/InDel VCFs from Mutect, Strelka, Varscan, SvABA, CaVEMan.
#' Also supports conversion of germline SNP/InDel VCF from DeepVariant.
#' The VCF file can be either zipped or unzipped.
#'
#' @param vcf_file_path Path to VCF file
#' @param tumor_sample Name of tumor sample as reported in VCF
#' @param normal_sample Name of normal sample as reported in VCF
#' @param caller Name of the caller that generated input VCF to be converted, supported: mutect, strelka, varscan, svaba, caveman, deepvariant
#' @param mut_type Type of mutations within VCF, supported: snv, indel, snp
#' @param seq_lengths Named vector object used as the template for new seq details, see `gUtils::hg_seqlengths()` for example
#'
#' @returns GenomicRanges object with VCF FILTER/INFO/FORMAT columns, if present, and updated seqinfo, seqnames, seqlengths, seqlevels
#' @export
read_vcf_file <- function(vcf_file_path, tumor_sample = NULL, normal_sample = NULL,
                          caller = NULL, mut_type = NULL, seq_lengths = gUtils::hg_seqlengths()) {

  # Read in VCF into VA VCF obj
  vcf_va <- VariantAnnotation::readVcf(file = vcf_file_path)

  # Build the GRanges obj from VCF obj
  # Start by setting the GRanges base and exclude the paramRangesID column
  vcf_gr_base <- vcf_va@rowRanges[,-1]

  # remove names of range rows
  names(vcf_gr_base) <- NULL

  # Have user provide tumor_sample and normal_sample
  # Create metadata column with patient and sample name
  vcf_query_ids <- vcf_va@metadata$header@samples

  # Edge case: SvABA uses BAM name for SAMPLE columns in VCF
  if(caller %in% c("svaba")) {
    vcf_query_ids <- stringr::str_remove(string = vcf_query_ids, pattern = "\\..+\\.bam$")
  }

  # Add column for name of caller
  vcf_gr_base$CALLER <- caller

  # Sanity Check: Do VCF query IDs match user-provided tumor/normal parameters?
  # Check if germline first then somatic
  # DeepVariant only uses normal sample for germline
  if(caller == "deepvariant" & is.null(tumor_sample) & !is.null(normal_sample)) {
    vcf_normal_sample_index <- 1

    vcf_gr_base$PATIENT <- normal_sample
    vcf_gr_base$NORMAL <- normal_sample

  } else if(caller %in% c("mutect", "svaba") & tumor_sample %in% vcf_query_ids & normal_sample %in% vcf_query_ids) {
    vcf_tumor_sample_index <- which(tumor_sample == vcf_query_ids)
    vcf_normal_sample_index <- which(normal_sample == vcf_query_ids)

    vcf_gr_base$TUMOR <- vcf_query_ids[vcf_tumor_sample_index]
    vcf_gr_base$NORMAL <- vcf_query_ids[vcf_normal_sample_index]

    vcf_gr_base$SAMPLE <- vcf_query_ids[vcf_tumor_sample_index]
    vcf_gr_base$PATIENT <- vcf_query_ids[vcf_normal_sample_index]

    # Strelka, VarScan, CaVEMan uses generic NORMAL and TUMOR/TUMOUR as name of SAMPLE columns instead of sample ID/BAM basename
  } else if(caller %in% c("strelka", "varscan", "caveman") & !is.null(tumor_sample) & !is.null(normal_sample)) {

    vcf_tumor_sample_index <- which(vcf_query_ids %in% c("TUMOR", "TUMOUR"))
    vcf_normal_sample_index <- which(vcf_query_ids == "NORMAL")

    vcf_gr_base$SAMPLE <- tumor_sample
    vcf_gr_base$TUMOR <- tumor_sample

    vcf_gr_base$PATIENT <- normal_sample
    vcf_gr_base$NORMAL <- normal_sample

  } else {
    # Problem if there is no proper combo of samples and caller
    stop(message = "\nTumor/Normal sample names provided NOT FOUND in VCF")
  }

  # Now form the final GRanges obj by grabbing the REF, ALT, QUAL, FILTER, and all INFO columns
  vcf_gr <- vcf_gr_base
  S4Vectors::mcols(vcf_gr) <- c(S4Vectors::mcols(vcf_gr_base), vcf_va@fixed, vcf_va@info)

  # Convert the REF/ALT field from DNA Biostring to character
  # ALT
  if(!is.character(vcf_gr$ALT)) {
    vcf_gr$ALT <- as.character(unlist(vcf_va@fixed$ALT))  # Needed for SNVs primarily but not exclusively
  }
  # REF
  if(!is.character(vcf_gr$REF)) {
    vcf_gr$REF <- unlist(stringr::str_split(string = Biostrings::toString(vcf_va@fixed$REF), pattern = ", "))  # Needed for InDels
  }

  # Add tumor and normal specific DP field
  if(caller %in% c("mutect", "varscan", "strelka", "caveman")) {
    vcf_gr$DP_TUMOR <- vcf_va@assays@data@listData$DP[,vcf_tumor_sample_index]
    vcf_gr$DP_NORMAL <- vcf_va@assays@data@listData$DP[,vcf_normal_sample_index]

  } else if(caller == "deepvariant") {
    vcf_gr$DP_NORMAL <- vcf_va@assays@data@listData$DP[,vcf_normal_sample_index]
  }

  if(caller == "mutect") {
    # FORMAT fields are stored in list of lists, need to properly extract tumor AD, AF and normal AD
    # When unlisting the AD/AF fields, the allele depth is split into REF and ALT columns
    # so easily grab with even (ALT) and odd (REF) vector index
    vcf_tumor_allele_depth <- unlist(vcf_va@assays@data@listData$AD[,vcf_tumor_sample_index])
    odd_even_index <- seq_len(length(vcf_tumor_allele_depth)) %% 2

    vcf_gr$AD_REF_TUMOR <- vcf_tumor_allele_depth[odd_even_index == 1]
    vcf_gr$AD_ALT_TUMOR <- vcf_tumor_allele_depth[odd_even_index == 0]

    vcf_gr$AF_TUMOR <- unlist(vcf_va@assays@data@listData$AF[,vcf_tumor_sample_index])
    vcf_gr$GT_TUMOR <- vcf_va@assays@data@listData$GT[,vcf_tumor_sample_index]

    vcf_normal_allele_depth <- unlist(vcf_va@assays@data@listData$AD[,vcf_normal_sample_index])
    vcf_gr$AD_REF_NORMAL <- vcf_normal_allele_depth[odd_even_index == 1]
    vcf_gr$AD_ALT_NORMAL <- vcf_normal_allele_depth[odd_even_index == 0]

    vcf_gr$GT_NORMAL <- vcf_va@assays@data@listData$GT[,vcf_normal_sample_index]

    # Some INFO metrics need to be reformatted from complex to simple (i.e. list to vector)
    vcf_gr$AS_FilterStatus <- unlist(vcf_gr$AS_FilterStatus)
    vcf_gr$AS_UNIQ_ALT_READ_COUNT <- unlist(vcf_gr$AS_UNIQ_ALT_READ_COUNT)

    MBQ_1 <- unlist(vcf_gr$MBQ)[odd_even_index == 1]
    MBQ_2 <- unlist(vcf_gr$MBQ)[odd_even_index == 0]
    vcf_gr$MBQ <- stringr::str_c(MBQ_1, MBQ_2, sep = ",")

    MFRL_1 <- unlist(vcf_gr$MFRL)[odd_even_index == 1]
    MFRL_2 <- unlist(vcf_gr$MFRL)[odd_even_index == 0]
    vcf_gr$MFRL <- stringr::str_c(MFRL_1, MFRL_2, sep = ",")

    MMQ_1 <- unlist(vcf_gr$MMQ)[odd_even_index == 1]
    MMQ_2 <- unlist(vcf_gr$MMQ)[odd_even_index == 0]
    vcf_gr$MMQ <- stringr::str_c(MMQ_1, MMQ_2, sep = ",")

    vcf_gr$MPOS <- unlist(vcf_gr$MPOS)
    vcf_gr$NALOD <- unlist(vcf_gr$NALOD)
    vcf_gr$NLOD <- unlist(vcf_gr$NLOD)
    vcf_gr$POPAF <- unlist(vcf_gr$POPAF)

    RPA_1 <- unlist(vcf_gr$RPA)[odd_even_index == 1]
    RPA_2 <- unlist(vcf_gr$RPA)[odd_even_index == 0]
    vcf_gr$RPA <- stringr::str_c(RPA_1, RPA_2, sep = ",")

    vcf_gr$TLOD <- unlist(vcf_gr$TLOD)

  } else if(caller == "strelka" & mut_type == "snv") {
    # Strelka VCF breaks down reads by nucleotide, then by tier
    vcf_gr$AU_TIER1_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$AU)[,vcf_tumor_sample_index]
    vcf_gr$AU_TIER2_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$AU)[,vcf_tumor_sample_index + 2]

    vcf_gr$CU_TIER1_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$CU)[,vcf_tumor_sample_index]
    vcf_gr$CU_TIER2_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$CU)[,vcf_tumor_sample_index + 2]

    vcf_gr$GU_TIER1_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$GU)[,vcf_tumor_sample_index]
    vcf_gr$GU_TIER2_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$GU)[,vcf_tumor_sample_index + 2]

    vcf_gr$TU_TIER1_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$TU)[,vcf_tumor_sample_index]
    vcf_gr$TU_TIER2_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$TU)[,vcf_tumor_sample_index + 2]

    vcf_gr$AU_TIER1_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$AU)[,vcf_normal_sample_index]
    vcf_gr$AU_TIER2_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$AU)[,vcf_normal_sample_index + 2]

    vcf_gr$CU_TIER1_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$CU)[,vcf_normal_sample_index]
    vcf_gr$CU_TIER2_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$CU)[,vcf_normal_sample_index + 2]

    vcf_gr$GU_TIER1_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$GU)[,vcf_normal_sample_index]
    vcf_gr$GU_TIER2_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$GU)[,vcf_normal_sample_index + 2]

    vcf_gr$TU_TIER1_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$TU)[,vcf_normal_sample_index]
    vcf_gr$TU_TIER2_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$TU)[,vcf_normal_sample_index + 2]

  } else if(caller == "strelka" & mut_type == "indel") {
    # Strelka has different FORMAT fields for indel VCF, most relevant is TIR (Reads strongly supporting indel allele for tiers 1,2)
    vcf_gr$TIR_TIER1_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$TIR)[,vcf_tumor_sample_index]
    vcf_gr$TIR_TIER2_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$TIR)[,vcf_tumor_sample_index + 2]

    vcf_gr$TIR_TIER1_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$TIR)[,vcf_normal_sample_index]
    vcf_gr$TIR_TIER2_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$TIR)[,vcf_normal_sample_index + 2]

  } else if(caller == "varscan") {
    # Varscan breaks down the read depth into 2 separate fields as ref read depth and variant read depth
    vcf_gr$RD_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$RD)[,vcf_tumor_sample_index]
    vcf_gr$AD_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$AD)[,vcf_tumor_sample_index]

    vcf_gr$FREQ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$FREQ)[,vcf_tumor_sample_index]
    vcf_gr$GT_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$GT)[,vcf_tumor_sample_index]

    vcf_gr$RD_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$RD)[,vcf_normal_sample_index]
    vcf_gr$AD_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$AD)[,vcf_normal_sample_index]

    vcf_gr$FREQ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$FREQ)[,vcf_normal_sample_index]
    vcf_gr$GT_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$GT)[,vcf_normal_sample_index]

  } else if(caller == "svaba") {
    # SvABA also provides the SR FORMAT field for number of spanning reads for the variants
    vcf_gr$AD_TUMOR <- vcf_va@assays@data@listData$AD[,vcf_tumor_sample_index]
    vcf_gr$SR_TUMOR <- vcf_va@assays@data@listData$SR[,vcf_tumor_sample_index]
    vcf_gr$GT_TUMOR <- vcf_va@assays@data@listData$GT[,vcf_tumor_sample_index]

    vcf_gr$AD_NORMAL <- vcf_va@assays@data@listData$AD[,vcf_normal_sample_index]
    vcf_gr$SR_NORMAL <- vcf_va@assays@data@listData$SR[,vcf_normal_sample_index]
    vcf_gr$GT_NORMAL <- vcf_va@assays@data@listData$GT[,vcf_normal_sample_index]

    # Some INFO metrics are complex format but empty, remove them here
    vcf_gr <- vcf_gr[,!colnames(S4Vectors::mcols(vcf_gr)) %in% c("READNAMES", "BX")]

  } else if(caller == "caveman") {
    # CaVEMan provides a format field for each nucleotide type per forward and reverse strand reads at the variant
    # The DS metric is complex format but empty/redundant, remove them here
    vcf_gr <- vcf_gr[,!colnames(S4Vectors::mcols(vcf_gr)) == "DS"]

    vcf_gr$FAZ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$FAZ)[,vcf_tumor_sample_index]
    vcf_gr$FCZ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$FCZ)[,vcf_tumor_sample_index]
    vcf_gr$FGZ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$FGZ)[,vcf_tumor_sample_index]
    vcf_gr$FTZ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$FTZ)[,vcf_tumor_sample_index]
    vcf_gr$RAZ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$RAZ)[,vcf_tumor_sample_index]
    vcf_gr$RCZ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$RCZ)[,vcf_tumor_sample_index]
    vcf_gr$RGZ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$RGZ)[,vcf_tumor_sample_index]
    vcf_gr$RTZ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$RTZ)[,vcf_tumor_sample_index]
    vcf_gr$PM_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$PM)[,vcf_tumor_sample_index]
    vcf_gr$GT_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$GT)[,vcf_tumor_sample_index]

    vcf_gr$FAZ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$FAZ)[,vcf_normal_sample_index]
    vcf_gr$FCZ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$FCZ)[,vcf_normal_sample_index]
    vcf_gr$FGZ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$FGZ)[,vcf_normal_sample_index]
    vcf_gr$FTZ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$FTZ)[,vcf_normal_sample_index]
    vcf_gr$RAZ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$RAZ)[,vcf_normal_sample_index]
    vcf_gr$RCZ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$RCZ)[,vcf_normal_sample_index]
    vcf_gr$RGZ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$RGZ)[,vcf_normal_sample_index]
    vcf_gr$RTZ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$RTZ)[,vcf_normal_sample_index]
    vcf_gr$PM_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$PM)[,vcf_normal_sample_index]
    vcf_gr$GT_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$GT)[,vcf_normal_sample_index]

  } else if(caller == "deepvariant") {

    vcf_gr$REF_AD_NORMAL <- as.vector(unlist(as.data.frame(vcf_va@assays@data@listData$AD[,])[1,]))
    vcf_gr$ALT_AD_NORMAL <- as.vector(unlist(as.data.frame(vcf_va@assays@data@listData$AD[,])[2,]))
    vcf_gr$VAF_NORMAL <- as.vector(unlist(as.data.frame(vcf_va@assays@data@listData$VAF[,])[1,]))
    vcf_gr$GT_NORMAL <- vcf_va@assays@data@listData$GT[,]

    # Remove some populated columns
    GenomicRanges::mcols(vcf_gr) <- GenomicRanges::mcols(vcf_gr)[,-c(8:12)]
  }

  # Sort out seqinfo/levels/lengths mess
  vcf_gr <- gr_refactor_seqs(input_gr = vcf_gr, new_levels = seq_lengths)
  return(vcf_gr)
}











#' @name aggregate_these
#' @title Read in all data files of a specific grep pattern, aggregate them into a single data.table
#'
#' @description
#' Collect all files that match a specific `ls`-style pattern at a specific path, read them into a data.table, then aggregate
#' all into single data.table. Best suited for genomic data formats such as SNV/InDel mutation table, CNV BED, or SV BEDPE.
#'
#' @param path_to_files path to location of files to be aggregated
#' @param pattern_to_grab `ls`-style pattern used to identify files
#' @param delim delimiter used in files to be aggregated, expected to be same in all files
#' @param has_header indicate if files have a header line, expected to be same in all files
#' @param cpus number of cpus for reading in data, used by `data.table::fread()`
#' @param add_uniq_id indicate if the output data.table should include a unique identifier column, derived from input file basename
#'
#' @returns data.table object with all data under preserved column construct
#' @export
aggregate_these <- function(path_to_files, pattern_to_grab, delim = "\t", has_header = TRUE,
                            cpus = 1, add_uniq_id = FALSE) {

  # Set available threads
  doParallel::registerDoParallel(cores = cpus)

  # Find all files at the provided path that match the provided pattern
  input_files_to_aggregate <- list.files(path = path_to_files,
                                         pattern = pattern_to_grab)

  # Create output DT to fill with aggregated data
  aggregate_dt <- data.table::data.table()
  for(i in 1:length(input_files_to_aggregate)) {

    # Read in single file
    dt_to_add <- data.table::fread(input = paste0(path_to_files, input_files_to_aggregate[i]),
                                   sep = delim,
                                   header = has_header,
                                   stringsAsFactors = F,
                                   nThread = cpus)

    # Some file formats do not explicitly have a patient/sample column or any unique identifier
    # Let's add one derived from the input file name, if needed
    if(add_uniq_id) {
      uniq_id <- str_remove(string = input_files_to_aggregate[i], pattern = "\\..*$")
      dt_to_add$id <- uniq_id
    }

    # Add to aggregate DT
    aggregate_dt <- gUtils::rrbind(aggregate_dt, dt_to_add, as.data.table = T)
  }

  # TODO: The sort functionality is bugged, aggregated file has some sort of mix-and-match of columns
  # sort_output = TRUE,
  # #' @param sort_output indicate if the output data.table should be sorted by genomic coordinate, BEDPE not supported yet
  # Sort the output by genomic coordinate if desired
  #if(sort_output) {
  #
  #  # TODO: BEDPE files don't translate from DT to GR with standard header, likely need gGnome junctions
  #  # Convert to GR to run foolproof sorting
  #  aggregate_gr <- gr_refactor_seqs(input_gr = gUtils::dt2gr(aggregate_dt))
  #  aggregate_dt <- gUtils::gr2dt(x = aggregate_gr)
  #}
  return(aggregate_dt)
}




#
#
# }}}}------->>> Viz: Colors, Geoms, and such
#
#

#' @name copynumber_palettier
#' @title Create color palette for integer copy number states
#'
#' @description
#' Given a set of discrete integer copy number states, produce a diverging blue/red
#' color palette that scales to any number.
#'
#' @param cn_states Discrete integer values of copy number states, typically for plotting
#'
#' @examples
#' # Most common set of states
#' copynumber_palettier(cn_states = seq(0,4))
#'
#' # high level jump
#' copynumber_palettier(cn_states = c(1,2,3,8))
#'
#' @returns data.table of states and assigned color
#' @export
copynumber_palettier <- function(cn_states) {
  # Set the base colors for most common CNs
  common_cn_dt <- data.table::data.table("copynumber" = c(0,1,2,3),
                                         "color" = c("#264DFF",
                                                     "#72D9FF",
                                                     "#999999",
                                                     "#F4B86E"))

  max_cn_state <- max(as.numeric(cn_states))
  # Check the max high CN value
  if(max_cn_state <= 3) {
    high_cn_dt <- common_cn_dt

  } else if(max_cn_state == 4) {
    # If only 4, add a max color
    high_cn_dt <- rbind(x = common_cn_dt,
                        y = data.table::data.table("copynumber" = 4,
                                                   "color"= "#A10E39"))
  } else if(max_cn_state >= 5) {
    # If greater or equal to 5, add sequential colors from 3 to max
    high_cn_dt <- rbind(x = common_cn_dt,
                        y = data.table::data.table("copynumber" = seq(4,max_cn_state),
                                                   "color"= grDevices::colorRampPalette(colors = c("#F4B86E","#A10E39"))(max_cn_state - 2)[-1]))
  }

  # Subset the CN-color DT to desired min/max then factorize in to discrete pal
  final_cn_dt <- high_cn_dt %>%
    dplyr::filter(copynumber %in% cn_states)
  final_cn_dt$copynumber <- factor(final_cn_dt$copynumber,
                                   levels = sort(cn_states))
  return(final_cn_dt)
}

#' @name geom_gap_imputation
#' @title Diagnostic plot used for reviewing the imputation of gaps in segmentation
#'
#' @description
#' Creates a simple ggpplot2 style plot for quickly reviewing how the imputation of
#' each gap identified in a segmentation file
#'
#' Note, this function was designed to be run as part of the `get_segmentation_gap_imputation()`
#' workflow.
#'
#' @param original_gap GenomicRanges object of gap
#' @param imputed_gap_gr GenomicRanges object of imputed values across gap
#' @param sv_bp GenomicRanges object of structural variant breakpoint that falls within
#'  the original gap, default: NULL
#'
#' @examples
#' # Snippet from within the function `` that calls this geom
#' # geom_gap_imputation_diagnostic(
#' # original_gap = gap_of_interest,
#' # imputed_gap_gr = gUtils::grbind(partition_regression_data, imputed_sv_gaps),
#' # sv_bp = goi_sv_bp_overlap)
#'
#' @returns ggplot object
#' @export
geom_gap_imputation <- function(original_gap, imputed_gap_gr, sv_bp = NULL) {
  # Convert the input GR to a DT
  imputed_gap_dt <- gUtils::gr2dt(imputed_gap_gr)

  # Build the plot starting with points for the segments
  diagnostic_plot <- ggplot2::ggplot(data = imputed_gap_dt) +
    ggplot2::geom_point(aes(x = end, y = seg.mean, color = tile_type), size = 3) +
    ggplot2::scale_color_manual(name = NULL, values = paletteer::paletteer_d("ggthemr::pale")) +
    ggplot2::geom_step(aes(x = end, y = seg.mean), color = "cyan", linewidth = 1.5) +
    ggplot2::labs(title = paste0("Gap at ", gUtils::gr.string(original_gap), " (", GenomicRanges::width(original_gap), " bp)"),
                  x = paste0(stringr::str_to_title(as.character(GenomeInfoDb::seqnames(original_gap)@values)), " genomic position"),
                  y = "Seg. Mean") +
    ggplot2::theme(panel.background = element_blank(),
                   panel.border = element_rect(fill = "transparent"),
                   panel.grid.major.x = element_blank(),
                   panel.grid.major.y = element_line(color = "gray40", linetype = "dotted"),
                   panel.grid.minor.x = element_blank(),
                   panel.grid.minor.y = element_blank(),
                   legend.position = "inside",
                   legend.position.inside = c(0.20,0.80),
                   legend.text = element_text(size = 9),
                   legend.background = element_rect(fill = alpha("gray80", alpha = 0.8)),
                   title = element_text(size = 11),
                   axis.text = element_text(size = 10),
                   axis.title = element_text(size = 11))

  # Add marker to show where the SV BP is
  if(!is.null(sv_bp)) {
    diagnostic_plot <- diagnostic_plot +
      ggplot2::annotate(geom = "point",
                        x = GenomicRanges::start(sv_bp),
                        y =  min(imputed_gap_dt$seg.mean),
                        color = "tan2",
                        size = 4.5,
                        shape = 17,
                        alpha = 0.8)
  }
  # Return the final plot
  return(diagnostic_plot)
}



#' @name geom_deseq2_volcano
#' @title Volcano plot for exploring results from DESeq2 differential gene expression analysis
#'
#' @description
#' Creates a ggplot2 style volcano plot for exploring the results from a DESeq2 DGE
#' analysis with parameters for easy styling
#'
#' @param deseq2_diff_expr_output DESeq2 object, works directly from `get_deseq2_diff_expr()` output
#' @param log2_fc_threshold Numeric cutoff for coloring points based on log fold change, default: 2
#' @param p_adj_threshold Numeric cutoff for coloring points based on adjust P-value significance, default: 0.05
#' @param n_positive_labels Number of top genes to label on positive side of log fold change, default: 25
#' @param n_negative_labels Number of top genes to label on negative side of log fold change, default: 25
#' @param label_vector Set of a priori genes to label, cannot be used in tandem with top N genes
#' @param point_label_nudge_x Distance on x-axis to adjust the gene labels, can be positive or negative value, default: 0
#' @param point_label_nudge_y Distance on y-axis to adjust the gene labels, can be positive or negative value, default: 0
#' @param condition_label_x Location on x-axis to put condition labels, default: 5
#'
#' @examples
#' # Run the DESeq2 DGE workflow
#' # dge_demo <- get_deseq2_diff_expr(
#' # counts_file_path = fs::path_package("extdata", "hmcl_counts.hg38.txt.gz", package = "devgru"),
#' # condition_file_path = fs::path_package("extdata", "hmcl_conditions.hg38.txt", package = "devgru"),
#' # gene_universe = gene_body_hg38,
#' # gene_symbol_column = "#GENE",
#' # ensembl_id_column = NULL,
#' # formula_string = "U266 ~ RPMI8226",
#' # min_transcripts = 10)
#'
#' # Exploratory plot with top 25 genes labeled on both ends of spectrum
#' # geom_deseq2_volcano(deseq2_diff_expr_output = dge_demo)
#'
#' # Targeted assessment with labels for genes of interest
#' # geom_deseq2_volcano(deseq2_diff_expr_output = dge_demo, label_vector = c("CCND1","MYC","MYCL"))
#'
#' @returns ggplot object
#' @export
geom_deseq2_volcano <- function(deseq2_diff_expr_output, log2_fc_threshold = 2, p_adj_threshold = 0.05,
                                n_positive_labels = 25, n_negative_labels = 25, label_vector = NULL,
                                point_label_nudge_x = 0, point_label_nudge_y = 0, condition_label_x = 5) {
  # Build the set of labels to add to the plot
  if(!is.null(label_vector)) {
    point_labels <- label_vector

  } else {
    # Extract the top N genes to label for both LFC directions
    top_n_pos_lfc_genes <- deseq2_diff_expr_output$deseq2_results_dt %>%
      dplyr::arrange(p_val_adj) %>%
      dplyr::filter(log2_fc > 0) %>%
      dplyr::select(gene) %>%
      dplyr::slice_head(n = n_positive_labels) %>%
      purrr::as_vector()

    top_n_neg_lfc_genes <- deseq2_diff_expr_output$deseq2_results_dt %>%
      dplyr::arrange(p_val_adj) %>%
      dplyr::filter(log2_fc < 0) %>%
      dplyr::select(gene) %>%
      dplyr::slice_head(n = n_negative_labels) %>%
      purrr::as_vector()

    point_labels <- c(top_n_pos_lfc_genes, top_n_neg_lfc_genes)
  }

  # Transform the observed P-values to -log10, add labels and colors for points
  dge_plot_data <- deseq2_diff_expr_output$deseq2_results_dt %>%
    dplyr::mutate("neg_log10_p_adj" = -log10(p_val_adj + .Machine$double.eps * 10^-299),
                  "point_label" = dplyr::case_when(gene %in% point_labels ~ gene,
                                                   !gene %in% point_labels ~ NA),
                  "point_color" = dplyr::case_when(p_val_adj <= p_adj_threshold &
                                                     sign(log2_fc) == -1 &
                                                     abs(log2_fc) >= log2_fc_threshold ~ ggplot2::alpha(colour = "dodgerblue", alpha = 0.7),
                                                   p_val_adj <= p_adj_threshold &
                                                     sign(log2_fc) == 1 &
                                                     abs(log2_fc) >= log2_fc_threshold ~ ggplot2::alpha(colour = "firebrick2", alpha = 0.7),
                                                   p_val_adj <= p_adj_threshold &
                                                     dplyr::between(x = abs(log2_fc), left = 0, right = log2_fc_threshold) ~ ggplot2::alpha(colour = "gray10", alpha = 0.5),
                                                   p_val_adj > p_adj_threshold ~ ggplot2::alpha(colour = "gray10", alpha = 0.5)))

  # Combine the plot elements to create volcano plot
  volcano_plot <- ggplot2::ggplot(dge_plot_data) +
    ggplot2::geom_point(aes(x = neg_log10_p_adj, y = log2_fc), color = dge_plot_data$point_color) +
    ggrepel::geom_text_repel(aes(x = neg_log10_p_adj, y = log2_fc, label = point_label),
                             min.segment.length = 0, max.overlaps = 1000, nudge_x = point_label_nudge_x, nudge_y = point_label_nudge_y, na.rm = T) +
    ggplot2::labs(x = expression("-Log"[10]*"("*italic("Adj. P")*")"),
                  y = expression("Log"[2]*"(Fold Change)")) +
    ggplot2::annotate(geom = "label",
                      label = c(levels(SummarizedExperiment::colData(deseq2_diff_expr_output$deseq2_obj)$condition)[1],
                                levels(SummarizedExperiment::colData(deseq2_diff_expr_output$deseq2_obj)$condition)[2]),
                      x = condition_label_x,
                      y = c(min(dge_plot_data$log2_fc),
                            max(dge_plot_data$log2_fc)),
                      size = 4.75,
                      fontface = "bold") +
    ggplot2::theme(panel.border = ggplot2::element_rect(fill = "transparent"),
                   panel.background = ggplot2::element_blank())

  return(volcano_plot)
}

#' @name geom_gsea_enrichment
#' @title Enrichment plot for exploring results from fgsea pathway enrichment analysis
#'
#' @description
#' Creates a ggplot2 style enrichment plot for exploring the results from a fgsea GSEA
#' analysis.
#'
#' @param pathways GMT file with desired pathway gene sets to test for enrichment
#' @param pathway_of_interest Specific pathway to in GMT to explore
#' @param ranked_genes Named vector of genes and their ranks, works directly from `get_fgsea_pathway_enrichment()` output
#'
#' @examples
#' # Run the DESeq2 DGE workflow
#' # dge_demo <- get_deseq2_diff_expr(
#' # counts_file_path = fs::path_package("extdata", "hmcl_counts.hg38.txt.gz", package = "devgru"),
#' # condition_file_path = fs::path_package("extdata", "hmcl_conditions.hg38.txt", package = "devgru"),
#' # gene_universe = gene_body_hg38,
#' # gene_symbol_column = "#GENE",
#' # ensembl_id_column = NULL,
#' # formula_string = "U266 ~ RPMI8226",
#' # min_transcripts = 10)
#'
#' # Get enrichment against B cell specific pathways from ImmuneSigDB
#' # gsea_demo <- get_fgsea_pathway_enrichment(
#' # deseq2_diff_expr_output = dge_demo,
#' # pathways = "c7.bcell.immunesigdb.v2025.1.Hs.symbols.gmt",
#' # cpus = 2)
#'
#' # Plot the enrichment of specific pathway
#' # geom_gsea_enrichment(
#' # pathways = "~/morganLab/nsd2dTagSystem/data/c7.bcell.immunesigdb.v2025.1.Hs.symbols.gmt",
#' # pathway_of_interest = "GSE38304_MYC_NEG_VS_POS_GC_BCELL_UP",
#' # ranked_genes = gsea_demo$ranked_genes)
#'
#' @returns ggplot object
#' @export
geom_gsea_enrichment <- function(pathways, pathway_of_interest, ranked_genes) {
  # Check pathway GMT file path, read in
  if(file.exists(pathways) & tools::file_ext(pathways) == "gmt") {
    pathway_list <- fgsea::gmtPathways(pathways)
  }

  # Subset to pathway gene set of interest
  pathway_gene_set <- pathway_list[[pathway_of_interest]]

  # Code originally from fgsea
  rnk <- rank(-ranked_genes)
  ord <- order(rnk)

  statsAdj <- ranked_genes[ord]
  statsAdj <- sign(statsAdj) * abs(statsAdj)

  pathway <- unname(as.vector(na.omit(match(pathway_gene_set, names(statsAdj)))))
  pathway <- sort(pathway)
  pathway <- unique(pathway)
  gseaRes <- fgsea::calcGseaStat(stats = statsAdj,
                                 selectedStats = pathway,
                                 returnAllExtremes = TRUE)
  bottoms <- gseaRes$bottoms
  tops <- gseaRes$tops

  n <- length(statsAdj)
  xs <- as.vector(rbind(pathway - 1, pathway))
  ys <- as.vector(rbind(bottoms, tops))

  spreadES <- max(tops) - min(bottoms)
  toPlot <- data.table::data.table("rank" = c(0, xs, n + 1), "ES" = c(0, ys, 0))
  ticks <- data.table::data.table("rank" = pathway, "stat" = statsAdj[pathway])
  stats <- data.table::data.table("rank" = seq_along(ranked_genes), "stat" = statsAdj)

  # Build the enrichment plot using 3 separate subsections
  # Starting with the total enrichment score curve
  enrichment_score_curve <- ggplot2::ggplot(toPlot) +
    ggplot2::geom_line(aes(x = rank, y = ES), color = "green", linewidth = 1.5) +
    ggplot2::geom_hline(yintercept = 0, color = "black") +
    ggplot2::labs(x = NULL,
                  y = "Enrichment Score") +
    ggplot2::scale_x_continuous(expand = c(0,0)) +
    ggplot2::scale_y_continuous(expand = c(0.01,0.01)) +
    ggplot2::theme(panel.grid.major.x = ggplot2::element_line(color = "gray", linetype = "dotted"),
                   panel.grid.major.y = element_blank(),
                   panel.grid.minor.y = element_blank(),
                   panel.background = element_blank(),
                   panel.border = element_rect(fill = "transparent"),
                   axis.line.x = element_blank(),
                   axis.text.x = element_blank(),
                   axis.ticks.x = element_blank(),
                   axis.text.y = element_text(size = 13),
                   axis.title.y = element_text(size = 14),
                   plot.margin = unit(c(0.05,0.05,0.05,0.05), "mm"))

  # Add dash marks for the hits of the pathway gene set
  pathway_hits <- ggplot2::ggplot(ticks) +
    ggplot2::geom_segment(aes(x = rank, xend = rank, y = -spreadES/16, yend = spreadES/16), linewidth = 0.3, color = "darkred") +
    ggplot2::labs(x = NULL,
                  y = "Hits") +
    ggplot2::scale_x_continuous(expand = c(0,0)) +
    ggplot2::scale_y_continuous(expand = c(0,0)) +
    ggplot2::theme(panel.grid.major.x = element_blank(),
                   panel.grid.major.y = element_blank(),
                   panel.grid.minor.y = element_blank(),
                   panel.background = element_blank(),
                   axis.line.x = element_blank(),
                   axis.text.x = element_blank(),
                   axis.ticks.x = element_blank(),
                   axis.title.y = element_text(size = 14),
                   axis.text.y = element_blank(),
                   axis.ticks.y = element_blank(),
                   plot.margin = unit(c(0.05,0.05,0.05,0.05), "mm"))

  # Finally, add the full ordered ranking of all genes used in the GSEA
  gene_rank_seesaw <- ggplot2::ggplot(stats) +
    ggplot2::geom_col(aes(x = rank, y = stat), width = 1, fill = "black") +
    ggplot2::labs(x = "Rank Ordered Genes",
                  y = "Rank Score") +
    ggplot2::scale_x_continuous(expand = c(0,0)) +
    ggplot2::scale_y_continuous(expand = c(0,0)) +
    ggplot2::theme(panel.grid.major.x = element_line(color = "gray", linetype = "dotted"),
                   panel.grid.major.y = element_blank(),
                   panel.grid.minor.y = element_blank(),
                   panel.background = element_blank(),
                   panel.border = element_rect(fill = "transparent"),
                   axis.text.y = element_text(size = 13),
                   axis.title.y = element_text(size = 14),
                   plot.margin = unit(c(0.05,0.05,0.05,0.05), "mm"))

  # Combine the each subsection to make the final enrichment plot
  enrichment_plot <- patchwork::wrap_plots(list(enrichment_score_curve, pathway_hits, gene_rank_seesaw),
                                           nrow = 3,
                                           ncol = 1,
                                           axis_titles = "collect_x",
                                           heights = c(0.55,0.1,0.30))
  return(enrichment_plot)
}

#' @name geom_jabba_stats
#' @title Diagnostic plot used for evaluating the performance of a JaBbA run
#'
#' @description
#' Creates a ggplot quilt-like plot for quickly evaluating the run performance
#' and output graph characterisics of a JaBbA run.
#'
#' Note, this function was designed to be run as part of the `get_jabba_qc_diagnostic()`
#' workflow.
#'
#' @param path_to_stats_dt Path to the `qc_stats.txt` output from `get_jabba_qc_diagnostic()` run
#' @param karyograph_dt Karyograph data.table from `JaBbA` run
#'
#' @examples
#' # Snippet from within the function `get_jabba_qc_diagnostic` that calls this geom
#' # diagnostic_plot <- geom_jabba_stats(
#' # path_to_stats_dt = paste0(jabba_workdir_path, "qc_stats.txt"),
#' # karyograph_dt = data.table::data.table("cn" = kar$segstats$cn,
#' #                                        "cnmle" = kar$segstats$cnmle))
#'
#' @returns ggplot object
#' @export
geom_jabba_stats <- function(path_to_stats_dt, karyograph_dt) {
  # Read in stats file and transpose
  cli::cli_alert_info("Reading {.file {path_to_stats_dt}} {crayon::white(clisymbols::symbol$ellipsis)}")
  if(file.exists(path_to_stats_dt)){
    QCDF <- data.table::fread(path_to_stats_dt) %>%
      data.table::transpose(make.names = 1)
    QCDF[, Tier_1_Input_Junctions := as.numeric(Tier_1_Input_Junctions)]
    QCDF[, Tier_2_Input_Junctions := as.numeric(Tier_2_Input_Junctions)]
    QCDF[, Tier_3_Input_Junctions := as.numeric(Tier_3_Input_Junctions)]
    QCDF[, Tier_1_Output_Junctions := as.numeric(Tier_1_Output_Junctions)]
    QCDF[, Tier_2_Output_Junctions := as.numeric(Tier_2_Output_Junctions)]
    QCDF[, Tier_3_Output_Junctions := as.numeric(Tier_3_Output_Junctions)]
    QCDF[, Final_epgap := as.numeric(Final_epgap)]
    QCDF[, p_value_of_Pearson_r := as.numeric(p_value_of_Pearson_r)]
    QCDF[, p_value_of_Spearman_Rho := as.numeric(p_value_of_Spearman_Rho)]
    QCDF[, purity := as.numeric(purity)]
    QCDF[, ploidy := as.numeric(ploidy)]
  } else {
    stop(cli::cli_alert_danger("Check input"))
  }
  cli::cli_alert_success("Success")
  cat("\n")

  cli::cli_alert_info("Building QC plots {crayon::white(clisymbols::symbol$ellipsis)}")
  # Build headers and captions of plot
  signifr <- ifelse(QCDF$p_value_of_Pearson_r < 0.01, "Signif.", "Non-Signif.")
  signifRho <- ifelse(QCDF$p_value_of_Spearman_Rho < 0.01, "Signif.", "Non-Signif.")
  convergence <- ifelse(QCDF$Converged, "Reached", "Not Reached")
  subtext <- paste0("Convergence ", convergence, " (epgap delta=", signif(as.numeric(QCDF$Requested_epgap) - as.numeric(QCDF$Final_epgap), digits = 4), ")")
  captiontext <- paste0("rho=", QCDF$Spearman_Rho_of_Coverage_and_CN, " (", signifRho, ")\n", "r=", QCDF$Pearson_r_of_Coverage_and_CN, " (", signifr, ")")

  # Create scatter plot of output copy number of each segment compared to the maximum likelihood estimate
  karyograph_dt$cn <- factor(karyograph_dt$cn,
                             levels = sort(unique(karyograph_dt$cn)))

  cn_estimate_scatter <- ggplot2::ggplot(data = karyograph_dt %>%
                                           dplyr::filter(!is.na(cn))) +
    ggplot2::geom_jitter(aes(x = cn, y = cnmle, color = cn), width = 0.05, alpha = 0.5, size = 2.5, na.rm = T) +
    ggplot2::labs(title = "Copy Number vs MLE",
                  subtitle = subtext,
                  x = "Copy number",
                  y = "Maximum likelihood estimate") +
    ggplot2::scale_y_continuous(limits = c(0, round(max(karyograph_dt$cnmle, na.rm = T) + 0.25, 0))) +
    ggplot2::scale_color_manual(values = copynumber_palettier(cn_states = levels(karyograph_dt$cn))$color) +
    ggplot2::annotate(geom = "text",
                      x = 1.5,
                      y = max(karyograph_dt$cnmle, na.rm = T) - 0.1,
                      label = captiontext) +
    ggplot2::theme(legend.position = "none",
                   panel.background = element_rect(fill = "transparent"),
                   panel.border = element_rect(fill = "transparent"),
                   panel.grid.major = element_line(color = "gray", linetype = "dotted"),
                   plot.title = element_text(size = 14),
                   axis.text = element_text(size = 12),
                   axis.title = element_text(size = 13))


  # Create barplot of output versus input number of copy number segments
  segment_barplot_data <- data.table::data.table("frequency" = c(as.integer(as.numeric(QCDF$Number_of_Segments_Input)),
                                                                 as.integer(as.numeric(QCDF$Number_of_Segments_Output))),
                                                 "type" = c("Input", "Output"))

  segment_barplot <- ggplot2::ggplot(data = segment_barplot_data,
                                     aes(x = type, y = frequency, fill = type)) +
    ggplot2::geom_bar(stat = "identity", color = "black", width = 0.6) +
    ggfittext::geom_bar_text(aes(label = frequency), min.size = 10) +
    ggplot2::scale_fill_manual(values = c("#F05C3B", "#46732E")) +
    ggplot2::labs(title = "Genomic Segments",
                  y = "Count",
                  x = NULL) +
    ggplot2::theme(legend.position = "none",
                   panel.background = element_rect(fill = "transparent"),
                   panel.border = element_rect(fill = "transparent"),
                   plot.title = element_text(size = 14),
                   axis.text = element_text(size = 12),
                   axis.title = element_text(size = 13))

  # Create barplot of output versus input number of copy number segments
  junction_barplot_data <- data.table::data.table("frequency" = c(QCDF$Tier_3_Input_Junctions, QCDF$Tier_2_Input_Junctions, QCDF$Tier_1_Input_Junctions,
                                                                  QCDF$Tier_3_Output_Junctions, QCDF$Tier_2_Output_Junctions, QCDF$Tier_1_Output_Junctions),
                                                  "type" = c("Input","Input","Input","Output","Output","Output"),
                                                  "tier" = c(3,2,1,3,2,1))
  junction_barplot_data$tier <- factor(junction_barplot_data$tier,
                                       levels = c(3,2,1))

  junction_barplot <- ggplot2::ggplot(data = junction_barplot_data,
                                      aes(x = tier, y = frequency, fill = type)) +
    ggplot2::geom_bar(stat = "identity", color = "black", position = "dodge") +
    ggplot2::scale_fill_manual(name = NULL, values = c("#F05C3B", "#46732E")) +
    ggplot2::labs(title = "SV Junction Tiers",
                  subtitle = paste0("Number of non-telomeric loose ends=",QCDF$Non_telomeric_Loose_Ends),
                  y = "Count",
                  x = "Tier") +
    ggplot2::theme(legend.position = "right",
                   panel.background = element_rect(fill = "transparent"),
                   panel.border = element_rect(fill = "transparent"),
                   plot.title = element_text(size = 14),
                   axis.text = element_text(size = 12),
                   axis.title = element_text(size = 13))

  # Create a table of important values for quick evaluation
  QCDF$Final_epgap <- signif(QCDF$Final_epgap, digits = 4)
  QCDF$p_value_of_Spearman_Rho <- scales::scientific(QCDF$p_value_of_Spearman_Rho)
  QCDF$p_value_of_Pearson_r <- scales::scientific(QCDF$p_value_of_Pearson_r)
  QCDF$purity <- round(QCDF$purity, digits = 4)
  QCDF$ploidy <- round(QCDF$ploidy, digits = 4)

  eval_table <- ggpubr::ggtexttable(t(QCDF %>%
                                        dplyr::select(Tumor_Normal_ID,Final_epgap,Requested_epgap,
                                                      RMSE_of_Coverage_and_CN,p_value_of_Spearman_Rho,p_value_of_Pearson_r,
                                                      Non_telomeric_Loose_Ends,purity,ploidy)))

  diagnostic_plot <- patchwork::wrap_plots(list(eval_table, cn_estimate_scatter, junction_barplot, segment_barplot), nrow = 2)
  return(diagnostic_plot)
}

