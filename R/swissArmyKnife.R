######################################################################################
#                         ___   ___        ____   ____                               #
#                          | | |     |   /  |     |   | |   |                        #
# }}}}------->>>           + | |-+-  |  +   | +-  |-+-  |   |         <<<-------{{{{ #
#                          | | |     | /    |   | |  \  |   |                        #
#                         ---   ---   /      ---      \  ---                         #
######################################################################################
# ▒▓▓▒▒▒▒▒▒▒▒▓▓▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▓▒▒▒▒▒▒▒▒▒▒▒▒
# ▒▒▒▒▒░▒▒▒▒▓▓▒▒▒▒░░░░░░░░░░░░░░░░░░▒▒░░░░░░░░▒░░░░░░░▒░░░░░░░░░░░░░░░░░░▒▒▒▓▓▓▒▒▒▒▒▒▒
# ▒▒▒▒▒░░░░▒▒▒▒▒░░░░░░░░░░░░░░░░░░░░░▒▒▒▒▒▒▒▒▒▒▒▒▒▒░░░░░░░░░░░▒▒▒▒▒░░░░░░░░▒▒▒▓▓▒▒▒▒▒▒
# ▒▒▒▒▒░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░▒▓▓▓▓▓▓▓▒▒▒▒▒░░░░░░░░░▒▒▒▒▓▓▓▓▒░░░░░░░▒▒▓▓▓▒▒▒▓▓
# ▒▒▒▒▒░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░▒▒▒▓▒▓▓▓▓▓▓▓▓▒▒▒░░░░░░▒▓▓▓▒▒▒▓▓▓▒░░░░░░░▒▒▓▓▓▒▒▒▒
# ▒▒▒▒▒▒░░░░░░░▒▒░░░░░░░░░░░░░░░▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░░░░░▒▓▒░░░░▒▒▓▓▒░░░░░░░░▒▒▒▒▒▒▒
# ▒▒▒▒▒▒░░░░░▒▒▒▒▓▒░░░░░░░░░░░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░▒▒▒░░░░░░▒▓▓▒░░░░░░░░░▒▒▒▒▒▒
# ▒▒▒▒▒░░░░░░▒▓▓▓▓▓▒░░░░░▒▒▒▒░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░░░░░░░░░░░▒▓▓▒░░░░░░░░░▒▒▒▒▒▒
# ▒▒▒▒▒░░░░░░▒▓▓▓▓▓▓░░░░░▒▒▓▓▒▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░░░░░░░▒▒▒▒▓▒░░░░░░░░░░▒▒▒▒▒░
# ▒▒▒▒▒▒▒░░░░░░▒▓▓▓▒▒░░░░░░▒▒▒▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░░▒▒▒▒▓▓▓▓▓▒▒░░░░░░░░░▒▒▒▒▒░
# ▒▒▒▒▒▒▒░░░░░░▒▓▓▓▓▓▒░░░░░░░░░░░▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░░░░░▒▓▓▓▓▓▓▒▒░░░░░░░░░░░▒▒▒▒▒░
# ▒▒▒▒▒▒▒░░░░▒▒▓▓▓▓▓▓▓▒░░░░░░░░░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒▒▒░░░░░░▒▒▓▓▓▓▒▒░░░░░░░░░░░░▒▒▓▒▒▒▒
# ▒▒▒▒▒▒▒░░░▒▒▒▓▓▓▓▓▓▓▓▓▒░░░░░░░░▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░▒▒▓▓▓▓▒▒░░░░░░░░░░▒▒▒▒▓▒▒▒▒
# ▒▒▒▒▒▒▒░░░░░░░░░░▒▒▓▓▓▓▓▒▒▒▒▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▓▒░░░░░░░░░▒▒▓▓▓▒▒░░░░░░░░░▒▒▓▓▓▓▓▒▒▒
# ▒▒▒▒▒▒▒░░░░░░░░░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░░░░░░▒▓▓▓▒░░░░░░░░░░░▒▒▓▓▓▓▒▒
# ▒▒▒▒▒▒▒▒░░░░░░░░░░░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░░░░░░▒▒▓▓▓▒░░░░░░░░░░░░▒▓▓█▒▒
# ▒▒▒▒▒▒▒▒░░░░░░░░░░░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░▒▒░░░░░░░░░░░▒▓▓▒░░░░░░░░░░░▒▓▓▓▒▒
# ▒▒▒▒▒▒▒▒░░░░░░░░░░░░▒▒▒▒░▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒▒▒░░░░░░░░░░░▒▒▓▒▒░░░░░░░░░▒▓▓▓▒▒
# ▒▒▒▒▓▒▒▒░░░░░░░░░░░░░░░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒▒░░░░░░░░░░░░░▒▓▓▒▒░░░░░░░▒▓▓▓▒▒
# ▒▓▒▓▒▒▒▒▒▒▒▒░░░░░░░░░▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░░░░░░▒▓▓▒░░░░░░░▒▓▓▒▒▒▒
# ▒▒▒▒▒▒▒▒▒▓▓▓▓▒░░░░░░▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░░░░░░░░░▒▓▓▒▒░░░░░░▒▒▓▓▒▒
# ▒▒▒▒▓▒▒▒▒▓▓█▓▓▒▒░▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒▒▒▒▒▒▒▒▒▓▓▓▒▒░░░░░▒▒▓▓▒▒▒
# ▒▒▒▓▓▒▒░▒▒▒▓█▓▓▓▓▓▓██▓▓▓▓▓▓▓▓▓▓▒▒▒▒▒▒▒▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░░░░░▒▒▓▒▒▒
# ▒▒▒▒▓▒▒░░▒▒▓▓██████▓▓▓▒▒▒▒▒▒▒▒▒░░░░░░░░░▒▒▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░░░░░░▒▓▓▒▒▒
# ▒▒▒▒▓▒▒▒▒▒▒▓▓██▓▓▓▒▒░░░░░░░░░░░░░░░░▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░░▒▒▓▒▒▒
# ▒▒▒▒▓▒▒▒▒▒▓▓▓▓▓▒▒▒░░░░░░░░░░░░░░░░▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓█▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░░░░░▒▒▒▒▒▒
# ▓▓▒▒▓▓▓▒▒▒▒▒▒▒▒▒░░░░░░░░░░░░░░░░░░▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░░▒▒▒▒▓▒▒▒
# ▒▒▒▒▒▓▓▒▒▒▒▒░░▒░░░░░░░░░░░░░░░░░░░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░░░▒▓▒▓▓▒▒
# ▒▒▒▒▒▓▓▓▓▒▒▒░░░░░░░░░░░░░░░░░▒▒▒▒░░▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░▒▒▓▓▒▒
# ▒▒▒▒▒▓▒▒▒▓▒▒▒░░░░░░░░░░░░░░▒▒▓▓▓▓▓▒▒░░░▒▒▒▓▓▓▓▓▓▓▓▒▒▒░░░░░▒▒▒▓▓▓▓▓▓▓▓▓▓▓▒▒░░░▒▒▒▓▒▒▒
# ▓▒▒▒▓▓▓▒▒▓▒▒▒▒░░▒░░░░░░░░░░▒▒▒▓▓▓▓▓▓▒▒▒▒▒▒▒▒▓▓▓▓▓▓▓▓▒▒░░░░░░░░▒▒▓▓▓▓▓▓▓▒▒▓▒░░░▒▒▓▓▒▒
# ▓▒▒▒▓▓▒▒▓▓▒▒▒▒▒▒▒▒░░░░░░░░░░▒▒▒▒▒▓▓▓▓▓▓▓▓▓▒▓▓▓▓▓▓▓▓▒▒▒░░░░░░░░░░▒▒▓▓▓▓▓▓▒░░░░░▒▒▒▒▒▒
# ▓▒▒▒▓▓▒▒▓▓▓▒▒▒▒▒▒▒▒▒▒▒░░░░░▒▒▒▒▒▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░▒▒▒░░░▒▒▒▓▓▓▓▒▒░░░░▒▒▒▒▒▒
# ▓▒▒▒▓▓▓▒▓▓▒▒▒▒▓▒▒▒▒▒▒▒▒▒░░░▒▒▓▓▒▒▒▒▒▓▓▓▒▒▒▒▒▒▒▓▓▓▓▓▓▒░░░░░░▒▒▒░▒▒▒▒▒▓▓▓▓▓▓▒▒▒░▒▒▒▒▒▒
# ▓▒▒▒▒▓▓▓▓▓▓▓▒▒▓▒▒▒▒▒▒▒▒▒░░░▒░▒▒▒▒▒▒▒▒▒▒▒░░░░░░▒▒▒▓▒▒▒░░░░░░░░░▒▒▒▓▓▓▓▓▓▓▓▓▓▓▒▒▒▒▒▒▒▒
# ▒▓▒▒▒▓▓▓▓▒▒▓▓▓▓▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒░░▒▒░░░░░░░░░░░░░░░▒░▒▒▒▒▒▒▓▓▓▓▓▓▓▒▓▓▓▓▓▓▓▒▒▒▒▒
# ▒▒▒▒▒▓▓▓▓▓▓▓▓▓▓▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒░▒▒▒▒▒▒▒▒▒▒▒░░░░░▒░░░░░░░▒▒▒▒▓▓▓▓▓▒▒▒▒▒▒░▒▒▓▓▓▓▒▒▒▒▒
# ▒▒▒▒▒▒▒▓▓▓▓▓▒▒▒▓▒▓▓▓▓▓▓▒▒▒▓▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒░░░░░░▒▒▒░░░░▒▒▒▒▓▓▒▓▒▒▓▓▓▓▒▒▒▒▒▓▒▒▓▒▒▒▒▒▒
# ▓▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▓▓▓▒▓▓▓▓▒▒▒▓▓▓▓▓▓▒▒▒▒▓▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒
#                                                                                    #
# }}}}------->>>                                                      <<<-------{{{{ #

#' @import gUtils
#' @import GenomicRanges
#' @import GenomeInfoDb
#' @import data.table
#' @import VariantAnnotation
#' @import stringr
#' @import dplyr
#' @import ggplot2
#' @import scales
#' @import paletteer
#' @import patchwork
#' @import ggpubr
#' @import ggside
#' @import stats
#' @import crayon
#' @import cli
#' @import pio

#' @importFrom pak pkg_install
#' @importFrom BSgenome.Hsapiens.UCSC.hg38 Hsapiens
#' @importFrom rtracklayer import
#' @importFrom readr read_delim
#' @importFrom S4Vectors mcols
#' @importFrom Biostrings toString
#' @importFrom doParallel registerDoParallel
#' @importFrom foreach foreach
#' @importFrom foreach `%dopar%`
#' @importFrom paint paint
#' @importFrom reshape2 melt
#' @importFrom purrr as_vector
#' @importFrom ggridges stat_density_ridges
#' @importFrom ggfittext geom_bar_text
#' @importFrom hms hms
#' @importFrom utils packageVersion
#' @importFrom DNAcopy CNA smooth.CNA segment


# Appease R CMD CHECK misunderstanding of data.table/data.frame/ggplot2 syntax by declaring these 'global' variables
# Split these into multiple rows just for better aesthetics as there are many
x=DeletionRate=FractionCovered=InsertionRate=Mapped=MappedForwardFraction=MappedProperFraction=NULL
MappedReverseFraction=MedianCoverage=MedianInsertSize=Sample=alignment_group=fraction=med_reads=NULL
alignment_group=fraction=med_reads=median_count=tumor_normal=ALT=CALLER=REF=SAMPLE=total_indels=NULL
total_per_caller=total_snvs=gene_biotype=type=gene_name=AD_ALT_TUMOR=AD_TUMOR=AF_TUMOR=DP_TUMOR=NULL
FREQ_TUMOR=PM_TUMOR=TIR_TIER1_TUMOR=nearest_gene=NULL

# Set up the global default genome and number display
.onLoad <- function(libname, pkgname) {
  op <- options()
  op.devgru <- list(
    devgru.ref_genome = "hg38"
  )
  toset <- !(names(op.devgru) %in% names(op))
  if (any(toset)) options(op.devgru[toset])

  Sys.setenv(DEFAULT_BSGENOME = 'BSgenome.Hsapiens.UCSC.hg38::Hsapiens')
  Sys.setenv(DEFAULT_GENOME = 'BSgenome.Hsapiens.UCSC.hg38::Hsapiens')
  options(scipen = 999)

  invisible()
}

#
#
# }}}}------->>> Data for analysis and demos
#
#

#' DNAaseI hypersensitivity sites on hg38
#'
#' DNAaseI hypersensitivity sites in the H562 cell line from UCSC Table Browser
#' hg19 that has been lifted over to hg38 using `rtracklayer::liftOver()`
#'
#' @name example_dnase_hg38
#' @docType data
#' @keywords data
#' @format \code{GRanges}
NULL

#' DNAaseI hypersensitivity sites for KRAS on hg19 as GRanges
#'
#' DNAaseI hypersensitivity sites in the H562 cell line from UCSC Table Browser
#' hg19, subset to the KRAS locus with 1000 bp flank.
#'
#' @name kras_dnase_demo_gr_hg19
#' @docType data
#' @keywords data
#' @format \code{GRanges}
NULL

#' DNAaseI hypersensitivity sites for KRAS on hg38 as GRanges
#'
#' DNAaseI hypersensitivity sites in the H562 cell line from UCSC Table Browser
#' hg38 liftover, subset to the KRAS locus with 1000 bp flank.
#'
#' @name kras_dnase_demo_gr_hg38
#' @docType data
#' @keywords data
#' @format \code{GRanges}
NULL

#' DNAaseI hypersensitivity sites for BRAF on hg19 as data.table
#'
#' DNAaseI hypersensitivity sites in the H562 cell line from UCSC Table Browser
#' hg19, subset to the BRAF locus with 1000 bp flank.
#'
#' @name braf_dnase_demo_dt_hg19
#' @docType data
#' @keywords data
#' @format \code{data.table}
NULL

#' DNAaseI hypersensitivity sites for BRAF on hg38 as data.table
#'
#' DNAaseI hypersensitivity sites in the H562 cell line from UCSC Table Browser
#' hg38 liftover, subset to the BRAF locus with 1000 bp flank.
#'
#' @name braf_dnase_demo_dt_hg38
#' @docType data
#' @keywords data
#' @format \code{data.table}
NULL

#' Collection of genomic regions to exclude from analysis on hg38 as GRanges
#'
#' A convenient single collection of genomic regions suggested to exclude from
#' analysis due to mappability issues, enrichment of duplicated regions,
#' telomeric, centromeric, acrocentric short-arms, and highly heterochromatin/gene
#' desert portions of the chromosomes.
#'
#' Built from UCSC and ENCODE blacklists.
#' See excluderanges (https://github.com/dozmorovlab/excluderanges).
#'
#' @name exclusion_regions_hg38
#' @docType data
#' @keywords data
#' @format \code{GRanges}
NULL

#' Genomic coordinates of each chromosome arm on hg38 as GRanges
#'
#' A convenient single collection of the genomic span of each chromosome arm.
#' The span is described as:
#'                     |  ranges kept  |
#' p-arm         start |<------------->| centromere
#' q-arm    centromere |<------------->| end
#'
#' Note, this data does not include a range across the centromeres, for these
#' see `exclusion_regions_hg38`.
#'
#' @name chromosome_arms_hg38
#' @docType data
#' @keywords data
#' @format \code{GRanges}
NULL

#' dryclean-fragCounter read depth profile on hg38 as GRanges
#'
#' A slice of data from a `dryclean` adjusted `fragCounter` read depth profile
#' of a tumor sample.
#' The demo contains slices from chr19 and chr22.
#'
#' See `fragCounter` (https://github.com/mskilab-org/fragCounter)
#' and `dryclean` (https://github.com/mskilab-org/dryclean)
#'
#' @name read_depth_demo_hg38
#' @docType data
#' @keywords data
#' @format \code{GRanges}
NULL

#
#
# }}}}------->>> CLI for talking the user through the package
#
#

#' @name cli_pio_colorscheme
#' @title Set the color scheme options for pio CLI text in devgru
#'
#' @description
#' Quickly set the options for pio package CLI text output.
#'
#' @examples
#' cli_pio_colorscheme()
#'
#' @export
cli_pio_colorscheme <- function () {
  options(pio.header_bg_colour = crayon::bgBlack)
  options(pio.header_fg_colour = crayon::cyan)
  options(pio.title_sep_colour = crayon::cyan)
  options(pio.title_fg_colour = crayon::cyan)
  options(pio.string_bg_colour = crayon::bgBlack)
  options(pio.string_fg_colour = crayon::cyan)
}

#' @name cli_stopwatch_start
#' @title Verbose CLI output to designate a workflow start
#'
#' @description
#' Display to the user the workflow has begun, the function that launched it, and
#' start the stopwatch to track execution time,
#'
#' @param package What is the package of the function, default: devgru
#' @param function_name What is the function name
#'
#' @examples
#' process_start <- cli_stopwatch_start(package = "devgru", function_name = "workflow_demo_func")
#' process_start
#'
#' @export
cli_stopwatch_start <- function(package = "devgru", function_name) {
  # Time stamp start
  cli::cli_rule("{crayon::green('Start')}")
  cli::cli_text("{crayon::cyan({package})} :: {.emph {.pkg {function_name}()}} ",
                as.character(Sys.time()))
  # Stopwatch start
  stopwatch_start <- proc.time()
  return(stopwatch_start)
}

#' @name cli_stopwatch_end
#' @title Verbose CLI output to designate a workflow end
#'
#' @description
#' Display to the user the workflow has ended, stop the stopwatch, and display execution time.
#'
#' @param package What is the package of the function, default: devgru
#' @param function_name What is the function name
#' @param stopwatch_start What was the start time of the stopwatch, typically captured
#'  and passed along by `cli_stopwatch_start()`, see examples
#'
#' @examples
#' process_start <- cli_stopwatch_start(package = "devgru",
#'                                      function_name = "workflow_demo_func")
#' process_end <- cli_stopwatch_end(package = "devgru",
#'                                  function_name = "workflow_demo_func",
#'                                  stopwatch_start = process_start)
#'
#' @export
cli_stopwatch_end <- function(package = "devgru", function_name, stopwatch_start) {
  # Time stamp stop
  cli::cli_rule("{crayon::red('Stop')}")
  cli::cli_text("{crayon::cyan({package})} :: {.emph {.pkg {function_name}()}} ",
                as.character(Sys.time()))
  stopwatch_end <- proc.time() - stopwatch_start

  # Convert to human table of hours,minutes,seconds
  hms_table <- stringr::str_split(string = hms::hms(stopwatch_end[3]), pattern = ":", simplify = T)
  colnames(hms_table) <- c("hours","minutes","seconds")
  cli::cli_alert_info("Duration {crayon::white(clisymbols::symbol$ellipsis)}")
  paint::paint(as.data.table(hms_table))
}


#' @name function_cli_intro
#' @title Verbose CLI output for extended and rich description of steps along a
#'  complex workflow, typically used in a pipeline
#'
#' @description
#' Display to the user the main package, the function being executed, and the parameters
#' passed to the function.
#'
#' @param package What is the package of the function, default: devgru
#' @param function_name What is the function name
#' @param ... What parameters were used in the function
#'
#' @examples
#' # For demo purposes, set these variables
#' parameter_x <- 100
#' parameter_y <- "demo"
#'
#' # In practice, these variables are set within the function being called as in below:
#' # workflow_demo_func <- function(parameter_x, parameter_y)
#' # then the function_cli_intro is called within the function
#'
#' function_cli_intro(package = "devgru",
#'                    function_name = "workflow_demo_func",
#'                    parameter_x, parameter_y)
#'
#' @export
function_cli_intro <- function(package = "devgru", function_name, ...) {
  # Show package
  cli_pio_colorscheme()
  pio::pioHdr(package, paste0("v",utils::packageVersion(package)))
  cli::cli_rule()
  cat("\n")
  # Show function
  cli::cli_alert(text = "Launching {.emph {.pkg {function_name}()}} {crayon::white(clisymbols::symbol$ellipsis)}")
  cat("\n")
  # show params if provided
  params <- list(...)
  params_names <- lapply(substitute(list(...))[-1], deparse)
  if(length(params) != 0) {
    # Construct the parameter CLI
    params_string <- c()
    for(i in 1:length(params)) {
      params_string <- append(x = params_string,
                              values = paste0("{crayon::green('", params_names[i], "')} = ", params[i]))
    }
    cli::cli_text("*****************************  {crayon::green('PARAMS')}  *****************************")
    cli::cli_ul(params_string)
    cli::cli_text("*****************************************************************")
    cat("\n")
  }
}

#' @name kit_loadout
#' @title Build the devgru environment by installing/loading packages
#'
#' @description
#' Single command to install, if needed, and load all packages used in the devgru kit.
#'
#' @param update_kit Update all packages even if already installed, default: FALSE
#'
#' @examples
#' # Quick start devgru environment
#' # kit_loadout()
#'
#' # Update the suite of packages used in the kit
#' # kit_loadout(update_kit = T)
#'
#' @export
kit_loadout <- function(update_kit = F) {
  process_start <- cli_stopwatch_start(function_name = "kit_loadout")
  logo_viz <- "
                   ___   ___        ____   ____
                    | | |     |   /  |     |   | |   |
 }}}}------->>>     + | |-+-  |  +   | +-  |-+-  |   |    <<<-------{{{{
                    | | |     | /    |   | |  \\  |   |
                   ---   ---   /      ---      \\  ---
"
  # Packages for loadout
  loadout <- c("BSgenome.Hsapiens.UCSC.hg38", "GenomicRanges", "GenomeInfoDb",
               "data.table", "mskilab-org/gUtils", "VariantAnnotation",
               "rtracklayer", "Biostrings", "S4Vectors", "dplyr",
               "stringr", "readr", "ggplot2", "ggsci", "paletteer", "scico",
               "flextable", "mclust", "parallel", "doParallel", "foreach",
               "R.utils")

  # The set of packages used to work on GenomicRanges objects
  gr_core_pkgs <- data.frame("GenomicRanges Core" = c("BSgenome.Hsapiens.UCSC.hg38","GenomicRanges",
                                                      "GenomeInfoDb","data.table","mskilab-org/gUtils",
                                                      "VariantAnnotation","rtracklayer","Biostrings",
                                                      "S4Vectors"))
  # The set of packages used to add more functionality on top to GenomicRanges objects
  util_core_pkgs <- data.frame("Utility Core" = c("dplyr","stringr","readr","ggplot2","ggsci",
                                                  "paletteer","scico","flextable","mclust","parallel",
                                                  "doParallel","foreach","R.utils"))
  # Output the logo
  cat(logo_viz)
  # CLI to show the packages in the kit
  cat("\n")
  cli::cli_alert_info("Building the {.pkg devgru} kit {crayon::white(clisymbols::symbol$ellipsis)}")
  cli::cli_alert_info("Loadout currently includes:")
  options(paint_max_width = 1000)
  paint::paint(gr_core_pkgs)
  paint::paint(util_core_pkgs)
  # Load the packages with librarian
  pak::pkg_install(pkg = loadout, upgrade = update_kit)
  cat("\n")
  process_end <- cli_stopwatch_end(function_name = "kit_loadout",
                                   stopwatch_start = process_start)
}

#
#
# }}}}------->>> Tools for surveying the GenomicRanges
#
#

#' @name gr_refactor_seqs
#' @title Refactor seqinfo, seqnames, seqlengths, seqlevels of GRanges object for easy harmony
#'
#' @description
#' Single command to refactor all seq details of a GRanges object to easily harmonize with any other GRanges object.
#' By default, this package uses the autosome (1-22) and sex chromosomes (X,Y) of hg38, see `gUtils::hg_seqlengths()`
#' Users can adjust this using the `new_levels` parameter.
#'
#' @param input_gr GenomicRanges object to refactor
#' @param new_levels Named vector object used as the template for new seq details, see `gUtils::hg_seqlengths()` for example
#'
#' @examples
#' # Converting between reference genomes is complicated and proper seqinfo is hard
#' # to achieve without many lines of code, this function helps alleviate the issue
#'
#' # Look at seqinfo from a hg19 dataset
#' GenomeInfoDb::seqinfo(kras_dnase_demo_gr_hg19)
#'
#' # Look at seqinfo after lift over to hg38
#' GenomeInfoDb::seqinfo(example_dnase_hg38)
#'
#' # Use gr_refactor_seqs to fix the inconsistencies
#' GenomeInfoDb::seqinfo(gr_refactor_seqs(example_dnase_hg38))
#'
#' @return GenomicRanges object with updated seqinfo, seqnames, seqlengths, seqlevels
#' @export
gr_refactor_seqs <- function(input_gr, new_levels = gUtils::hg_seqlengths()) {
  # First, make sure we match input GR 'chr' notation with the desired seqs
  if(length(grep(x = names(new_levels), pattern = "^chr")) > 0) {
    gr <- gUtils::gr.chr(input_gr)
  } else {
    gr <- gUtils::gr.nochr(input_gr)
  }

  # Now start to reset seqnames
  gr <- GenomeInfoDb::dropSeqlevels(x = gr,
                                    value = GenomeInfoDb::seqlevels(gr)[!GenomeInfoDb::seqlevels(gr) %in% names(new_levels)[1:24]],
                                    pruning.mode = "coarse")

  # Now start to reset seqnames
  gr@seqnames@values <- factor(x = gr@seqnames@values,
                               levels =  names(new_levels)[1:24][GenomeInfoDb::seqlevels(gr) %in% names(new_levels)[1:24]])

  # Sort the new seqinfo
  gr@seqinfo <- GenomeInfoDb::sortSeqlevels(gr@seqinfo, X.is.sexchrom = T)

  # Now ensure seqinfo matches seqnames
  gr@seqinfo <- GenomeInfoDb::Seqinfo(seqnames = names(new_levels)[1:24],
                                      seqlengths = new_levels[1:24])

  # Final sort to ensure ranges are properly sorted by genomic coordinate
  gr <- GenomicRanges::sort.GenomicRanges(gr, ignore.strand = TRUE)

  # And complete the remaining seqinfo columns for genome and isCircular
  GenomeInfoDb::genome(gr) <- "GRCh38"
  GenomeInfoDb::isCircular(gr) <- rep(FALSE,24)
  return(gr)
}

#' @name dt_to_gr
#' @title Convert data.table to GRanges Object
#'
#' @description
#' Single command to smartly convert a data.table object to a GRanges object by
#' wrapping `gr_refactor_seqs()` around the `gUtils::dt2gr()` to avoid seqinfo conflicts
#' and apply proper sorting.
#'
#' @param input_dt data.table object that minimally contains columns like chromosome start, and end position
#'  that describe the genomic coordinates of the range
#'
#' @examples
#' # Converting from data.table to GRanges can be easily done with gUtils::dt2gr()
#' # however this single command conversion leaves some loose ends with the seqinfo
#'
#' # Look at the original data.table
#' braf_dnase_demo_dt_hg38
#' # Now convert to GRanges
#' dt_to_gr(braf_dnase_demo_dt_hg38)
#' # Check the seqinfo
#' GenomeInfoDb::seqinfo(dt_to_gr(braf_dnase_demo_dt_hg38))
#'
#' # Compared to the old way
#' # Conversion looks fine
#' gUtils::dt2gr(braf_dnase_demo_dt_hg38)
#' # However the seqinfo will conflict with other hg38 GRanges
#' GenomeInfoDb::seqinfo(gUtils::dt2gr(braf_dnase_demo_dt_hg38))
#'
#' @export
dt_to_gr <- function(input_dt) {
  # Wrap the dt2gr function with the gr_refactor_seqs function
  gr <- gr_refactor_seqs(input_gr = gUtils::dt2gr(input_dt, seqlengths = gUtils::hg_seqlengths()[1:24]),
                         new_levels = gUtils::hg_seqlengths()[1:24])
  return(gr)
}

#' @name gr_sanitycheck
#' @title Check if input is a GRanges object, plus optional sanity check of column names
#'
#' @description
#' Simple check if the input is a GRanges object, plus includes an additional functionality
#' to perform a smart, transparent sanity check of expected column names.
#'
#' @param query_gr Suspected GRanges-like object to test
#' @param expected_cols Vector of character strings to check for consistency in
#'  columns of query GRanges, default: NULL
#'
#' @examples
#' # Not a GR
#' gr_sanitycheck(query_gr = braf_dnase_demo_dt_hg38)
#' # Just a GR
#' gr_sanitycheck(query_gr = kras_dnase_demo_gr_hg38)
#' # GR with correct columns
#' gr_sanitycheck(query_gr = kras_dnase_demo_gr_hg38,
#'                expected_cols = c("signalValue","pValue","biospecimen","gene"))
#' # GR with less columns than expected
#' gr_sanitycheck(query_gr = kras_dnase_demo_gr_hg38[,-3],
#'                expected_cols = c("signalValue","pValue","biospecimen","gene"))
#'
#' @export
gr_sanitycheck <- function(query_gr, expected_cols = NULL) {
  # Generic check if query is a GR obj
  # No constrait on expected number of columns
  if(is.null(expected_cols)) {
    if(inherits(query_gr, "GenomicRanges")) {
      return(TRUE)
    } else {
      return(FALSE)
    }
    # Specific check if query is a GR obj
    # Must have expected number of columns
    # Should only be used for defined workflows
  } else if(!is.null(expected_cols)) {
    # First check if GR, then add constraints
    if(inherits(query_gr, "GenomicRanges")) {
      # Check if columns are equal
      if(length(colnames(S4Vectors::mcols(query_gr))) == length(expected_cols)) {
        # Check if columns are same as expected
        if(all.equal(target = expected_cols, current = colnames(S4Vectors::mcols(query_gr)))) {
          return(TRUE)
        } else {
          pio::pioDisp(gUtils::gr2dt(query_gr))
          cli::cli_alert_danger(all.equal(target = expected_cols, current = colnames(S4Vectors::mcols(query_gr))))
          return(FALSE)
        }
        # Columns are not equal
      } else if(length(colnames(S4Vectors::mcols(query_gr))) > length(expected_cols)) {
        extra_cols <- colnames(S4Vectors::mcols(query_gr))[which(!colnames(S4Vectors::mcols(query_gr)) %in% expected_cols)]
        pio::pioDisp(gUtils::gr2dt(query_gr))
        cli::cli_alert_danger("Input GenomicRanges object had more columns than expected - extra columns: {crayon::red({extra_cols})}")
        return(FALSE)
      } else if(length(colnames(S4Vectors::mcols(query_gr))) < length(expected_cols)) {
        missing_cols <- expected_cols[which(!expected_cols %in% colnames(S4Vectors::mcols(query_gr)))]
        pio::pioDisp(gUtils::gr2dt(query_gr))
        cli::cli_alert_danger("Input GenomicRanges object had less columns than expected - missing columns: {crayon::red({missing_cols})}")
        return(FALSE)
      }
    } else {
      return(FALSE)
    }
  }
}

#' @name dt_sanitycheck
#' @title Check if input is a data.table object, plus optional sanity check of column names
#'
#' @description
#' Simple check if the input is a data.table object, plus includes an additional functionality
#' to perform a smart, transparent sanity check of expected column names.
#'
#' @param query_dt Suspected data.table-like object to test
#' @param expected_cols Vector of character strings to check for consistency in
#'  columns of query data.table, default: NULL
#'
#' @examples
#' # Not a DT
#' dt_sanitycheck(query_dt = kras_dnase_demo_gr_hg38)
#' # Just a DT
#' dt_sanitycheck(query_dt = braf_dnase_demo_dt_hg38)
#' # DT with correct columns
#' dt_sanitycheck(query_dt = braf_dnase_demo_dt_hg38,
#'                expected_cols = c("seqnames","start","end","strand","signalValue",
#'                                  "pValue","biospecimen","gene"))
#' # DT with less columns than expected
#' dt_sanitycheck(query_dt = braf_dnase_demo_dt_hg38[,-7],
#'                expected_cols = c("seqnames","start","end","strand","signalValue",
#'                                  "pValue","biospecimen","gene"))
#'
#' @export
dt_sanitycheck <- function(query_dt, expected_cols = NULL) {
  # Generic check if query is a DT obj
  # No constrait on expected number of columns
  if(is.null(expected_cols)) {
    if(inherits(query_dt, "data.table")) {
      return(TRUE)
    } else {
      return(FALSE)
    }
    # Specific check if query is a DT obj
    # Must have expected number of columns
    # Should only be used for defined workflows
  } else if(!is.null(expected_cols)) {
    # First check if DT, then add constraints
    if(inherits(query_dt, "data.table")) {
      # Check if columns are equal
      if(length(colnames(query_dt)) == length(expected_cols)) {
        # Check if columns are same as expected
        if(all.equal(target = expected_cols, current = colnames(query_dt))) {
          return(TRUE)
        } else {
          pio::pioDisp(query_dt)
          cli::cli_alert_danger(all.equal(target = expected_cols, current = colnames(query_dt)))
          return(FALSE)
        }
        # Columns are not equal
      } else if(length(colnames(query_dt)) > length(expected_cols)) {
        extra_cols <- colnames(query_dt)[which(!colnames(query_dt) %in% expected_cols)]
        pio::pioDisp(query_dt)
        cli::cli_alert_danger("Input data.table object had more columns than expected - extra columns: {crayon::red({extra_cols})}")
        return(FALSE)
      } else if(length(colnames(query_dt)) < length(expected_cols)) {
        missing_cols <- expected_cols[which(!expected_cols %in% colnames(query_dt))]
        pio::pioDisp(query_dt)
        cli::cli_alert_danger("Input data.table object had less columns than expected - missing columns: {crayon::red({missing_cols})}")
        return(FALSE)
      }
    } else {
      return(FALSE)
    }
  }
}

# TODO: add more intelligent setting of boundaries by storing the values of the
#       chromosome arms and finding these boundaries for each chromosome and arm in a GR
#' @name gr_flank
#' @title Precise addition of flanking to GRanges with boundary-aware options
#'
#' @description
#' Precise addition of flanks to the start and/or end of a GRanges object with the option
#' of setting a boundary for the flanks, helpful to account for boundaries like chromosome arms.
#'
#' Note, the boundaries are compared directly to the new flanked start/end and do not currently
#' take the chromosome into account automatically. Thus, this function is best applied in on
#' per chromosome basis.
#'
#' If the flank exceeds the boundary, the new flanked start/end will set at the boundary.
#'
#' @param input_gr GRanges object to add flanks to
#' @param start_flank Amount of flank (in bp) to be added to the start of the ranges, default:NULL
#' @param end_flank Amount of flank (in bp) to be added to the end of the ranges, default:NULL
#' @param start_flank_boundary The genomic coordinate the start of the flanked GRanges should
#'  to not exceed, default: NULL
#' @param end_flank_boundary The genomic coordinate the end of the flanked GRanges should
#'  to not exceed, default: NULL
#'
#' @examples
#' # The gene NOTCH2 is close to the p-arm centromere on chr1
#' notch2 <- gUtils::parse.gr("chr1:119911553-120069662")
#' notch2
#' chr1_p_arm <- gUtils::`%Q%`(chromosome_arms_hg38, seqnames == "chr1" & arm == "p")
#' chr1_p_arm
#' GenomicRanges::end(chr1_p_arm)
#'
#' # If sampling data around this locus in a 3 Mb window, it's important to not
#' # extend into/beyond the centromere so we need to set this boundary
#' gr_flank(input_gr = notch2,
#'          start_flank = 3e6,
#'          end_flank = 3e6,
#'          start_flank_boundary = GenomicRanges::start(chr1_p_arm),
#'          end_flank_boundary = GenomicRanges::end(chr1_p_arm))
#'
#' @export
gr_flank <- function(input_gr, start_flank = NULL, end_flank = NULL, start_flank_boundary = NULL, end_flank_boundary = NULL) {
  # Check the input object. If data.table, continue on. If not, convert
  if(gr_sanitycheck(query_gr = input_gr)) {
    input_dt <- gUtils::gr2dt(input_gr)
  } else if(dt_sanitycheck(query_dt = input_gr)) {
    input_dt <- input_gr
  }

  # Check user has set one of the flank values
  if(is.null(start_flank) & is.null(end_flank)) {
    stop(cli::cli_alert_danger("Must set either {crayon::cyan('start_flank')} or {crayon::cyan('end_flank')} {crayon::white(clisymbols::symbol$ellipsis)}"))
  }

  # First, add the flank to the start of the DT obj to get the potential new loci value
  # this can end up being a negative number
  # Catch this behavior here and enforce a boundary if detected
  flanked_start <- input_dt$start - start_flank

  # If flanked start point is within the boundary
  if(!is.null(start_flank_boundary) & flanked_start >= start_flank_boundary) {
    new_start <- flanked_start

  # if flanked start is outside the boundary, set the new start to this edge
  } else if(!is.null(start_flank_boundary) & flanked_start < start_flank_boundary) {
    new_start <- start_flank_boundary

  # if boundary is not set, keep flanked start but must apply trim to keep on chromosome scale
  } else if(is.null(start_flank_boundary)) {
    new_start <- flanked_start
  }

  # Apply same process for the end of the GR obj
  flanked_end <- input_dt$end + end_flank

  # If flanked end point is within the boundary
  if(!is.null(end_flank_boundary) & flanked_end <= end_flank_boundary) {
    new_end <- flanked_end

  # if flanked end is outside the boundary, set the new end to this edge
  } else if(!is.null(end_flank_boundary) & flanked_end > end_flank_boundary) {
    new_end <- end_flank_boundary

  # if boundary is not set, keep flanked start but must apply trim to keep on chromosome scale
  } else if(is.null(end_flank_boundary)) {
    new_end <- flanked_end
  }

  # Now update the values
  input_dt$start <- new_start
  input_dt$end <- new_end

  # Convert back to GR obj
  # Apply the trim if unbound
  if(is.null(start_flank_boundary) | is.null(end_flank_boundary)) {
    flanked_gr <- GenomicRanges::trim(dt_to_gr(input_dt))
  } else {
    flanked_gr <- dt_to_gr(input_dt)
  }
  return(flanked_gr)
}








#
#
# }}}}------->>> Complex function workflows
#
#

#' @name get_cbs_per_chromosome
#' @title Single chromosome run circular binary segmentation (CBS) algorithm on read depth profile
#'
#' @description
#' Run CBS algorithm using DNAcopy on a per-chromosome basis on read depth profile. This
#' allows for parallel computation of the segmentation, rapidly reducing run time.
#' There should be no `NA`s in the columns or `0`s in the `signal` column.
#'
#' Note, this function was designed to be run as part of the `get_dryclean_segmentation()`
#' workflow. Also, see `chrompar()` for executing in parallel.
#'
#' @param chrom_for_cbs The chromosome to run CBS algorithm on
#' @param chromosome_names A vector of chromosome strings, equivalent to the seqnames
#'  column. Must contain at least the `chrom_for_cbs`
#' @param signal A vector of read depth signal to be used as input, equivalent to
#'  the foreground or read ratio column. These values will be `log`ged before use in CBS
#' @param position A vector of the genomic position of the signal measurement, equivalent
#'  to the start column
#' @param sample_id A string used to populate the ID column in the data.table
#'
#' @examples
#' # For this example, there are no NAs or zeros in the `signal`
#' # Check for these and may need to filter them out
#' read_depth_demo_hg38
#'
#' # Example of what the input looks like for
#' # chromosome_names
#' head(as.character(GenomicRanges::seqnames(read_depth_demo_hg38)))
#' # signal
#' head(as.double(GenomicRanges::values(read_depth_demo_hg38)[, "foreground"]))
#' # position
#' head(GenomicRanges::start(read_depth_demo_hg38))
#'
#' @export
get_cbs_per_chromosome <- function(chrom_for_cbs, chromosome_names, signal, position, sample_id) {
  # Function CLI
  cli::cli_text("{clisymbols::symbol$pointer} {.emph {crayon::green({chrom_for_cbs})}}")

  # Grab chromosome specific data for run the DNAcopy CBS workflow
  idx_per_chrom <- which(chromosome_names == chrom_for_cbs)
  log_signal_per_chrom <- log(signal)[idx_per_chrom]
  chromosome_names_per_idx <- chromosome_names[idx_per_chrom]
  position_per_chrom <- position[idx_per_chrom]

  # Run DNAcopy CBS workflow
  cna_per_chrom <- DNAcopy::CNA(genomdat = log_signal_per_chrom,
                                chrom = chromosome_names_per_idx,
                                maploc = position_per_chrom,
                                data.type = 'logratio')

  cna_segmentation_per_chrom <- DNAcopy::segment(x = DNAcopy::smooth.CNA(cna_per_chrom),
                                                 alpha = 1e-5,
                                                 undo.splits = "sdundo",
                                                 undo.SD = 3,
                                                 verbose = FALSE)
  cna_segmentation_per_chrom_dt <- data.table::as.data.table(cna_segmentation_per_chrom$output)
  cna_segmentation_per_chrom_dt$ID <- sample_id

  # Return output per-chromosome CBS DT
  return(cna_segmentation_per_chrom_dt)
}














# TODO: NEED TO MAKE SURE THIS WORKS
#' @name get_qc_diagnostics_alignment
#' @title Generate diagnostic plots for alignment QC checks using Alfred summary files
#'
#' @description
#' Single command to generate a comprehensive set of diagnostic plots that assist in
#' performing QC checks of tumor/normal read alignment of various sequencing protocol flavors
#' using Alfred summary files.
#'
#' @param path_to_tumor_dir Path to directory of tumor sample Alfred summary files
#' @param path_to_normal_dir Path to directory of normal sample Alfred summary files
#' @param seq_protocol Type of sequencing protocol for display purposes, default: WGS
#'
#' @return Patchwork 'quilt'-like plot of ggplots
#' @export
get_qc_diagnostics_alignment <- function(path_to_tumor_dir = NULL, path_to_normal_dir = NULL, seq_protocol = "WGS") {

  # Set figure base theme
  ggplot2::theme_set(
    ggplot2::theme_gray() +
      ggplot2::theme(axis.line = ggplot2::element_line(linewidth = 0.5,  color = "black"),
                     panel.background = ggplot2::element_rect(fill = NA, linewidth = rel(14)),
                     panel.grid.minor = ggplot2::element_line(color = NA),
                     axis.text = ggplot2::element_text(size = 12,  color = "black"),
                     axis.title = ggplot2::element_text(size = 14),
                     axis.ticks = ggplot2::element_line(linewidth = 0.75),
                     title = ggplot2::element_text(size = 16)))

  # User provides paths to directory with T/N Alfred alignment QC summary files
  if(!is.null(path_to_tumor_dir) & !is.null(path_to_normal_dir)) {
    # Read in and aggregate the tumor/normal alfred QC summary files
    message("Aggregate input QC summary metrics ...")
    tumor_alfreds <- aggregate_these(path_to_files = path_to_tumor_dir,
                                     pattern_to_grab = "*.alfred.qc.summary.txt",
                                     delim = "\t",
                                     has_header = T,
                                     add_uniq_id = F)
    tumor_alfreds$tumor_normal <- "Tumor"
    message("Found ", dplyr::n_distinct(tumor_alfreds$Sample), " tumor samples ...")

    normal_alfreds <- aggregate_these(path_to_files = path_to_normal_dir,
                                      pattern_to_grab = "*.alfred.qc.summary.txt",
                                      delim = "\t",
                                      has_header = T,
                                      add_uniq_id = F)
    normal_alfreds$tumor_normal <- "Normal"
    message("Found ", dplyr::n_distinct(normal_alfreds$Sample), " normal samples ...")

  } else if(is.null(path_to_tumor_dir) & !is.null(path_to_normal_dir)) {
    stop(message = "Must provide path to directories of tumor and normal Alfred QC summary files ...")

  } else if(!is.null(path_to_tumor_dir) & is.null(path_to_normal_dir)) {
    stop(message = "Must provide path to directories of tumor and normal Alfred QC summary files ...")
  }

  # Sanity check if there is no match between normal/tumor samples
  message("Quick view of samples for sanity cross-check ...")
  paint::paint(df = data.frame("Tumor" = tumor_alfreds$Sample))
  paint::paint(df = data.frame("Normal" = normal_alfreds$Sample))

  # Combine the SNV+InDel QC metrics
  message("Merging tumor and normal alignment metrics ...")
  alfred_metrics <- gUtils::rrbind(tumor_alfreds, normal_alfreds)

  # boxplot of total mapped reads
  message("Generating diagnostic plots ...")
  fraction_fwd_rev_melt <- alfred_metrics %>%
                            dplyr::select(Sample, MappedForwardFraction, MappedReverseFraction, tumor_normal) %>%
                            reshape2::melt(id.vars = c("Sample", "tumor_normal"),
                                           value.name = "fraction",
                                           variable.name = "alignment_group")

  mapped_reads_plt <- ggplot2::ggplot(alfred_metrics) +
    ggplot2::geom_boxplot(ggplot2::aes(x = tumor_normal, y = Mapped, fill = tumor_normal), alpha = 0.6, width = 0.3) +
    ggplot2::scale_fill_manual(name = "Sample\nType", values = c("skyblue", "darkred")) +
    ggplot2::geom_jitter(ggplot2::aes(x = tumor_normal, y = Mapped, color = round(MappedProperFraction * 100, digits = 1)), alpha = 0.5, size = 3, width = 0.2) +
    ggplot2::scale_color_gradientn(name = "Percent\nMapped", colors = paletteer::paletteer_c("grDevices::Inferno", 10)) +
    ggplot2::scale_y_continuous(labels = scales::label_comma(scale = 1e-6),
                       limits = c(min(alfred_metrics$Mapped) - min(alfred_metrics$Mapped) * 0.10,
                                  max(alfred_metrics$Mapped) + max(alfred_metrics$Mapped) * 0.10),
                       expand = c(0.02,0.02)) +
    ggside::geom_xsidecol(data = fraction_fwd_rev_melt,
                          ggplot2::aes(x = tumor_normal, y = fraction, group = alignment_group),
                          position = "dodge", width = 0.5, just = 0.3,
                          fill = dplyr::case_when(fraction_fwd_rev_melt$alignment_group == "MappedForwardFraction" ~ "#009292",
                                           fraction_fwd_rev_melt$alignment_group == "MappedReverseFraction" ~ "#490092"), color = "black") +
    ggside::geom_xsidehline(yintercept = 0.45, color = "cyan") +
    ggside::scale_xsidey_continuous(labels = scales::label_percent()) +
    ggplot2::labs(x = NULL,
                  y = "Reads (millions)") +
    ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 0, vjust = 0.95, hjust = 0.5),
                   panel.border = ggplot2::element_rect(fill = NA),
                   ggside.panel.scale = .25) +
    ggplot2::annotate(geom = "text",
                      x = c(0.85, 1.15, 1.85, 2.15),
                      y = max(alfred_metrics$Mapped) + max(alfred_metrics$Mapped) * 0.10,
                      label = c("Fwd", "Rev", "Fwd", "Rev"),
                      color = c("#009292", "#490092","#009292", "#490092")) +
    ggplot2::annotate(geom = "text",
                      x = c(0.60, 2.40),
                      y = alfred_metrics %>%
                             dplyr::group_by(tumor_normal) %>%
                             dplyr::reframe(med_reads = stats::median(Mapped)) %>%
                             dplyr::select(med_reads) %>%
                             purrr::as_vector(),
                      label = round(alfred_metrics %>%
                                       dplyr::group_by(tumor_normal) %>%
                                       dplyr::reframe(med_reads = stats::median(Mapped)) %>%
                                       dplyr::select(med_reads) %>%
                                       purrr::as_vector() %>%
                                       as.numeric(),
                                    digits = -6) / 1e6)

  # boxplots of read fractions
  all_fractions <- data.table("group" = c("DuplicateFraction", "SecondaryAlignmentFraction", "SupplementaryAlignmentFraction", "UnmappedFraction"),
                              "Duplicate" = as.numeric(alfred_metrics$DuplicateFraction),
                              "Secondary" = as.numeric(alfred_metrics$SecondaryAlignmentFraction),
                              "Supplementary" = as.numeric(alfred_metrics$SupplementaryAlignmentFraction),
                              "Unmapped" = as.numeric(alfred_metrics$UnmappedFraction)) %>%
    reshape2::melt(id.vars = "group",
                   value.name = "fraction",
                   variable.name = "alignment_group")

  median_fractions_by_group <- all_fractions %>%
                                dplyr::group_by(alignment_group) %>%
                                dplyr::summarise(median_frac = stats::median(fraction))

  read_fracs_plt <- ggplot2::ggplot(data = all_fractions) +
    ggplot2::geom_boxplot(ggplot2::aes(x = alignment_group, y = fraction * 100, fill = alignment_group), alpha = 0.6, width = 0.4, outliers = F) +
    ggplot2::scale_fill_manual(name = "Alignment\nType", values = paletteer::paletteer_d("ggsci::hallmarks_light_cosmic")[1:5]) +
    ggplot2::geom_jitter(ggplot2::aes(x = alignment_group, y = fraction * 100, color = alignment_group), alpha = 0.4, size = 2.5, width = 0.3) +
    ggplot2::scale_color_manual(name = "Alignment\nType", values = paletteer::paletteer_d("ggsci::hallmarks_light_cosmic")[1:5]) +
    ggplot2::scale_y_continuous(expand = c(0.02,0.02)) +
    ggplot2::labs(x = NULL,
                  y = "Reads (%)") +
    ggplot2::theme(axis.text.x =  ggplot2::element_text(angle = 33, vjust = 0.60, hjust = 0.5, size = 9),
                    legend.position = "right",
                    panel.border =  ggplot2::element_rect(fill = NA))

  all_reads <- data.table("group" = c("DuplicateMarked", "SecondaryAlignments", "SupplementaryAlignments", "Unmapped"),
                          "Duplicate" = as.numeric(alfred_metrics$DuplicateMarked),
                          "Secondary" = as.numeric(alfred_metrics$SecondaryAlignments),
                          "Supplementary" = as.numeric(alfred_metrics$SupplementaryAlignments),
                          "Unmapped" = as.numeric(alfred_metrics$Unmapped)) %>%
    reshape2::melt(id.vars = "group",
                   value.name = "count",
                   variable.name = "alignment_group")

  median_fractions_by_group <- all_reads %>%
                                dplyr::group_by(alignment_group) %>%
                                dplyr::summarise(median_count = stats::median(as.numeric(count)))

  read_counts_plt <- ggplot2::ggplot(data = all_reads) +
    ggplot2::geom_col(data = median_fractions_by_group,
             ggplot2::aes(x = alignment_group, y = median_count, fill = alignment_group), alpha = 0.3, width = 0.4, color = "black") +
    ggplot2::scale_fill_manual(name = "Alignment\nType", values = paletteer::paletteer_d("ggsci::hallmarks_light_cosmic")[1:5]) +
    ggplot2::geom_jitter(ggplot2::aes(x = alignment_group, y = count, color = alignment_group), alpha = 0.4, size = 2.5, width = 0.3) +
    ggplot2::scale_color_manual(name = "Alignment\nType", values = paletteer::paletteer_d("ggsci::hallmarks_light_cosmic")[1:5]) +
    ggplot2::scale_y_reverse(labels = scales::label_comma(scale = 1e-6),expand = c(0.02,0.02)) +
    ggplot2::scale_x_discrete(position = "top") +
    ggplot2::labs(x = NULL,
                  y = "Reads (millions)") +
    ggplot2::theme(axis.text.x = ggplot2::element_blank(),
                   legend.position = "none",
                   panel.border = ggplot2::element_rect(fill = NA))

  # First combo plot of read metrics
  read_mets_plt <- patchwork::wrap_plots(list(read_fracs_plt, read_counts_plt), ncol = 1, guides = "collect")

  # Coverage
  coverage_dist_plt <- ggplot2::ggplot(alfred_metrics) +
    ggridges::stat_density_ridges(ggplot2::aes(x = MedianCoverage, y = tumor_normal, fill = 0.5 - abs(0.5 - ggplot2::after_stat(ecdf))),
                                  alpha = 0.5,
                                  calc_ecdf = TRUE,
                                  bandwidth = 3,
                                  geom = "density_ridges_gradient",
                                  scale = 2) +
    ggplot2::scale_fill_gradientn(name = "Tail prob.\nCoverage", colors = paletteer::paletteer_c("grDevices::Turku", n = 10)) +
    ggplot2::scale_x_continuous(expand = c(0.03,0.03), limits = c(min(alfred_metrics$MedianCoverage),max(alfred_metrics$MedianCoverage) + 5)) +
    ggside::geom_xsidepoint(ggplot2::aes(x = MedianCoverage, y = tumor_normal, color = tumor_normal),
                            position = "jitter", alpha = 0.5, show.legend = F, na.rm = T) +
    ggplot2::scale_color_manual(values = c("skyblue", "darkred")) +
    ggplot2::labs(x = "Coverage",
                  y = NULL) +
    ggplot2::theme(panel.border = ggplot2::element_rect(fill = NA))

  # Insert size distribution
  insert_dist_plt <- ggplot2::ggplot(alfred_metrics) +
    ggridges::stat_density_ridges(ggplot2::aes(x = MedianInsertSize, y = tumor_normal, fill = 0.5 - abs(0.5 - ggplot2::after_stat(ecdf))),
                                  alpha = 0.5,
                                  calc_ecdf = TRUE,
                                  bandwidth = 10,
                                  geom = "density_ridges_gradient",
                                  scale = 2) +
    ggplot2::scale_fill_gradientn(name = "Insert\nSize", colors = paletteer::paletteer_c("grDevices::Lajolla", n = 10)) +
    ggplot2::scale_x_continuous(expand = c(0.03,0.03), limits = c(min(alfred_metrics$MedianInsertSize),max(alfred_metrics$MedianInsertSize) + 5)) +
    ggside::geom_xsidepoint(ggplot2::aes(x = MedianInsertSize, y = tumor_normal, color = tumor_normal),
                            position = "jitter", alpha = 0.5, show.legend = F, na.rm = T) +
    ggplot2::scale_color_manual(values = c("skyblue", "darkred")) +
    ggplot2::labs(x = "Insert Size (bp)",
                  y = NULL) +
    ggplot2::theme(panel.border = ggplot2::element_rect(fill = NA),
                    axis.text.y = ggplot2::element_blank())

  # Second combo plot of coverage and insert size distribution
  cov_insrt_plt <- patchwork::wrap_plots(list(coverage_dist_plt, insert_dist_plt), ncol = 2, nrow = 1, guides = "collect")

  # Text table of summary metrics
  # TODO: add outlier sample flagging
  tumor_table_metrics <- alfred_metrics %>% dplyr::filter(tumor_normal == "Tumor")
  normal_table_metrics <- alfred_metrics %>% dplyr::filter(tumor_normal == "Normal")
  outtable <- data.table(placeholder = c("Tumor", "Normal"),
                         "Coverage" = c(stringr::str_c(round(mean(tumor_table_metrics$MedianCoverage), digits = 1), " (", range(tumor_table_metrics$MedianCoverage)[1], "-", range(tumor_table_metrics$MedianCoverage)[2], ")"),
                                        stringr::str_c(round(mean(normal_table_metrics$MedianCoverage), digits = 1), " (", range(normal_table_metrics$MedianCoverage)[1], "-", range(normal_table_metrics$MedianCoverage)[2], ")")),
                         "Insert Size" = c(stringr::str_c(round(mean(tumor_table_metrics$MedianInsertSize), digits = 1), " (", range(tumor_table_metrics$MedianInsertSize)[1], "-", range(tumor_table_metrics$MedianInsertSize)[2], ")"),
                                           stringr::str_c(round(mean(normal_table_metrics$MedianInsertSize), digits = 1), " (", range(normal_table_metrics$MedianInsertSize)[1], "-", range(normal_table_metrics$MedianInsertSize)[2], ")")),
                         "Read Length" = c(stringr::str_split(string = unique(tumor_table_metrics$MedianReadLength), pattern = ":",simplify = T)[,1],
                                           stringr::str_split(string = unique(normal_table_metrics$MedianReadLength), pattern = ":",simplify = T)[,1]))
  colnames(outtable)[1] <- paste0(seq_protocol, " mean(range)")
  metrics_summary_table <- ggpubr::ggtexttable(t(outtable), theme = ggpubr::ttheme("light"))

  # Histograms of target bed mapped fraction, insertion and deletion detection rate
  target_frac_plt <- ggplot2::ggplot(alfred_metrics) +
    ggplot2::geom_histogram(ggplot2::aes(x = FractionCovered, group = tumor_normal, fill = tumor_normal),
                            position = "dodge", binwidth = 0.05,  color = "black", alpha = 0.6) +
    ggplot2::scale_x_continuous(limits = c(0,1), expand = c(0.02,0.02), breaks = scales::breaks_width(width = 0.1)) +
    ggplot2::scale_y_continuous(expand = c(0.02,0.02)) +
    ggplot2::scale_fill_manual(values = c("skyblue", "darkred")) +
    ggplot2::labs(x = "Fraction of target covered",
                  y = "Count of samples per bin") +
    ggplot2::theme(panel.border = ggplot2::element_rect(fill = NA),
                   legend.position = "none")

  ins_rate_plt <- ggplot2::ggplot(alfred_metrics) +
    ggplot2::geom_histogram(ggplot2::aes(x = InsertionRate, group = tumor_normal, fill = tumor_normal),
                   position = "stack", binwidth = 0.000005, color = "black", alpha = 0.6) +
    ggplot2::scale_y_continuous(expand = c(0.02,0.02)) +
    ggplot2::scale_fill_manual(values = c("skyblue", "darkred")) +
    ggplot2::labs(x = "Insertion rate",
                  y = "Count of samples per bin") +
    ggplot2::theme(panel.border = ggplot2::element_rect(fill = NA),
                   legend.position = "none")

  del_rate_plt <- ggplot2::ggplot(alfred_metrics) +
    ggplot2::geom_histogram(ggplot2::aes(x = DeletionRate, group = tumor_normal, fill = tumor_normal),
                            position = "stack", binwidth = 0.000005, color = "black", alpha = 0.6) +
    ggplot2::scale_y_continuous(expand = c(0.02,0.02)) +
    ggplot2::scale_fill_manual(values = c("skyblue", "darkred")) +
    ggplot2::labs(x = "Deletion rate",
                  y = "Count of samples per bin") +
    ggplot2::theme(panel.border = ggplot2::element_rect(fill = NA),
                   legend.position = "none")

  # Third combo plot of histograms
  hist_combo_plot <- target_frac_plt / ins_rate_plt / del_rate_plt + patchwork::plot_layout(axes = "collect_y")

  # Final quilt plot of all QC plots
  read_combo_plt <- (patchwork::plot_spacer() + metrics_summary_table + patchwork::plot_spacer()) / (mapped_reads_plt + hist_combo_plot + read_mets_plt) / cov_insrt_plt + patchwork::plot_layout(ncol = 1, nrow = 3, heights = c(0.66, 1, 1))
  return(read_combo_plt)
}


# TODO: NEED TO MAKE SURE THIS WORKS
#' @name get_qc_diagnostics_snvindel
#' @title Generate diagnostic plots for SNV & InDel variant calling QC checks
#'
#' @description
#' Single command to generate a comprehensive set of diagnostic plots that assist in
#' performing QC checks of SNVs & InDels called from MGP1000 using union consensus.
#' Can be used as both a first pass of unfiltered variants to see consensus skew as
#' well as used after filtering to show changes in calling metrics.
#'
#' @param path_to_snv_dir Path to directory of MGP1000 union consensus SNVs
#' @param path_to_indel_dir Path to directory of MGP1000 union consensus InDels
#' @param snv_indel_obj Data.table object with merged SNVs & InDels, used in place of paths to directories
#' @param plot_sample_names Output plots to include sample names on y-axis, default: TRUE
#' @param include_caveman Add caveman to consensus list if used in SNV variant calling, default: FALSE
#'
#' @return Patchwork 'quilt'-like plot of ggplots
#' @export
get_qc_diagnostics_snvindel <- function(path_to_snv_dir = NULL, path_to_indel_dir = NULL, snv_indel_obj = NULL, plot_sample_names = T, include_caveman = F) {

  # Set figure base theme
  ggplot2::theme_set(
    ggplot2::theme_gray() +
      ggplot2::theme(axis.line = ggplot2::element_line(linewidth = 0.5,  color = "black"),
                     panel.background = ggplot2::element_rect(fill = NA, linewidth = rel(14)),
                     panel.grid.minor = ggplot2::element_line(color = NA),
                     axis.text = ggplot2::element_text(size = 12,  color = "black"),
                     axis.title = ggplot2::element_text(size = 14),
                     axis.ticks = ggplot2::element_line(linewidth = 0.75),
                     title = ggplot2::element_text(size = 16)))

  # User provides either paths to directory with SNVs and InDel or a single DT obj with both SNV+InDels
  if(!is.null(path_to_snv_dir) & !is.null(path_to_indel_dir) & is.null(snv_indel_obj)) {
    # Aggregate all SNV and InDel union-consensus files
    message("Aggregate input mutations ...")
    snvs <- aggregate_these(path_to_files = path_to_snv_dir,
                            pattern_to_grab = "*.hq.union.consensus.somatic.snv.txt.gz",
                            delim = "\t",
                            has_header = T,
                            cpus = 1,
                            add_uniq_id = F)

    indels <- aggregate_these(path_to_files = path_to_indel_dir,
                              pattern_to_grab = "*.hq.union.consensus.somatic.indel.txt.gz",
                              delim = "\t",
                              has_header = T,
                              cpus = 1,
                              add_uniq_id = F)

    # If user already aggregated, split DT obj into SNVs and InDels
  } else if(is.null(path_to_snv_dir) & is.null(path_to_indel_dir) & !is.null(snv_indel_obj)) {
    # Aggregate all SNV and InDel union-consensus files
    message("Read in aggregated mutations ...")
    snvs <- snv_indel_obj %>% dplyr::filter(stringr::str_length(REF) == 1 & stringr::str_length(ALT) == 1)
    indels <- dplyr::setdiff(x = snv_indel_obj, y = snvs)

  } else {
    stop(message = "Must provide either path to directories of SNVs and InDels or SNV+InDel aggregated data.table ...")
  }

  # Get count of all SNVs and InDels per sample by caller
  message("Counting mutations per sample by caller ...")
  snvs_by_caller <- snvs %>%
    dplyr::group_by(SAMPLE) %>%
    dplyr::count(CALLER) %>%
    dplyr::ungroup() %>%
    dplyr::mutate(total_snvs = sum(n)) %>%
    dplyr::arrange(dplyr::desc(total_snvs))

  indels_by_caller <- indels %>%
    dplyr::group_by(SAMPLE) %>%
    dplyr::count(CALLER) %>%
    dplyr::ungroup() %>%
    dplyr::mutate(total_indels = sum(n)) %>%
    dplyr::arrange(dplyr::desc(total_indels))

  # Factor the caller list for consistent plotting
  if(include_caveman) {
    snv_caller_levels <- c("caveman","mutect","strelka","varscan",
                           "caveman,mutect","caveman,strelka","caveman,varscan",
                           "mutect,strelka","mutect,varscan","strelka,varscan",
                           "caveman,mutect,strelka","caveman,mutect,varscan",
                           "caveman,strelka,varscan","mutect,strelka,varscan",
                           "caveman,mutect,strelka,varscan")
  } else if(!include_caveman) {
    snv_caller_levels <- c("mutect","strelka","varscan",
                           "mutect,strelka", "mutect,varscan","strelka,varscan",
                           "mutect,strelka,varscan")
  }

  snvs_by_caller$CALLER <- factor(snvs_by_caller$CALLER,
                                  levels = snv_caller_levels)

  indels_by_caller$CALLER <- factor(indels_by_caller$CALLER,
                                    levels = c("mutect","strelka","svaba","varscan",
                                               "mutect,strelka","mutect,svaba","mutect,varscan",
                                               "strelka,svaba","strelka,varscan","svaba,varscan",
                                               "mutect,strelka,svaba","mutect,strelka,varscan","mutect,svaba,varscan",
                                               "strelka,svaba,varscan","mutect,strelka,svaba,varscan"))

  # Build SNVs per sample by caller plot
  message("Generating diagnostic plots ...")
  snvs_per_sample_by_caller <- ggplot2::ggplot(snvs_by_caller) +
    ggplot2::geom_col(ggplot2::aes(x = SAMPLE, y = n, fill = CALLER), position = "stack") +
    ggplot2::scale_fill_manual(name = "Callers", values = paletteer::paletteer_d("ggsci::default_jama")) +
    ggplot2::scale_y_reverse(expand = c(0.01,0.01), labels = scales::label_comma()) +
    ggplot2::scale_x_discrete(position = "top") +
    ggplot2::coord_flip() +
    ggplot2::labs(title = "SNVs",
         x = NULL,
         y = "Count") +
    ggplot2::theme(legend.position = "left",
                    plot.title = ggplot2::element_text(hjust = 0.5),
                    panel.border = ggplot2::element_rect(fill = NA),
                    legend.key.size = ggplot2::unit("1.5", "mm"),
                    legend.title = ggplot2::element_text(size = 11))
  # Sample names or not on Y axis
  if(plot_sample_names) {
    snvs_per_sample_by_caller <- snvs_per_sample_by_caller + ggplot2::theme(axis.text.y = element_text(size = 8))

  } else if(!plot_sample_names) {
    snvs_per_sample_by_caller <- snvs_per_sample_by_caller + ggplot2::theme(axis.text.y = element_blank())
  }

  # Build counts of total by caller
  caller_by_snvs <- ggplot2::ggplot(data = snvs_by_caller %>%
                                             dplyr::group_by(CALLER) %>%
                                             dplyr::summarise(total_per_caller = round((sum(n) / sum(snvs_by_caller$n)) * 100, digits = 1)),
                                    ggplot2::aes(x = CALLER, y = total_per_caller, fill = CALLER, label = total_per_caller)) +
                    ggplot2::geom_col() +
                    ggfittext::geom_bar_text(min.size = 1) +
                    ggplot2::scale_fill_manual(name = "Callers", values = paletteer::paletteer_d("ggsci::default_jama")) +
                    ggplot2::scale_y_reverse(expand = c(0.02,0.02), labels = scales::label_percent(scale = 1), position = "right") +
                    ggplot2::scale_x_discrete(position = "top") +
                    ggplot2::labs(x = "Percentage of\ncalled mutations",
                                  y = NULL) +
                    ggplot2::theme(axis.text.x = ggplot2::element_blank(),
                                    axis.ticks.x.top = ggplot2::element_blank(),
                                    legend.position = "none",
                                    panel.border = ggplot2::element_rect(fill = NA))

  # Build InDels per sample by caller plot
  indels_per_sample_by_caller <- ggplot2::ggplot(indels_by_caller) +
    ggplot2::geom_col(ggplot2::aes(x = SAMPLE, y = n, fill = CALLER), position = "stack") +
    ggplot2::scale_fill_manual(name = "Callers", values = paletteer_d("colorBlindness::paletteMartin")) +
    ggplot2::scale_y_continuous(expand = c(0.01,0.01), labels = scales::label_comma(), position = "left") +
    ggplot2::scale_x_discrete(position = "bottom") +
    ggplot2::coord_flip() +
    ggplot2::labs(title = "InDels",
                   x = NULL,
                   y = "Count") +
    ggplot2::theme(legend.position = "right",
                    plot.title = ggplot2::element_text(hjust = 0.5),
                    axis.text.y = ggplot2::element_blank(),
                    panel.border = ggplot2::element_rect(fill = NA),
                    legend.key.size = ggplot2::unit("1.5", "mm"),
                    legend.title = ggplot2::element_text(size = 11))

  # Build counts of total by caller
  caller_by_indels <- ggplot2::ggplot(data = indels_by_caller %>%
                                               dplyr::group_by(CALLER) %>%
                                               dplyr::summarise(total_per_caller = round((sum(n) / sum(indels_by_caller$n)) * 100, digits = 1)),
                                      ggplot2::aes(x = CALLER, y = total_per_caller, fill = CALLER, label = total_per_caller)) +
                        ggplot2::geom_col() +
                        ggfittext::geom_bar_text(min.size = 1) +
                        ggplot2::scale_fill_manual(name = "Callers", values = paletteer::paletteer_d("colorBlindness::paletteMartin")) +
                        ggplot2::scale_y_reverse(expand = c(0.02,0.02), labels = scales::label_percent(scale = 1), position = "left") +
                        ggplot2::scale_x_discrete(position = "top") +
                        ggplot2::labs(x = "Percentage of\ncalled mutations",
                                      y = NULL) +
                        ggplot2::theme(axis.text.x = ggplot2::element_blank(),
                                        axis.ticks.x.top = ggplot2::element_blank(),
                                        legend.position = "none",
                                        panel.border = ggplot2::element_rect(fill = NA))

  # Final combo QC diagnostic plot
  snvindel_qc_diagnostic_plot <- (snvs_per_sample_by_caller / caller_by_snvs) | (indels_per_sample_by_caller / caller_by_indels)
  return(snvindel_qc_diagnostic_plot)
}






#' @name get_vaf
#' @title Quick pull or explicitly calculate the VAF for mutation records of various flavors
#'
#' @description
#' Given a data.table or GRanges VCF object, quickly extract or explicitly calculate the VAF for all mutations.
#' For clarity, the read support for the VAF will be extracted as well.
#' Currently supports somatic SNV/InDel VCFs from Mutect, Strelka, Varscan, SvABA, CaVEMan.
#'
#' @param vcf_obj VCF file in data.table or GRanges format
#' @param caller Name of the caller that generated input VCF to be converted, supported: mutect, strelka, varscan, svaba, caveman
#' @param mut_type Type of mutations within VCF, supported: snv, indel
#'
#' @return data.table object with read support and VAF per record
#' @export
get_vaf <- function(vcf_obj, caller, mut_type) {

  # First, check the VCF object. If data.table, continue on. If not, convert
  if(!"data.table" %in% class(vcf_obj) & "GRanges" %in% class(vcf_obj)) {
    mut_records <- gUtils::gr2dt(vcf_obj)

  } else if("data.table" %in% class(vcf_obj)) {
    mut_records <- vcf_obj

  } else {
    # Problem if input VCF object is not correct class
    stop(message = "\nInput VCF object needs to be either data.table or GRanges class")
  }

  if(caller == "mutect") {
    # Mutect SNVs and InDels
    # VAF is reported as AF ["Allele fractions of alternate alleles in the tumor"]
    # ALT depth is reported as AD ["Allelic depths for the ref and alt alleles in the order listed"]
    # Total depth is reported as DP ["Approximate read depth (reads with MQ=255 or with bad mates are filtered)"]
    mut_alt_depth <- mut_records[, AD_ALT_TUMOR]
    mut_total_depth <- mut_records[, DP_TUMOR]
    mut_vaf <- round(mut_records[, AF_TUMOR], digits = 4)

  } else if(caller == "varscan") {
    # VarScan SNVs and InDels
    # VAF is reported as FREQ ["Variant allele frequency"]
    # ALT depth is reported as AD ["Depth of variant-supporting bases (reads2)"]
    # Total depth is reported as DP ["Read Depth"]
    mut_alt_depth <- mut_records[, AD_TUMOR]
    mut_total_depth <- mut_records[, DP_TUMOR]
    mut_vaf <- round(as.numeric(stringr::str_remove(string = mut_records[, FREQ_TUMOR], pattern = "%")) / 100, digits = 4)

  } else if(caller == "strelka" & mut_type == "snv") {
    # Strelka SNVs
    # Does not directly report VAF
    # ALT depth is reported as read support per nucleotide tier AU, CU, TU, GU ["Number of 'A/C/G/T' alleles used in tiers 1,2"]
    # Total depth is reported as depth DP ["Read depth for tier1 (used+filtered)"]
    # The VAF will be calculated as: [AU_TIER1, CU_TIER1, TU_TIER1, GU_TIER1] / DP

    # To get the correct ALT depth, need to loop through the records to build
    mut_alt_depth <- rep(NA, nrow(mut_records))
    mut_total_depth <- mut_records[, DP_TUMOR]
    mut_vaf <- rep(NA, nrow(mut_records))

    for(i in 1:nrow(mut_records)) {
      # Get the ALT depth
      mut_alt_depth[i] <- as.data.frame(mut_records[i,])[,colnames(mut_records[i,]) == paste0(mut_records$ALT[i], "U_TIER1_TUMOR")]

      # Calculate the VAF
      mut_vaf[i] <- round(mut_alt_depth[i] / mut_total_depth[i], digits = 4)
    }

  } else if(caller == "strelka" & mut_type == "indel") {
    # Strelka InDels
    # Does not directly report VAF
    # ALT depth is reported as indel tier read support TIR ["Reads strongly supporting indel allele for tiers 1,2"]
    # Total depth is reported as depth DP ["Read depth for tier1 (used+filtered)"]
    # The VAF will be calculated as: TIR_TIER1 / DP
    mut_alt_depth <- mut_records[, TIR_TIER1_TUMOR]
    mut_total_depth <- mut_records[, DP_TUMOR]
    mut_vaf <- round(mut_alt_depth / mut_total_depth, digits = 4)

  } else if(caller == "svaba" & mut_type == "indel") {
    # SvABA InDels
    # Does not directly report VAF
    # ALT depth is reported as allele depth AD ["Allele depth: Number of reads supporting the variant"]
    # Total depth is reported as depth DP ["Depth of coverage: Number of reads covering site."]
    # The VAF will be calculated as: AD / DP
    mut_alt_depth <- mut_records[, AD_TUMOR]
    mut_total_depth <- mut_records[, DP_TUMOR]
    mut_vaf <- round(mut_alt_depth / mut_total_depth, digits = 4)

  } else if(caller == "caveman" & mut_type == "snv") {
    # CaVEMan SNVs
    # VAF is reported as proportion of mut allele PM ["Proportion of mutant allele presenting reads (ALT field) seen by CaVEMan"]
    # ALT depth is reported as read support per nucleotide per strand FAZ, FCZ, FGZ, FTZ, RAZ, RCZ, RGZ, RTZ
    # Total depth is not directly reported

    # To get the correct ALT and total depth, need to loop through the records to build
    mut_alt_depth <- rep(NA, nrow(mut_records))
    mut_total_depth <- rep(NA, nrow(mut_records))
    mut_vaf <- mut_records[, PM_TUMOR]

    for(i in 1:nrow(mut_records)) {
      # Get all nucleotide read depth on both strands
      fwd_alt_depth <- as.data.frame(mut_records[i,])[,colnames(mut_records[i,]) == paste0("F", mut_records$ALT[i], "Z_TUMOR")]
      rev_alt_depth <- as.data.frame(mut_records[i,])[,colnames(mut_records[i,]) == paste0("R", mut_records$ALT[i], "Z_TUMOR")]
      fwd_ref_depth <- as.data.frame(mut_records[i,])[,colnames(mut_records[i,]) == paste0("F", mut_records$REF[i], "Z_TUMOR")]
      rev_ref_depth <- as.data.frame(mut_records[i,])[,colnames(mut_records[i,]) == paste0("R", mut_records$REF[i], "Z_TUMOR")]

      # Calculate the ALT and total read depth
      mut_alt_depth[i] <- sum(fwd_alt_depth, rev_alt_depth)
      mut_total_depth[i] <- sum(fwd_alt_depth, rev_alt_depth, fwd_ref_depth, rev_ref_depth)
    }

  } else {
    # Problem if there is no proper combo of caller and mut_type
    stop(message = "\ncaller and mut_type provided do not match possible combos. See function description")
  }

  # Create final DT of read depth and VAF for each mutation record
  mut_vaf_and_reads <- data.table(alt_depth = mut_alt_depth,
                                  total_depth = mut_total_depth,
                                  vaf = mut_vaf)

  # Output the VAF for the mutation record
  return(mut_vaf_and_reads)
}


#' @name get_maf_lite
#' @title Convert SNV & InDel mutation table to MAF-lite format
#'
#' @description
#' Read in multiple MGP1000 union consensus SNV & InDel mutation tables, filter based on consensus threshold
#' or sample/gene, merge all tables, calculate VAF, and prepare for downstream use in maf2maf or maf2vcf.
#' The bare minimum for a MAF is Chromosome, Start_Position, Reference_Allele, Tumor_Seq_Allele2, Tumor_Sample_Barcode
#' but will also include Matched_Norm_Sample_Barcode.
#'
#' @param path_to_snv_dir Path to directory of MGP1000 union consensus SNVs
#' @param path_to_indel_dir Path to directory of MGP1000 union consensus InDels
#' @param snv_consensus_filter Threshold consensus filter for SNVs
#' @param indel_consensus_filter Threshold consensus filter for InDels
#' @param strict_samples Samples that will be filtered with `*_consensus_filter``+1`
#' @param discovery_genes Gene set vector used for discovery with `*_consensus_filter``=0`
#' @param return_type Output either the converted maf-lite format table or data.table of standard format mutation table, supported: maf.lite, data.table
#'
#' @return data.table like in either maf-lite or standard format
#' @export
get_maf_lite <- function(path_to_snv_dir, path_to_indel_dir, snv_consensus_filter = 2, indel_consensus_filter = 2,
                         strict_samples = NULL, discovery_genes = NULL, return_type = "maf.lite") {

  # First, check if return type is properly set
  if(!return_type %in% c("maf.lite", "data.table")) {
    stop(message = "\nInvalid return type, please specify either 'maf.lite' or 'data.table'")
  }

  # Aggregate all SNV and InDel union-consensus files
  # Perform sanity checks on patients and samples
  message("Aggregate input mutations ...")
  snvs <- aggregate_these(path_to_files = path_to_snv_dir,
                          pattern_to_grab = "*.hq.union.consensus.somatic.snv.txt.gz",
                          delim = "\t",
                          has_header = T,
                          cpus = 1,
                          add_uniq_id = F)
  message("Found ", dplyr::n_distinct(snvs$SAMPLE), " samples from ", dplyr::n_distinct(snvs$PATIENT), " patients with SNVs ...")

  indels <- aggregate_these(path_to_files = path_to_indel_dir,
                            pattern_to_grab = "*.hq.union.consensus.somatic.indel.txt.gz",
                            delim = "\t",
                            has_header = T,
                            cpus = 1,
                            add_uniq_id = F)
  message("Found ", dplyr::n_distinct(indels$SAMPLE), " samples from ", dplyr::n_distinct(indels$PATIENT), " patients with InDels ...")

  # Sanity check if there is no overlap in samples/patients or if there is a missing sample/patient
  if(length(dplyr::setdiff(x = indels$SAMPLE, y = snvs$SAMPLE)) == 0) {
    message("No difference in set of samples between SNVs and InDels ...")

  } else if(length(dplyr::setdiff(x = indels$SAMPLE, y = snvs$SAMPLE)) > 0) {
    message("Warning: Detected ", length(dplyr::setdiff(x = indels$SAMPLE, y = snvs$SAMPLE)), " samples in InDel sample set NOT in SNV sample set ...")
    setdiff_samples <- indels$SAMPLE[which(!indels$SAMPLE %in% unique(snvs$SAMPLE))]
    paint::paint(df = data.frame("Missing_Samples" = setdiff_samples))
    message("Recommend inspection ...")
  }

  # Now filter the data based on desired conditions
  message("Beginning filtering for high-quality variants ...")
  hq_snvs <- NULL
  hq_indels <- NULL

  # Standard consensus filtering, no special cases
  if(is.null(strict_samples) & is.null(discovery_genes)) {
    message("Maintaining SNVs with consensus >= ", snv_consensus_filter,  " ...")
    message("Maintaining InDels with consensus >= ", indel_consensus_filter,  " ...")

    hq_snvs <- snvs %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= snv_consensus_filter - 1)
    hq_indels <- indels %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= indel_consensus_filter - 1)

    # Standard consensus filtering, plus special case to keep all muts for genes of interest
  } else if(is.null(strict_samples) & !is.null(discovery_genes)) {
    message("Maintaining SNVs with consensus >= ", snv_consensus_filter,  " ...")
    message("Maintaining InDels with consensus >= ", indel_consensus_filter,  " ...")
    message("Special case filter to maintain all calls for genes of interest ...")
    paint::paint(df = data.frame("Discovery_Genes" = discovery_genes))

    consensus_non_discovery_snvs <- snvs %>%
      dplyr::filter(!nearest_gene %in% discovery_genes) %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= snv_consensus_filter - 1)
    discovery_gene_snvs <- snvs %>%
      dplyr::filter(nearest_gene %in% discovery_genes)
    hq_snvs <- gUtils::rrbind(consensus_non_discovery_snvs, discovery_gene_snvs)

    consensus_non_discovery_indels <- indels %>%
      dplyr::filter(!nearest_gene %in% discovery_genes) %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= indel_consensus_filter - 1)
    discovery_gene_indels <- indels %>%
      dplyr::filter(nearest_gene %in% discovery_genes)
    hq_indels <- gUtils::rrbind(consensus_non_discovery_indels, discovery_gene_indels)

    # Standard consensus filtering, plus special case to strictly filter specific samples
  } else if(!is.null(strict_samples) & is.null(discovery_genes)) {
    message("Maintaining SNVs with consensus >= ", snv_consensus_filter,  " ...")
    message("Maintaining InDels with consensus >= ", indel_consensus_filter,  " ...")
    message("Special case filter to strictly filter specific samples with +1 to consensus filters ...")
    paint::paint(df = data.frame("Strict_Samples" = strict_samples))

    consensus_non_strict_snvs <- snvs %>%
      dplyr::filter(!SAMPLE %in% strict_samples) %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= snv_consensus_filter - 1)
    strict_sample_snvs <- snvs %>%
      dplyr::filter(SAMPLE %in% strict_samples) %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= snv_consensus_filter)
    hq_snvs <- gUtils::rrbind(consensus_non_strict_snvs, strict_sample_snvs)

    consensus_non_strict_indels <- indels %>%
      dplyr::filter(!SAMPLE %in% strict_samples) %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= indel_consensus_filter - 1)
    strict_sample_indels <- indels %>%
      dplyr::filter(SAMPLE %in% strict_samples) %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= indel_consensus_filter)
    hq_indels <- gUtils::rrbind(consensus_non_strict_indels, strict_sample_indels)

    # Standard consensus filtering, plus special case to keep all muts for genes of interest and to strictly filter specific samples
  } else if(!is.null(strict_samples) & !is.null(discovery_genes)) {
    message("Maintaining SNVs with consensus >= ", snv_consensus_filter,  " ...")
    message("Maintaining InDels with consensus >= ", indel_consensus_filter,  " ...")
    message("Special case filter to maintain all calls for genes of interest ...")
    paint::paint(df = data.frame("Discovery_Genes" = discovery_genes))
    message("Special case filter to strictly filter specific samples with +1 to consensus filters ...")
    paint::paint(df = data.frame("Strict_Samples" = strict_samples))

    consensus_non_discovery_strict_snvs <- snvs %>%
      dplyr::filter(!SAMPLE %in% strict_samples) %>%
      dplyr::filter(!nearest_gene %in% discovery_genes) %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= snv_consensus_filter - 1)
    discovery_gene_snvs <- snvs %>%
      dplyr::filter(!SAMPLE %in% strict_samples) %>%
      dplyr::filter(nearest_gene %in% discovery_genes)
    strict_sample_snvs <- snvs %>%
      dplyr::filter(SAMPLE %in% strict_samples) %>%
      dplyr::filter(!nearest_gene %in% discovery_genes) %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= snv_consensus_filter)
    hq_snvs <- gUtils::rrbind(consensus_non_discovery_strict_snvs, discovery_gene_snvs, strict_sample_snvs)

    consensus_non_discovery_strict_indels <- indels %>%
      dplyr::filter(!SAMPLE %in% strict_samples) %>%
      dplyr::filter(!nearest_gene %in% discovery_genes) %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= indel_consensus_filter - 1)
    discovery_gene_indels <- indels %>%
      dplyr::filter(!SAMPLE %in% strict_samples) %>%
      dplyr::filter(nearest_gene %in% discovery_genes)
    strict_sample_indels <- indels %>%
      dplyr::filter(SAMPLE %in% strict_samples) %>%
      dplyr::filter(!nearest_gene %in% discovery_genes) %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= indel_consensus_filter)
    hq_indels <- gUtils::rrbind(consensus_non_discovery_strict_indels, discovery_gene_indels, strict_sample_indels)
  }

  # Combine HQ SNVs and InDels
  message("Filter complete, merging to single SNV+InDel DT ...")
  hq_muts <- gUtils::rrbind(hq_snvs, hq_indels)

  # Calculate the read depth information for the MAF-like file
  message("Calculate VAF for normal samples ...")

  # Edge Case: Strelka does not directly report AD for SNVs so it will be determined for normal as [AU_TIER1, CU_TIER1, TU_TIER1, GU_TIER1]
  # However, AD is output for InDels as TIR_TIER1_NORMAL
  strelka_normal_alt_depth <- rep(NA, nrow(hq_muts))
  # To get the correct ALT depth, need to loop through the records and differentiate between SNVs and InDels
  for(i in 1:nrow(hq_muts)) {
    # Check if SNV or InDel
    if(stringr::str_length(hq_muts$ALT[i]) == 1 & stringr::str_length(hq_muts$REF[i]) == 1) {
      strelka_normal_alt_depth[i] <- as.data.frame(hq_muts[i,])[,colnames(hq_muts[i,]) == paste0("STRELKA_", hq_muts$ALT[i], "U_TIER1_NORMAL")]
    } else {
      strelka_normal_alt_depth[i] <-  hq_muts$STRELKA_TIR_TIER1_NORMAL[i]
    }
  }
  # Now add calculated Strelka normal ALT depth to mutation table
  hq_muts$STRELKA_alt_depth_normal <- strelka_normal_alt_depth

  normal_read_colnames <- which(c("MUTECT_DP_NORMAL", "STRELKA_DP_NORMAL", "VARSCAN_DP_NORMAL", "SVABA_DP_NORMAL") %in% colnames(hq_muts))
  normal_read_metrics <- hq_muts %>%
    dplyr::select(c("MUTECT_DP_NORMAL", "STRELKA_DP_NORMAL", "VARSCAN_DP_NORMAL", "SVABA_DP_NORMAL")[normal_read_colnames])
  dp_mean <- round(rowMeans(x = normal_read_metrics, na.rm = T), digits = 0)

  alt_read_colnames <- which(c("MUTECT_AD_ALT_NORMAL","STRELKA_alt_depth_normal", "VARSCAN_AD_NORMAL", "SVABA_AD_NORMAL") %in% colnames(hq_muts))
  alt_read_metrics <- hq_muts %>%
    dplyr::select(c("MUTECT_AD_ALT_NORMAL","STRELKA_alt_depth_normal", "VARSCAN_AD_NORMAL", "SVABA_AD_NORMAL")[alt_read_colnames])
  alt_mean <- round(rowMeans(x = alt_read_metrics, na.rm = T), digits = 0)

  ref_mean <- dp_mean - alt_mean

  # Now build the MAF-like DT for conversion with maftools
  hq_muts_maf_lite_dt <- data.table::data.table("Chromosome" = hq_muts$seqnames,
                                                "Start_Position" = hq_muts$start,
                                                "Reference_Allele" = hq_muts$REF,
                                                "Tumor_Seq_Allele2" = hq_muts$ALT,
                                                "Tumor_Sample_Barcode" = hq_muts$TUMOR,
                                                "Matched_Norm_Sample_Barcode" = hq_muts$NORMAL,
                                                "Tumor_Total_Read_Depth" = hq_muts$total_depth_mean,
                                                "Tumor_Variant_Allele_Depth" = hq_muts$alt_read_depth_mean,
                                                "Tumor_Reference_Allele_Depth" = hq_muts$total_depth_mean - hq_muts$alt_read_depth_mean,
                                                "Normal_Total_Read_Depth" = dp_mean,
                                                "Normal_Variant_Read_Depth" = alt_mean,
                                                "Normal_Reference_Allele_Depth" = ref_mean)
  # Final output
  if(return_type == "maf.lite") {
    message("MAF-lite generated ...")
    paint::paint(hq_muts_maf_lite_dt)
    return(hq_muts_maf_lite_dt)

  # return the non-transformed post-filtered mutation table for QC
  } else if(return_type == "data.table") {
    message("Mutation table generated ...")
    paint::paint(hq_muts)
    return(hq_muts)
  }
}


#' @name get_allele_counts
#' @title Read in a BAM file, collect read counts for alleles at set of mutation loci using alleleCounter, and convert to data.table object
#'
#' @description
#' Wrapper command to use alleleCounter to read in a BAM file and count all reads supporting each possible allele at set of mutation loci, then convert it to a data.table object with refactored seq details.
#' The process will be split across each chromosome and then merged for the final output.
#' Expects the first column to be chromosome name, and 3 other columns to exist in the mutation loci file: pos/start/end, ref/REF/Reference_Allele, alt/ALT/Tumor_Seq_Allele2.
#'
#' @param bam_file_path Path to BAM file
#' @param mut_loci_obj Mutation loci file in data.table or GRanges format, required columns: chrom, pos, ref, alt
#' @param min_base_qual Minimum base quality required for a read to be counted, default: 20
#' @param min_map_qual Minimum mapping quality required for a read to be counted, default: 35
#' @param threads Number of threads to use for parallel execution, default: 1
#'
#' @return data.table object with the columns: #CHR, POS, Count_A, Count_C, Count_G, Count_T, Good_depth
#' @export
get_allele_counts = function(bam_file_path, mut_loci_obj, min_base_qual = 20, min_map_qual = 35, threads = 1) {

  # Set parallel cores parameter
  message("Setting parallel cores to ", threads, " ...")
  doParallel::registerDoParallel(cores = threads)

  # First, check if BAM and index exist at the path given
  if(!file.exists(bam_file_path)) {
    stop(message = "\nInput BAM does not exist at the path given")
  }

  if(!file.exists(paste0(bam_file_path, ".bai")) & !file.exists(stringr::str_replace(string = bam_file_path, pattern = "\\.bam", replacement ="\\.bai"))) {
    stop(message = "\nInput BAM .bai index does not at the path given")
  }

  # Second, check the mutation loci object. If data.table, continue on. If not, convert
  if(!"data.table" %in% class(mut_loci_obj) & "GRanges" %in% class(mut_loci_obj)) {
    mut_loci <- gUtils::gr2dt(mut_loci_obj)

  } else if("data.table" %in% class(mut_loci_obj)) {
    mut_loci <- mut_loci_obj

  } else {
    # Problem if input VCF object is not correct class
    stop(message = "\nInput mutation loci object needs to be either data.table or GRanges class")
  }

  # Finally, check if alleleCounter is on the path
  if(class(system("alleleCounter -v", intern = TRUE)) != "character") {
    stop(message = "\nCannot find alleleCounter binary executable on path")
  }

  # Begin foreach construct to parallelize the alleleCounter command per chromosome and then stitch the results together in a GRanges object
  chrom_iter_list <- as.character(unique(mut_loci$seqnames))
  possible_col_names <- c("seqnames", "chrom", "start", "pos", "POS", "ref", "REF", "Reference_Allele", "alt", "ALT", "Tumor_Seq_Allele2")

  final_allele_counts <- foreach::foreach(x = 1:length(chrom_iter_list), .combine = rrbind, .packages = "gUtils") %dopar% {

    # Grab the mutation loci per chromosome and prep for use in alleleCounter
    which_col_names <- which(possible_col_names %in% colnames(mut_loci))
    mut_loci_per_chrom_dt <- mut_loci %>%
      dplyr::filter(seqnames == chrom_iter_list[x]) %>%
      dplyr::select(possible_col_names[which_col_names])

    # Now create temporary loci and output file that will be read in as an intermediate file
    temp_alleleCounter_outfile <- tempfile(pattern = stringr::str_remove(string = basename(bam_file_path), pattern = "\\.*\\.bam"),
                                           fileext = paste0(".temp.alleleCounter.", chrom_iter_list[x], ".out.txt"))

    temp_alleleCounter_locifile <- tempfile(pattern = stringr::str_remove(string = basename(bam_file_path), pattern = "\\.*\\.bam"),
                                            fileext = paste0(".temp.alleleCounter.", chrom_iter_list[x], ".loci.txt"))
    data.table::fwrite(x = mut_loci_per_chrom_dt,
                       file =  temp_alleleCounter_locifile,
                       row.names = FALSE,
                       col.names = FALSE,
                       sep = "\t",
                       quote = FALSE)

    # Execute command
    alleleCounter_exe <- paste("alleleCounter",
                               "-b", bam_file_path,
                               "-o", temp_alleleCounter_outfile,
                               "-l", temp_alleleCounter_locifile,
                               "-m", min_base_qual,
                               "-q", min_map_qual)
    system(command = alleleCounter_exe, wait = TRUE)

    # After execution of alleleCounter command, read in the temp output file
    system(command = "sleep 7", wait = TRUE)
    read_counts <- data.table::fread(file = temp_alleleCounter_outfile,
                                     sep = "\t")

    # Unlink temps
    unlink(temp_alleleCounter_outfile)
    unlink(temp_alleleCounter_locifile)

    # Return output of the foreach loops, each GR obj will be concatenated
    read_counts
  }

  # Return combined alleleCount output
  return(final_allele_counts)
}


#' @name get_corrected_cnv_profile
#' @title Read in CNV profile DT of various flavors and extract a corrected profile
#'
#' @description
#' Given a data.table or GRanges CNV object, extract the corrected CNV profile.
#' Any segment with a non-rounded value within 0.2 of the next integer value is rounded to that value.
#' The output will data.table will contain 6 columns: sample, seqnames, start, end, total, minor
#' The `sample` is either user-provided or row count placeholder
#' Currently supports CNV calls from Battenberg and FACETS
#'
#' @param cnv_obj CNV file in data.table or GRanges format
#' @param caller Name of caller that generated input CNV to be converted, supported: Battenberg and FACETS
#' @param sample_id Unique identifier to add to output, default: NULL
#'
#' @return data.table object with corrected CNV segments
#' @export
get_corrected_cnv_profile <- function(cnv_obj, caller, sample_id = NULL) {

  # First, check the CNV object. If data.table, continue on. If not, convert
  if(!"data.table" %in% class(cnv_obj) & "GRanges" %in% class(cnv_obj)) {
    cnv_dt <- gUtils::gr2dt(cnv_obj)

  } else if("data.table" %in% class(cnv_obj)) {
    cnv_dt <- cnv_obj

  } else {
    # Problem if input CNV object is not correct class
    stop(message = "\nInput CNV object needs to be either data.table or GRanges class")
  }

  # Create ID string for sample column
  sample_string <- dplyr::case_when(is.null(sample_id) ~ paste0("sample_X_", caller),
                                    !is.null(sample_id) ~ as.character(sample_id))

  # Case 1: FACETS directly reports total and minor copy number,
  #         only consideration is the occasional NA for minor allele as a result of low het count
  if(caller == "facets") {
    corrected_profile <- data.table::data.table("sample" = rep(sample_string, nrow(cnv_dt)),
                                                "seqnames" = cnv_dt$seqnames,
                                                "start" = cnv_dt$start,
                                                "end" = cnv_dt$end,
                                                "total" = cnv_dt$tcn.em,
                                                "minor" = dplyr::case_when(is.na(cnv_dt$lcn.em) ~ 0,
                                                                          !is.na(cnv_dt$lcn.em) ~ cnv_dt$lcn.em))

    # TODO: this will be depreciated when issues with Battenberg are addressed
    # Case 2: Battenberg (fit.cnv) reports both total and major/minor alleles in rounded and non-rounded format
  } else if(caller == "battenberg.fit") {

    # First, need to account for negative non-rounded values
    bb_cnv_dt <- cnv_dt

    # Get the correct value of the minor allele, is occasionally negative
    corrected_minor_allele <- pmax(bb_cnv_dt$minor_allele_nonrounded, 0)

    # Loop through the Battenberg minor allele segments
    rounded_bb_minor <- c()
    for(i in 1:length(corrected_minor_allele)) {
      # Gather clonally rounded minor alleles
      rounded_bb_minor[i] <- dplyr::case_when(corrected_minor_allele[i] < 0.2 ~ 0,
                                              between(x = corrected_minor_allele[i], left = 0.2, right = 0.8) ~ corrected_minor_allele[i],
                                              between(x = corrected_minor_allele[i], left = 0.8, right = 1.2) ~ 1,
                                              between(x = corrected_minor_allele[i], left = 1.2, right = 1.8) ~ corrected_minor_allele[i],
                                              between(x = corrected_minor_allele[i], left = 1.8, right = 2.2) ~ 2,
                                              between(x = corrected_minor_allele[i], left = 2.2, right = 2.8) ~ corrected_minor_allele[i],
                                              between(x = corrected_minor_allele[i], left = 2.8, right = 3.2) ~ 3,
                                              between(x = corrected_minor_allele[i], left = 3.2, right = 3.8) ~ corrected_minor_allele[i],
                                              between(x = corrected_minor_allele[i], left = 3.8, right = 4.2) ~ 4,
                                              between(x = corrected_minor_allele[i], left = 4.2, right = 4.8) ~ corrected_minor_allele[i],
                                              between(x = corrected_minor_allele[i], left = 4.8, right = 5.2) ~ 5,
                                              between(x = corrected_minor_allele[i], left = 5.2, right = 5.8) ~ corrected_minor_allele[i],
                                              between(x = corrected_minor_allele[i], left = 5.8, right = 6.2) ~ 6,
                                              between(x = corrected_minor_allele[i], left = 6.2, right = 6.8) ~ corrected_minor_allele[i],
                                              corrected_minor_allele[i] >= 6.8 ~ round(x = corrected_minor_allele[i], digits = 0))
    }

    # Get the correct value of the minor allele, is occasionally negative
    corrected_major_allele <- pmax(bb_cnv_dt$major_allele_nonrounded, 0)

    # Now calculate the correct non-rounded total copy number
    corrected_total_cn <- corrected_major_allele + corrected_minor_allele

    # Loop through the Battenberg total CN segments
    rounded_bb_total_cn <- c()
    for(i in 1:length(corrected_total_cn)) {
      # Gather clonally rounded minor alleles
      rounded_bb_total_cn[i] <- dplyr::case_when(corrected_total_cn[i] < 0.2 ~ 0,
                                                 between(x = corrected_total_cn[i], left = 0.2, right = 0.8) ~ corrected_total_cn[i],
                                                 between(x = corrected_total_cn[i], left = 0.8, right = 1.2) ~ 1,
                                                 between(x = corrected_total_cn[i], left = 1.2, right = 1.8) ~ corrected_total_cn[i],
                                                 between(x = corrected_total_cn[i], left = 1.8, right = 2.2) ~ 2,
                                                 between(x = corrected_total_cn[i], left = 2.2, right = 2.8) ~ corrected_total_cn[i],
                                                 between(x = corrected_total_cn[i], left = 2.8, right = 3.2) ~ 3,
                                                 between(x = corrected_total_cn[i], left = 3.2, right = 3.8) ~ corrected_total_cn[i],
                                                 between(x = corrected_total_cn[i], left = 3.8, right = 4.2) ~ 4,
                                                 between(x = corrected_total_cn[i], left = 4.2, right = 4.8) ~ corrected_total_cn[i],
                                                 between(x = corrected_total_cn[i], left = 4.8, right = 5.2) ~ 5,
                                                 between(x = corrected_total_cn[i], left = 5.2, right = 5.8) ~ corrected_total_cn[i],
                                                 between(x = corrected_total_cn[i], left = 5.8, right = 6.2) ~ 6,
                                                 between(x = corrected_total_cn[i], left = 6.2, right = 6.8) ~ corrected_total_cn[i],
                                                 corrected_total_cn[i] >= 6.8 ~ round(x = corrected_total_cn[i], digits = 0))
    }

    corrected_profile <- data.table::data.table("sample" = rep(sample_string, nrow(cnv_dt)),
                                                "seqnames" = cnv_dt$seqnames,
                                                "start" = cnv_dt$start,
                                                "end" = cnv_dt$end,
                                                "total" = rounded_bb_total_cn,
                                                "minor" = rounded_bb_minor)
    }

  # Return the final profile
  return(corrected_profile)
}


#' @name get_dryclean_segmentation
#' @title Generate a segmentation file from a dryclean fragCounter read depth profile
#'
#' @description
#' Given dryclean processed fragCounter read depth profile, run DNAcopy's CBS algorithm
#' in a parallel manner to produce a segmentation file that is compatible with GISTIC2.0.
#'
#' @param path_to_dryclean_profile Path to dryclean fragCounter read depth profile
#' @param threads Number of threads to use for parallel execution, default: 1
#' @param random_seed Numeric value to use as random seed for consistent execution
#'
#' @return data.table object with required GISTIC2.0 columns
#' @export
get_dryclean_segmentation <- function(path_to_dryclean_profile, threads = 1, random_seed = 999) {

  # Set parallel cores parameter
  message("Setting parallel cores to ", threads, " ...")
  doParallel::registerDoParallel(cores = threads)

  # Display the random number used for this run
  message("Setting random seed to ", random_seed, " ...")
  set.seed(random_seed)

  # Read in dryclean fragCounter coverage for normal sample
  message("Reading in drycleaned fragCounter coverage ...")
  sample_id <- basename(stringr::str_remove(string = path_to_dryclean_profile, pattern = "\\..*dryclean.*rds"))
  dryclean_frag_cov <- readRDS(file = path_to_dryclean_profile)

  # Grab the drycleaned fragCounter foreground read coverage values
  foreground_cov <- as.double(GenomicRanges::values(dryclean_frag_cov)[, "foreground"])

  # Add very small constant value to move zero values to non-zero values before segmentation
  zero_idx <- which(foreground_cov == 0)
  if(length(zero_idx) > 0) {
    small_const <- .Machine$double.eps
    foreground_cov <- foreground_cov + small_const
    message(paste(length(zero_idx),
                  "coverage data points have zero value, adding small constant value",
                  small_const,
                  "to prevent log error ..."))
  }

  # Grab index of all non-NA drycleaned foreground read covearge
  idx <- which(!is.na(foreground_cov))
  foreground_cov_nona <- foreground_cov[idx]
  seqnames_nona <- as.character(GenomicRanges::seqnames(dryclean_frag_cov))[idx]
  start_nona <- GenomicRanges::start(dryclean_frag_cov)[idx]

  # Begin foreach construct to parallelize the DNAcopy command per chromosome and then stitch the results together in a GRanges object
  chrom_iter_list <- as.character(unique(dryclean_frag_cov@seqnames@values))
  message("Running DNAcopy CBS segmentation workflow ...")

  final_cbs_segmentation <- foreach::foreach(x = 1:length(chrom_iter_list), .combine = rrbind, .packages = "gUtils") %dopar% {

    # Grab chromosome specific data for run the DNAcopy workflow
    per_chrom_idx <- which(seqnames_nona == chrom_iter_list[x])
    log_signal_per_chrom <- log(foreground_cov_nona)[per_chrom_idx]
    seqnames_per_chrom <- seqnames_nona[per_chrom_idx]
    start_per_chrom <- start_nona[per_chrom_idx]

    # Run DNAcopy CBS workflow
    scna_per_chrom <- DNAcopy::CNA(genomdat = log_signal_per_chrom,
                                   chrom = seqnames_per_chrom,
                                   maploc = start_per_chrom,
                                   data.type = 'logratio')

    scna_segmentation_per_chrom <- DNAcopy::segment(x = DNAcopy::smooth.CNA(scna_per_chrom),
                                                    alpha = 1e-5,
                                                    verbose = FALSE,
                                                    undo.splits = "sdundo",
                                                    undo.SD = 2)
    scna_segmentation_per_chrom_dt <- data.table::as.data.table(scna_segmentation_per_chrom$output)
    scna_segmentation_per_chrom_dt$ID <- sample_id

    # Return output of the foreach loops, each DT obj will be concatenated
    scna_segmentation_per_chrom_dt
  }

  # Return the DT of CBS output for easy downstream use
  message("Segmentation finished ...")
  return(final_cbs_segmentation)
}





#
#
# }}}}------->>> Reader functions
#
#

#' @name read_gtf_file
#' @title Read in a GTF file, such as one from Ensembl, and convert to GRanges object
#'
#' @description
#' Read in a GTF file which contains a number of columns and convert it to a GRanges object with refactored seq details.
#' The GTF file can be either zipped or unzipped.
#'
#' @param gtf_file_path Path to GTF file
#' @param seq_lengths Named vector object used as the template for new seq details, see `gUtils::hg_seqlengths()` for example
#'
#' @return GenomicRanges object with GTF columns and updated seqinfo, seqnames, seqlengths, seqlevels
#' @export
read_gtf_file <- function(gtf_file_path, seq_lengths = gUtils::hg_seqlengths()) {

  gtf_gr <- rtracklayer::import(gtf_file_path)

  # Sort out seqinfo/levels/lengths mess
  gtf_gr <- gr_refactor_seqs(input_gr = gtf_gr, new_levels = seq_lengths)
  return(gtf_gr)
}

#' @name get_genes_shortcut
#' @title Shortcut to get only protein coding genes from GTF file and convert to GRanges object
#'
#' @description
#' Read in a GTF file, subset to protein coding genes, and convert it to a GRanges object with refactored seq details.
#' The GTF file can be either zipped or unzipped.
#'
#' @param gtf_file_path Path to GTF file
#' @param seq_lengths Named vector object used as the template for new seq details, see `gUtils::hg_seqlengths()` for example
#'
#' @return GenomicRanges object with GTF columns and updated seqinfo, seqnames, seqlengths, seqlevels
#' @export
get_genes_shortcut <- function(gtf_file_path, seq_lengths = gUtils::hg_seqlengths()) {

  gtf_gr <- read_gtf_file(gtf_file_path = gtf_file_path, seq_lengths = seq_lengths)

  # Subset to protein coding biotype and non-NA gene symbols
  genes <- gtf_gr %Q% (gene_biotype == "protein_coding" & type == "gene" & !is.na(gene_name))
  return(genes)
}

#' @name read_maf_file
#' @title Read MAF file and convert to GRanges object
#'
#' @description
#' Read in a MAF file which contains a number of columns and convert it to a GRanges object with refactored seq details.
#' The MAF file can be either zipped or unzipped.
#' For more specific MAFtools operations, see `maftools::read.maf()`
#'
#' @param maf_file_path Path to MAF file
#' @param cpus number of cpus for reading in data, used by `data.table::fread()`, default: 2
#' @param seq_lengths Named vector object used as the template for new seq details, see `gUtils::hg_seqlengths()` for example
#'
#' @return GenomicRanges object with MAF columns and updated seqinfo, seqnames, seqlengths, seqlevels
#' @export
read_maf_file <- function(maf_file_path, cpus = 2, seq_lengths = gUtils::hg_seqlengths()) {

  # Set available threads
  doParallel::registerDoParallel(cores = cpus)

  # Read in MAF with extra speed
  maf_dt <- data.table::fread(input = maf_file_path,
                              sep = "\t",
                              header = TRUE,
                              stringsAsFactors = FALSE,
                              nThread = cpus)
  maf_gr <- gUtils::dt2gr(maf_dt)

  # Sort out seqinfo/levels/lengths mess
  maf_gr <- gr_refactor_seqs(input_gr = maf_gr, new_levels = seq_lengths)
  return(maf_gr)
}

#' @name read_bed_file
#' @title Read in a BED file, with or without header, and convert to GRanges object
#'
#' @description
#' Read in a BED file and convert it to a GRanges object with refactored seq details.
#' Expects the first 3 columns as chromosome, start, end; However column names are not necessary
#' The BED file can be either zipped or unzipped.
#'
#' @param bed_file_path Path to BED file
#' @param has_header Does BED file have header line
#' @param additional_col_names Names for additional columns in BED file, beyond first three
#' @param cpus number of cpus for reading in data, used by `data.table::fread()`, default: 1
#' @param seq_lengths Named vector object used as the template for new seq details, see `gUtils::hg_seqlengths()` for example
#'
#' @return GenomicRanges object with BED columns, if present, and updated seqinfo, seqnames, seqlengths, seqlevels
#' @export
read_bed_file <- function(bed_file_path, has_header = FALSE, additional_col_names = NULL, cpus = 1, seq_lengths = gUtils::hg_seqlengths()) {

  # Set available threads
  doParallel::registerDoParallel(cores = cpus)

  # Read in file with options to account for various combinations of header/columns
  # Case 1: no header
  if(has_header == F) {
    bed_dt <- data.table::fread(input = bed_file_path,
                                sep = "\t",
                                header = has_header,
                                stringsAsFactors = FALSE,
                                nThread = cpus)

    # Subcase condition 1: only 3 columns
    if(ncol(bed_dt) == 3 & is.null(additional_col_names)) {
      colnames(bed_dt) <- c("chr", "start", "end")
    # Subcase condition 2: more than 3 columns, no additional names given
    } else if(ncol(bed_dt) > 3 & is.null(additional_col_names)) {
      colnames(bed_dt)[1:3] <- c("chr", "start", "end")
    # Subcase condition 3: more than 3 columns, additional names given
    } else if(ncol(bed_dt) > 3 & !is.null(additional_col_names)) {
      colnames(bed_dt) <- c("chr", "start", "end", additional_col_names)
    }

  # Case 2: has a header
  } else if(has_header == T) {
    bed_dt <- data.table::fread(input = bed_file_path,
                                sep = "\t",
                                header = has_header,
                                stringsAsFactors = FALSE,
                                nThread = cpus)

    # Subcase condition 1: only 3 columns
    if(ncol(bed_dt) == 3 & is.null(additional_col_names)) {
      colnames(bed_dt) <- c("chr", "start", "end")
      # Subcase condition 2: more than 3 columns
    } else if(ncol(bed_dt) > 3 & is.null(additional_col_names)) {
      colnames(bed_dt)[1:3] <- c("chr", "start", "end")
    }
  }

  # Edge Case: Check for use of 23/24 for chrX/chrY
  chromosome_set <- unique(bed_dt$chr)
  if(23 %in% chromosome_set) {
    message("Chromosome `23` detected ...\nConverting to `chrX` ...")
    bed_dt$chr <- dplyr::recode(bed_dt$chr, `23` = "X", .default = as.character(bed_dt$chr))
  }
  if(24 %in% chromosome_set) {
    message("Chromosome `24` detected ...\nConverting to `chrY` ...")
    bed_dt$chr <- dplyr::recode(bed_dt$chr, `24` = "Y", .default = as.character(bed_dt$chr))
  }

  bed_gr <- gUtils::dt2gr(bed_dt)

  # Sort out seqinfo/levels/lengths mess
  bed_gr <- gr_refactor_seqs(input_gr = bed_gr, new_levels = seq_lengths)
  return(bed_gr)
}

#' @name read_vcf_file
#' @title Read in a VCF file and convert to GRanges object
#'
#' @description
#' Read in a VCF file and convert it to a GRanges object with refactored seq details.
#' Currently supports conversion of somatic SNV/InDel VCFs from Mutect, Strelka, Varscan, SvABA, CaVEMan.
#' Also supports conversion of germline SNP/InDel VCF from DeepVariant.
#' The VCF file can be either zipped or unzipped.
#'
#' @param vcf_file_path Path to VCF file
#' @param tumor_sample Name of tumor sample as reported in VCF
#' @param normal_sample Name of normal sample as reported in VCF
#' @param caller Name of the caller that generated input VCF to be converted, supported: mutect, strelka, varscan, svaba, caveman, deepvariant
#' @param mut_type Type of mutations within VCF, supported: snv, indel, snp
#' @param seq_lengths Named vector object used as the template for new seq details, see `gUtils::hg_seqlengths()` for example
#'
#' @return GenomicRanges object with VCF FILTER/INFO/FORMAT columns, if present, and updated seqinfo, seqnames, seqlengths, seqlevels
#' @export
read_vcf_file <- function(vcf_file_path, tumor_sample = NULL, normal_sample = NULL,
                          caller = NULL, mut_type = NULL, seq_lengths = gUtils::hg_seqlengths()) {

  # Read in VCF into VA VCF obj
  vcf_va <- VariantAnnotation::readVcf(file = vcf_file_path)

  # Build the GRanges obj from VCF obj
  # Start by setting the GRanges base and exclude the paramRangesID column
  vcf_gr_base <- vcf_va@rowRanges[,-1]

  # remove names of range rows
  names(vcf_gr_base) <- NULL

  # Have user provide tumor_sample and normal_sample
  # Create metadata column with patient and sample name
  vcf_query_ids <- vcf_va@metadata$header@samples

  # Edge case: SvABA uses BAM name for SAMPLE columns in VCF
  if(caller %in% c("svaba")) {
    vcf_query_ids <- stringr::str_remove(string = vcf_query_ids, pattern = "\\..+\\.bam$")
  }

  # Add column for name of caller
  vcf_gr_base$CALLER <- caller

  # Sanity Check: Do VCF query IDs match user-provided tumor/normal parameters?
  # Check if germline first then somatic
  # DeepVariant only uses normal sample for germline
  if(caller == "deepvariant" & is.null(tumor_sample) & !is.null(normal_sample)) {
    vcf_normal_sample_index <- 1

    vcf_gr_base$PATIENT <- normal_sample
    vcf_gr_base$NORMAL <- normal_sample

  } else if(caller %in% c("mutect", "svaba") & tumor_sample %in% vcf_query_ids & normal_sample %in% vcf_query_ids) {
    vcf_tumor_sample_index <- which(tumor_sample == vcf_query_ids)
    vcf_normal_sample_index <- which(normal_sample == vcf_query_ids)

    vcf_gr_base$TUMOR <- vcf_query_ids[vcf_tumor_sample_index]
    vcf_gr_base$NORMAL <- vcf_query_ids[vcf_normal_sample_index]

    vcf_gr_base$SAMPLE <- vcf_query_ids[vcf_tumor_sample_index]
    vcf_gr_base$PATIENT <- vcf_query_ids[vcf_normal_sample_index]

    # Strelka, VarScan, CaVEMan uses generic NORMAL and TUMOR/TUMOUR as name of SAMPLE columns instead of sample ID/BAM basename
  } else if(caller %in% c("strelka", "varscan", "caveman") & !is.null(tumor_sample) & !is.null(normal_sample)) {

    vcf_tumor_sample_index <- which(vcf_query_ids %in% c("TUMOR", "TUMOUR"))
    vcf_normal_sample_index <- which(vcf_query_ids == "NORMAL")

    vcf_gr_base$SAMPLE <- tumor_sample
    vcf_gr_base$TUMOR <- tumor_sample

    vcf_gr_base$PATIENT <- normal_sample
    vcf_gr_base$NORMAL <- normal_sample

  } else {
    # Problem if there is no proper combo of samples and caller
    stop(message = "\nTumor/Normal sample names provided NOT FOUND in VCF")
  }

  # Now form the final GRanges obj by grabbing the REF, ALT, QUAL, FILTER, and all INFO columns
  vcf_gr <- vcf_gr_base
  S4Vectors::mcols(vcf_gr) <- c(S4Vectors::mcols(vcf_gr_base), vcf_va@fixed, vcf_va@info)

  # Convert the REF/ALT field from DNA Biostring to character
  # ALT
  if(!is.character(vcf_gr$ALT)) {
    vcf_gr$ALT <- as.character(unlist(vcf_va@fixed$ALT))  # Needed for SNVs primarily but not exclusively
  }
  # REF
  if(!is.character(vcf_gr$REF)) {
    vcf_gr$REF <- unlist(stringr::str_split(string = Biostrings::toString(vcf_va@fixed$REF), pattern = ", "))  # Needed for InDels
  }

  # Add tumor and normal specific DP field
  if(caller %in% c("mutect", "varscan", "strelka", "caveman")) {
    vcf_gr$DP_TUMOR <- vcf_va@assays@data@listData$DP[,vcf_tumor_sample_index]
    vcf_gr$DP_NORMAL <- vcf_va@assays@data@listData$DP[,vcf_normal_sample_index]

  } else if(caller == "deepvariant") {
    vcf_gr$DP_NORMAL <- vcf_va@assays@data@listData$DP[,vcf_normal_sample_index]
  }

  if(caller == "mutect") {
    # FORMAT fields are stored in list of lists, need to properly extract tumor AD, AF and normal AD
    # When unlisting the AD/AF fields, the allele depth is split into REF and ALT columns
    # so easily grab with even (ALT) and odd (REF) vector index
    vcf_tumor_allele_depth <- unlist(vcf_va@assays@data@listData$AD[,vcf_tumor_sample_index])
    odd_even_index <- seq_len(length(vcf_tumor_allele_depth)) %% 2

    vcf_gr$AD_REF_TUMOR <- vcf_tumor_allele_depth[odd_even_index == 1]
    vcf_gr$AD_ALT_TUMOR <- vcf_tumor_allele_depth[odd_even_index == 0]

    vcf_gr$AF_TUMOR <- unlist(vcf_va@assays@data@listData$AF[,vcf_tumor_sample_index])
    vcf_gr$GT_TUMOR <- vcf_va@assays@data@listData$GT[,vcf_tumor_sample_index]

    vcf_normal_allele_depth <- unlist(vcf_va@assays@data@listData$AD[,vcf_normal_sample_index])
    vcf_gr$AD_REF_NORMAL <- vcf_normal_allele_depth[odd_even_index == 1]
    vcf_gr$AD_ALT_NORMAL <- vcf_normal_allele_depth[odd_even_index == 0]

    vcf_gr$GT_NORMAL <- vcf_va@assays@data@listData$GT[,vcf_normal_sample_index]

    # Some INFO metrics need to be reformatted from complex to simple (i.e. list to vector)
    vcf_gr$AS_FilterStatus <- unlist(vcf_gr$AS_FilterStatus)
    vcf_gr$AS_UNIQ_ALT_READ_COUNT <- unlist(vcf_gr$AS_UNIQ_ALT_READ_COUNT)

    MBQ_1 <- unlist(vcf_gr$MBQ)[odd_even_index == 1]
    MBQ_2 <- unlist(vcf_gr$MBQ)[odd_even_index == 0]
    vcf_gr$MBQ <- stringr::str_c(MBQ_1, MBQ_2, sep = ",")

    MFRL_1 <- unlist(vcf_gr$MFRL)[odd_even_index == 1]
    MFRL_2 <- unlist(vcf_gr$MFRL)[odd_even_index == 0]
    vcf_gr$MFRL <- stringr::str_c(MFRL_1, MFRL_2, sep = ",")

    MMQ_1 <- unlist(vcf_gr$MMQ)[odd_even_index == 1]
    MMQ_2 <- unlist(vcf_gr$MMQ)[odd_even_index == 0]
    vcf_gr$MMQ <- stringr::str_c(MMQ_1, MMQ_2, sep = ",")

    vcf_gr$MPOS <- unlist(vcf_gr$MPOS)
    vcf_gr$NALOD <- unlist(vcf_gr$NALOD)
    vcf_gr$NLOD <- unlist(vcf_gr$NLOD)
    vcf_gr$POPAF <- unlist(vcf_gr$POPAF)

    RPA_1 <- unlist(vcf_gr$RPA)[odd_even_index == 1]
    RPA_2 <- unlist(vcf_gr$RPA)[odd_even_index == 0]
    vcf_gr$RPA <- stringr::str_c(RPA_1, RPA_2, sep = ",")

    vcf_gr$TLOD <- unlist(vcf_gr$TLOD)

  } else if(caller == "strelka" & mut_type == "snv") {
    # Strelka VCF breaks down reads by nucleotide, then by tier
    vcf_gr$AU_TIER1_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$AU)[,vcf_tumor_sample_index]
    vcf_gr$AU_TIER2_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$AU)[,vcf_tumor_sample_index + 2]

    vcf_gr$CU_TIER1_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$CU)[,vcf_tumor_sample_index]
    vcf_gr$CU_TIER2_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$CU)[,vcf_tumor_sample_index + 2]

    vcf_gr$GU_TIER1_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$GU)[,vcf_tumor_sample_index]
    vcf_gr$GU_TIER2_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$GU)[,vcf_tumor_sample_index + 2]

    vcf_gr$TU_TIER1_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$TU)[,vcf_tumor_sample_index]
    vcf_gr$TU_TIER2_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$TU)[,vcf_tumor_sample_index + 2]

    vcf_gr$AU_TIER1_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$AU)[,vcf_normal_sample_index]
    vcf_gr$AU_TIER2_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$AU)[,vcf_normal_sample_index + 2]

    vcf_gr$CU_TIER1_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$CU)[,vcf_normal_sample_index]
    vcf_gr$CU_TIER2_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$CU)[,vcf_normal_sample_index + 2]

    vcf_gr$GU_TIER1_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$GU)[,vcf_normal_sample_index]
    vcf_gr$GU_TIER2_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$GU)[,vcf_normal_sample_index + 2]

    vcf_gr$TU_TIER1_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$TU)[,vcf_normal_sample_index]
    vcf_gr$TU_TIER2_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$TU)[,vcf_normal_sample_index + 2]

  } else if(caller == "strelka" & mut_type == "indel") {
    # Strelka has different FORMAT fields for indel VCF, most relevant is TIR (Reads strongly supporting indel allele for tiers 1,2)
    vcf_gr$TIR_TIER1_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$TIR)[,vcf_tumor_sample_index]
    vcf_gr$TIR_TIER2_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$TIR)[,vcf_tumor_sample_index + 2]

    vcf_gr$TIR_TIER1_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$TIR)[,vcf_normal_sample_index]
    vcf_gr$TIR_TIER2_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$TIR)[,vcf_normal_sample_index + 2]

  } else if(caller == "varscan") {
    # Varscan breaks down the read depth into 2 separate fields as ref read depth and variant read depth
    vcf_gr$RD_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$RD)[,vcf_tumor_sample_index]
    vcf_gr$AD_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$AD)[,vcf_tumor_sample_index]

    vcf_gr$FREQ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$FREQ)[,vcf_tumor_sample_index]
    vcf_gr$GT_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$GT)[,vcf_tumor_sample_index]

    vcf_gr$RD_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$RD)[,vcf_normal_sample_index]
    vcf_gr$AD_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$AD)[,vcf_normal_sample_index]

    vcf_gr$FREQ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$FREQ)[,vcf_normal_sample_index]
    vcf_gr$GT_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$GT)[,vcf_normal_sample_index]

  } else if(caller == "svaba") {
    # SvABA also provides the SR FORMAT field for number of spanning reads for the variants
    vcf_gr$AD_TUMOR <- vcf_va@assays@data@listData$AD[,vcf_tumor_sample_index]
    vcf_gr$SR_TUMOR <- vcf_va@assays@data@listData$SR[,vcf_tumor_sample_index]
    vcf_gr$GT_TUMOR <- vcf_va@assays@data@listData$GT[,vcf_tumor_sample_index]

    vcf_gr$AD_NORMAL <- vcf_va@assays@data@listData$AD[,vcf_normal_sample_index]
    vcf_gr$SR_NORMAL <- vcf_va@assays@data@listData$SR[,vcf_normal_sample_index]
    vcf_gr$GT_NORMAL <- vcf_va@assays@data@listData$GT[,vcf_normal_sample_index]

    # Some INFO metrics are complex format but empty, remove them here
    vcf_gr <- vcf_gr[,!colnames(S4Vectors::mcols(vcf_gr)) %in% c("READNAMES", "BX")]

  } else if(caller == "caveman") {
    # CaVEMan provides a format field for each nucleotide type per forward and reverse strand reads at the variant
    # The DS metric is complex format but empty/redundant, remove them here
    vcf_gr <- vcf_gr[,!colnames(S4Vectors::mcols(vcf_gr)) == "DS"]

    vcf_gr$FAZ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$FAZ)[,vcf_tumor_sample_index]
    vcf_gr$FCZ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$FCZ)[,vcf_tumor_sample_index]
    vcf_gr$FGZ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$FGZ)[,vcf_tumor_sample_index]
    vcf_gr$FTZ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$FTZ)[,vcf_tumor_sample_index]
    vcf_gr$RAZ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$RAZ)[,vcf_tumor_sample_index]
    vcf_gr$RCZ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$RCZ)[,vcf_tumor_sample_index]
    vcf_gr$RGZ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$RGZ)[,vcf_tumor_sample_index]
    vcf_gr$RTZ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$RTZ)[,vcf_tumor_sample_index]
    vcf_gr$PM_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$PM)[,vcf_tumor_sample_index]
    vcf_gr$GT_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$GT)[,vcf_tumor_sample_index]

    vcf_gr$FAZ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$FAZ)[,vcf_normal_sample_index]
    vcf_gr$FCZ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$FCZ)[,vcf_normal_sample_index]
    vcf_gr$FGZ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$FGZ)[,vcf_normal_sample_index]
    vcf_gr$FTZ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$FTZ)[,vcf_normal_sample_index]
    vcf_gr$RAZ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$RAZ)[,vcf_normal_sample_index]
    vcf_gr$RCZ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$RCZ)[,vcf_normal_sample_index]
    vcf_gr$RGZ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$RGZ)[,vcf_normal_sample_index]
    vcf_gr$RTZ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$RTZ)[,vcf_normal_sample_index]
    vcf_gr$PM_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$PM)[,vcf_normal_sample_index]
    vcf_gr$GT_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$GT)[,vcf_normal_sample_index]

  } else if(caller == "deepvariant") {

    vcf_gr$REF_AD_NORMAL <- as.vector(unlist(as.data.frame(vcf_va@assays@data@listData$AD[,])[1,]))
    vcf_gr$ALT_AD_NORMAL <- as.vector(unlist(as.data.frame(vcf_va@assays@data@listData$AD[,])[2,]))
    vcf_gr$VAF_NORMAL <- as.vector(unlist(as.data.frame(vcf_va@assays@data@listData$VAF[,])[1,]))
    vcf_gr$GT_NORMAL <- vcf_va@assays@data@listData$GT[,]

    # Remove some populated columns
    GenomicRanges::mcols(vcf_gr) <- GenomicRanges::mcols(vcf_gr)[,-c(8:12)]
  }

  # Sort out seqinfo/levels/lengths mess
  vcf_gr <- gr_refactor_seqs(input_gr = vcf_gr, new_levels = seq_lengths)
  return(vcf_gr)
}











#' @name aggregate_these
#' @title Read in all data files of a specific grep pattern, aggregate them into a single data.table
#'
#' @description
#' Collect all files that match a specific `ls`-style pattern at a specific path, read them into a data.table, then aggregate
#' all into single data.table. Best suited for genomic data formats such as SNV/InDel mutation table, CNV BED, or SV BEDPE.
#'
#' @param path_to_files path to location of files to be aggregated
#' @param pattern_to_grab `ls`-style pattern used to identify files
#' @param delim delimiter used in files to be aggregated, expected to be same in all files
#' @param has_header indicate if files have a header line, expected to be same in all files
#' @param cpus number of cpus for reading in data, used by `data.table::fread()`
#' @param add_uniq_id indicate if the output data.table should include a unique identifier column, derived from input file basename
#'
#' @return data.table object with all data under preserved column construct
#' @export
aggregate_these <- function(path_to_files, pattern_to_grab, delim = "\t", has_header = TRUE,
                            cpus = 1, add_uniq_id = FALSE) {

  # Set available threads
  doParallel::registerDoParallel(cores = cpus)

  # Find all files at the provided path that match the provided pattern
  input_files_to_aggregate <- list.files(path = path_to_files,
                                         pattern = pattern_to_grab)

  # Create output DT to fill with aggregated data
  aggregate_dt <- data.table::data.table()
  for(i in 1:length(input_files_to_aggregate)) {

    # Read in single file
    dt_to_add <- data.table::fread(input = paste0(path_to_files, input_files_to_aggregate[i]),
                                   sep = delim,
                                   header = has_header,
                                   stringsAsFactors = F,
                                   nThread = cpus)

    # Some file formats do not explicitly have a patient/sample column or any unique identifier
    # Let's add one derived from the input file name, if needed
    if(add_uniq_id) {
      uniq_id <- str_remove(string = input_files_to_aggregate[i], pattern = "\\..*$")
      dt_to_add$id <- uniq_id
    }

    # Add to aggregate DT
    aggregate_dt <- gUtils::rrbind(aggregate_dt, dt_to_add, as.data.table = T)
  }

  # TODO: The sort functionality is bugged, aggregated file has some sort of mix-and-match of columns
  # sort_output = TRUE,
  # #' @param sort_output indicate if the output data.table should be sorted by genomic coordinate, BEDPE not supported yet
  # Sort the output by genomic coordinate if desired
  #if(sort_output) {
  #
  #  # TODO: BEDPE files don't translate from DT to GR with standard header, likely need gGnome junctions
  #  # Convert to GR to run foolproof sorting
  #  aggregate_gr <- gr_refactor_seqs(input_gr = gUtils::dt2gr(aggregate_dt))
  #  aggregate_dt <- gUtils::gr2dt(x = aggregate_gr)
  #}
  return(aggregate_dt)
}




