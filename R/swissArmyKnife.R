######################################################################################
#                         ___   ___        ____   ____                               #
#                          | | |     |   /  |     |   | |   |                        #
# }}}}------->>>           + | |-+-  |  +   | +-  |-+-  |   |         <<<-------{{{{ #
#                          | | |     | /    |   | |  \  |   |                        #
#                         ---   ---   /      ---      \  ---                         #
######################################################################################
# ▒▓▓▒▒▒▒▒▒▒▒▓▓▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▓▒▒▒▒▒▒▒▒▒▒▒▒
# ▒▒▒▒▒░▒▒▒▒▓▓▒▒▒▒░░░░░░░░░░░░░░░░░░▒▒░░░░░░░░▒░░░░░░░▒░░░░░░░░░░░░░░░░░░▒▒▒▓▓▓▒▒▒▒▒▒▒
# ▒▒▒▒▒░░░░▒▒▒▒▒░░░░░░░░░░░░░░░░░░░░░▒▒▒▒▒▒▒▒▒▒▒▒▒▒░░░░░░░░░░░▒▒▒▒▒░░░░░░░░▒▒▒▓▓▒▒▒▒▒▒
# ▒▒▒▒▒░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░▒▓▓▓▓▓▓▓▒▒▒▒▒░░░░░░░░░▒▒▒▒▓▓▓▓▒░░░░░░░▒▒▓▓▓▒▒▒▓▓
# ▒▒▒▒▒░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░▒▒▒▓▒▓▓▓▓▓▓▓▓▒▒▒░░░░░░▒▓▓▓▒▒▒▓▓▓▒░░░░░░░▒▒▓▓▓▒▒▒▒
# ▒▒▒▒▒▒░░░░░░░▒▒░░░░░░░░░░░░░░░▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░░░░░▒▓▒░░░░▒▒▓▓▒░░░░░░░░▒▒▒▒▒▒▒
# ▒▒▒▒▒▒░░░░░▒▒▒▒▓▒░░░░░░░░░░░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░▒▒▒░░░░░░▒▓▓▒░░░░░░░░░▒▒▒▒▒▒
# ▒▒▒▒▒░░░░░░▒▓▓▓▓▓▒░░░░░▒▒▒▒░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░░░░░░░░░░░▒▓▓▒░░░░░░░░░▒▒▒▒▒▒
# ▒▒▒▒▒░░░░░░▒▓▓▓▓▓▓░░░░░▒▒▓▓▒▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░░░░░░░▒▒▒▒▓▒░░░░░░░░░░▒▒▒▒▒░
# ▒▒▒▒▒▒▒░░░░░░▒▓▓▓▒▒░░░░░░▒▒▒▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░░▒▒▒▒▓▓▓▓▓▒▒░░░░░░░░░▒▒▒▒▒░
# ▒▒▒▒▒▒▒░░░░░░▒▓▓▓▓▓▒░░░░░░░░░░░▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░░░░░▒▓▓▓▓▓▓▒▒░░░░░░░░░░░▒▒▒▒▒░
# ▒▒▒▒▒▒▒░░░░▒▒▓▓▓▓▓▓▓▒░░░░░░░░░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒▒▒░░░░░░▒▒▓▓▓▓▒▒░░░░░░░░░░░░▒▒▓▒▒▒▒
# ▒▒▒▒▒▒▒░░░▒▒▒▓▓▓▓▓▓▓▓▓▒░░░░░░░░▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░▒▒▓▓▓▓▒▒░░░░░░░░░░▒▒▒▒▓▒▒▒▒
# ▒▒▒▒▒▒▒░░░░░░░░░░▒▒▓▓▓▓▓▒▒▒▒▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▓▒░░░░░░░░░▒▒▓▓▓▒▒░░░░░░░░░▒▒▓▓▓▓▓▒▒▒
# ▒▒▒▒▒▒▒░░░░░░░░░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░░░░░░▒▓▓▓▒░░░░░░░░░░░▒▒▓▓▓▓▒▒
# ▒▒▒▒▒▒▒▒░░░░░░░░░░░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░░░░░░▒▒▓▓▓▒░░░░░░░░░░░░▒▓▓█▒▒
# ▒▒▒▒▒▒▒▒░░░░░░░░░░░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░▒▒░░░░░░░░░░░▒▓▓▒░░░░░░░░░░░▒▓▓▓▒▒
# ▒▒▒▒▒▒▒▒░░░░░░░░░░░░▒▒▒▒░▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒▒▒░░░░░░░░░░░▒▒▓▒▒░░░░░░░░░▒▓▓▓▒▒
# ▒▒▒▒▓▒▒▒░░░░░░░░░░░░░░░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒▒░░░░░░░░░░░░░▒▓▓▒▒░░░░░░░▒▓▓▓▒▒
# ▒▓▒▓▒▒▒▒▒▒▒▒░░░░░░░░░▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░░░░░░▒▓▓▒░░░░░░░▒▓▓▒▒▒▒
# ▒▒▒▒▒▒▒▒▒▓▓▓▓▒░░░░░░▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░░░░░░░░░▒▓▓▒▒░░░░░░▒▒▓▓▒▒
# ▒▒▒▒▓▒▒▒▒▓▓█▓▓▒▒░▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒▒▒▒▒▒▒▒▒▓▓▓▒▒░░░░░▒▒▓▓▒▒▒
# ▒▒▒▓▓▒▒░▒▒▒▓█▓▓▓▓▓▓██▓▓▓▓▓▓▓▓▓▓▒▒▒▒▒▒▒▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░░░░░▒▒▓▒▒▒
# ▒▒▒▒▓▒▒░░▒▒▓▓██████▓▓▓▒▒▒▒▒▒▒▒▒░░░░░░░░░▒▒▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░░░░░░▒▓▓▒▒▒
# ▒▒▒▒▓▒▒▒▒▒▒▓▓██▓▓▓▒▒░░░░░░░░░░░░░░░░▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░░▒▒▓▒▒▒
# ▒▒▒▒▓▒▒▒▒▒▓▓▓▓▓▒▒▒░░░░░░░░░░░░░░░░▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓█▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░░░░░▒▒▒▒▒▒
# ▓▓▒▒▓▓▓▒▒▒▒▒▒▒▒▒░░░░░░░░░░░░░░░░░░▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░░▒▒▒▒▓▒▒▒
# ▒▒▒▒▒▓▓▒▒▒▒▒░░▒░░░░░░░░░░░░░░░░░░░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░░░▒▓▒▓▓▒▒
# ▒▒▒▒▒▓▓▓▓▒▒▒░░░░░░░░░░░░░░░░░▒▒▒▒░░▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░▒▒▓▓▒▒
# ▒▒▒▒▒▓▒▒▒▓▒▒▒░░░░░░░░░░░░░░▒▒▓▓▓▓▓▒▒░░░▒▒▒▓▓▓▓▓▓▓▓▒▒▒░░░░░▒▒▒▓▓▓▓▓▓▓▓▓▓▓▒▒░░░▒▒▒▓▒▒▒
# ▓▒▒▒▓▓▓▒▒▓▒▒▒▒░░▒░░░░░░░░░░▒▒▒▓▓▓▓▓▓▒▒▒▒▒▒▒▒▓▓▓▓▓▓▓▓▒▒░░░░░░░░▒▒▓▓▓▓▓▓▓▒▒▓▒░░░▒▒▓▓▒▒
# ▓▒▒▒▓▓▒▒▓▓▒▒▒▒▒▒▒▒░░░░░░░░░░▒▒▒▒▒▓▓▓▓▓▓▓▓▓▒▓▓▓▓▓▓▓▓▒▒▒░░░░░░░░░░▒▒▓▓▓▓▓▓▒░░░░░▒▒▒▒▒▒
# ▓▒▒▒▓▓▒▒▓▓▓▒▒▒▒▒▒▒▒▒▒▒░░░░░▒▒▒▒▒▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░▒▒▒░░░▒▒▒▓▓▓▓▒▒░░░░▒▒▒▒▒▒
# ▓▒▒▒▓▓▓▒▓▓▒▒▒▒▓▒▒▒▒▒▒▒▒▒░░░▒▒▓▓▒▒▒▒▒▓▓▓▒▒▒▒▒▒▒▓▓▓▓▓▓▒░░░░░░▒▒▒░▒▒▒▒▒▓▓▓▓▓▓▒▒▒░▒▒▒▒▒▒
# ▓▒▒▒▒▓▓▓▓▓▓▓▒▒▓▒▒▒▒▒▒▒▒▒░░░▒░▒▒▒▒▒▒▒▒▒▒▒░░░░░░▒▒▒▓▒▒▒░░░░░░░░░▒▒▒▓▓▓▓▓▓▓▓▓▓▓▒▒▒▒▒▒▒▒
# ▒▓▒▒▒▓▓▓▓▒▒▓▓▓▓▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒░░▒▒░░░░░░░░░░░░░░░▒░▒▒▒▒▒▒▓▓▓▓▓▓▓▒▓▓▓▓▓▓▓▒▒▒▒▒
# ▒▒▒▒▒▓▓▓▓▓▓▓▓▓▓▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒░▒▒▒▒▒▒▒▒▒▒▒░░░░░▒░░░░░░░▒▒▒▒▓▓▓▓▓▒▒▒▒▒▒░▒▒▓▓▓▓▒▒▒▒▒
# ▒▒▒▒▒▒▒▓▓▓▓▓▒▒▒▓▒▓▓▓▓▓▓▒▒▒▓▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒░░░░░░▒▒▒░░░░▒▒▒▒▓▓▒▓▒▒▓▓▓▓▒▒▒▒▒▓▒▒▓▒▒▒▒▒▒
# ▓▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▓▓▓▒▓▓▓▓▒▒▒▓▓▓▓▓▓▒▒▒▒▓▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒
#                                                                                    #
# }}}}------->>>                                                      <<<-------{{{{ #

#' @import gUtils
#' @import GenomicRanges
#' @import GenomeInfoDb
#' @import data.table
#' @import VariantAnnotation
#' @import stringr
#' @import dplyr
#' @import ggplot2
#' @import scales
#' @import paletteer
#' @import patchwork
#' @import ggpubr
#' @import ggside
#' @import stats

#' @importFrom librarian shelf
#' @importFrom BSgenome.Hsapiens.UCSC.hg38 Hsapiens
#' @importFrom rtracklayer import
#' @importFrom readr read_delim
#' @importFrom S4Vectors mcols
#' @importFrom Biostrings toString
#' @importFrom doParallel registerDoParallel
#' @importFrom foreach foreach
#' @importFrom foreach `%dopar%`
#' @importFrom paint paint
#' @importFrom reshape2 melt
#' @importFrom purrr as_vector
#' @importFrom ggridges stat_density_ridges
#' @importFrom ggfittext geom_bar_text


# Appease R CMD CHECK misunderstanding of data.table/data.frame/ggplot2 syntax by declaring these 'global' variables
# Split these into multiple rows just for better aesthetics as there are many
x=DeletionRate=FractionCovered=InsertionRate=Mapped=MappedForwardFraction=MappedProperFraction=NULL
MappedReverseFraction=MedianCoverage=MedianInsertSize=Sample=alignment_group=fraction=med_reads=NULL
alignment_group=fraction=med_reads=median_count=tumor_normal=ALT=CALLER=REF=SAMPLE=total_indels=NULL
total_per_caller=total_snvs=gene_biotype=type=gene_name=AD_ALT_TUMOR=AD_TUMOR=AF_TUMOR=DP_TUMOR=NULL
FREQ_TUMOR=PM_TUMOR=TIR_TIER1_TUMOR=nearest_gene=NULL

# Set up the global default genome and number display
.onLoad <- function(libname, pkgname) {
  op <- options()
  op.devgru <- list(
  	devgru.ref_genome = "hg38"
  )
  toset <- !(names(op.devgru) %in% names(op))
  if (any(toset)) options(op.devgru[toset])

  Sys.setenv(DEFAULT_BSGENOME = 'BSgenome.Hsapiens.UCSC.hg38::Hsapiens')
  Sys.setenv(DEFAULT_GENOME = 'BSgenome.Hsapiens.UCSC.hg38::Hsapiens')
  options(scipen = 999)

  invisible()
}


#' @name kit_loadout
#' @title Build the devgru environment by installing/loading packages
#'
#' @description
#' Single command to install, if needed, and load all packages used in the devgru kit.
#'
#' @param update_kit Update all packages even if already installed, default: TRUE
#'
#' @export
kit_loadout <- function(update_kit = T) {

  logo_viz <- "
#                   ___   ___        ____   ____                          #
#                    | | |     |   /  |     |   | |   |                   #
# }}}}------->>>     + | |-+-  |  +   | +-  |-+-  |   |    <<<-------{{{{ #
#                    | | |     | /    |   | |  \\  |   |                   #
#                   ---   ---   /      ---      \\  ---                    #
"

  # Packages for loadout
  loadout <- c("BSgenome.Hsapiens.UCSC.hg38", "GenomicRanges", "GenomeInfoDb",
               "data.table", "mskilab-org/gUtils", "VariantAnnotation",
               "rtracklayer", "Biostrings", "S4Vectors", "dplyr",
               "stringr", "readr", "ggplot2", "ggsci", "paletteer", "scico",
               "flextable", "mclust", "parallel", "doParallel", "foreach",
               "R.utils")

  loadout_string <- "
  ### GenomicRanges Core ###

  BSgenome.Hsapiens.UCSC.hg38
  GenomicRanges
  GenomeInfoDb
  data.table
  mskilab-org/gUtils
  VariantAnnotation
  rtracklayer
  Biostrings
  S4Vectors

  ### Utility Core ###

  dplyr
  stringr
  readr
  ggplot2
  ggsci
  paletteer
  scico
  flextable
  mclust
  parallel
  doParallel
  foreach
  R.utils
  "
  message(logo_viz)
  message("Building the devgru kit ...")
  message("Loadout currently includes:\n\t", loadout_string)
  librarian::shelf(loadout, update_all = update_kit, quiet = T)
  message("D O N E ...")
}

# }}}}------->>>
#
#  Tools for surveying the GenomicRanges
#
# }}}}------->>>

#' @name gr_refactor_seqs
#' @title Refactor seqinfo, seqnames, seqlengths, seqlevels of GRanges object for easy harmony
#'
#' @description
#' Single command to refactor all seq details of a GRanges object to easily harmonize with any other GRanges object.
#' By default, this package uses the autosome (1-22) and sex chromosomes (X,Y) of hg38, see `gUtils::hg_seqlengths()`
#' Users can adjust this using the `new_levels` parameter.
#'
#' @param input_gr GenomicRanges object to refactor
#' @param new_levels Named vector object used as the template for new seq details, see `gUtils::hg_seqlengths()` for example
#'
#' @return GenomicRanges object with updated seqinfo, seqnames, seqlengths, seqlevels
#' @export
gr_refactor_seqs <- function(input_gr, new_levels = gUtils::hg_seqlengths()) {

  # First, make sure we match input GR 'chr' notation with the desired seqs
  if(length(grep(x = names(new_levels), pattern = "^chr")) > 0) {

    gr <- gUtils::gr.chr(input_gr)
  } else {
    gr <- gUtils::gr.nochr(input_gr)
  }

  # Now start to reset seqnames
  gr <- GenomeInfoDb::dropSeqlevels(x = gr,
                                    value = GenomeInfoDb::seqlevels(gr)[!GenomeInfoDb::seqlevels(gr) %in% names(new_levels)[1:24]],
                                    pruning.mode = "coarse")

  # Now start to reset seqnames
  gr@seqnames@values <- factor(x = gr@seqnames@values,
                               levels =  names(new_levels)[1:24][GenomeInfoDb::seqlevels(gr) %in% names(new_levels)[1:24]])

  # Sort the new seqinfo
  gr@seqinfo <- GenomeInfoDb::sortSeqlevels(gr@seqinfo, X.is.sexchrom = T)

  # Now ensure seqinfo matches seqnames
  gr@seqinfo <- GenomeInfoDb::Seqinfo(seqnames = names(new_levels)[1:24],
                                      seqlengths = new_levels[1:24])

  # Final sort to ensure ranges are properly sorted by genomic coordinate
  gr <- GenomicRanges::sort.GenomicRanges(gr, ignore.strand = TRUE)
  return(gr)
}









#' @name get_qc_diagnostics_alignment
#' @title Generate diagnostic plots for alignment QC checks using Alfred summary files
#'
#' @description
#' Single command to generate a comprehensive set of diagnostic plots that assist in
#' performing QC checks of tumor/normal read alignment of various sequencing protocol flavors
#' using Alfred summary files.
#'
#' @param path_to_tumor_dir Path to directory of tumor sample Alfred summary files
#' @param path_to_normal_dir Path to directory of normal sample Alfred summary files
#' @param seq_protocol Type of sequencing protocol for display purposes, default: WGS
#'
#' @return Patchwork 'quilt'-like plot of ggplots
#' @export
get_qc_diagnostics_alignment <- function(path_to_tumor_dir = NULL, path_to_normal_dir = NULL, seq_protocol = "WGS") {

  # Set figure base theme
  ggplot2::theme_set(
    ggplot2::theme_gray() +
      ggplot2::theme(axis.line = ggplot2::element_line(linewidth = 0.5,  color = "black"),
                     panel.background = ggplot2::element_rect(fill = NA, linewidth = rel(14)),
                     panel.grid.minor = ggplot2::element_line(color = NA),
                     axis.text = ggplot2::element_text(size = 12,  color = "black"),
                     axis.title = ggplot2::element_text(size = 14),
                     axis.ticks = ggplot2::element_line(linewidth = 0.75),
                     title = ggplot2::element_text(size = 16)))

  # User provides paths to directory with T/N Alfred alignment QC summary files
  if(!is.null(path_to_tumor_dir) & !is.null(path_to_normal_dir)) {
    # Read in and aggregate the tumor/normal alfred QC summary files
    message("Aggregate input QC summary metrics ...")
    tumor_alfreds <- aggregate_these(path_to_files = path_to_tumor_dir,
                                     pattern_to_grab = "*.alfred.qc.summary.txt",
                                     delim = "\t",
                                     has_header = T,
                                     add_uniq_id = F)
    tumor_alfreds$tumor_normal <- "Tumor"
    message(paste0("Found ", dplyr::n_distinct(tumor_alfreds$Sample), " tumor samples ..."))

    normal_alfreds <- aggregate_these(path_to_files = path_to_normal_dir,
                                      pattern_to_grab = "*.alfred.qc.summary.txt",
                                      delim = "\t",
                                      has_header = T,
                                      add_uniq_id = F)
    normal_alfreds$tumor_normal <- "Normal"
    message(paste0("Found ", dplyr::n_distinct(normal_alfreds$Sample), " normal samples ..."))

  } else if(is.null(path_to_tumor_dir) & !is.null(path_to_normal_dir)) {
    stop(message = "Must provide path to directories of tumor and normal Alfred QC summary files ...")

  } else if(!is.null(path_to_tumor_dir) & is.null(path_to_normal_dir)) {
    stop(message = "Must provide path to directories of tumor and normal Alfred QC summary files ...")
  }

  # Sanity check if there is no match between normal/tumor samples
  message("Quick view of samples for sanity cross-check ...")
  paint::paint(df = data.frame("Tumor" = tumor_alfreds$Sample))
  paint::paint(df = data.frame("Normal" = normal_alfreds$Sample))

  # Combine the SNV+InDel QC metrics
  message("Merging tumor and normal alignment metrics ...")
  alfred_metrics <- gUtils::rrbind(tumor_alfreds, normal_alfreds)

  # boxplot of total mapped reads
  message("Generating diagnostic plots ...")
  fraction_fwd_rev_melt <- alfred_metrics %>%
                            dplyr::select(Sample, MappedForwardFraction, MappedReverseFraction, tumor_normal) %>%
                            reshape2::melt(id.vars = c("Sample", "tumor_normal"),
                                           value.name = "fraction",
                                           variable.name = "alignment_group")

  mapped_reads_plt <- ggplot2::ggplot(alfred_metrics) +
    ggplot2::geom_boxplot(ggplot2::aes(x = tumor_normal, y = Mapped, fill = tumor_normal), alpha = 0.6, width = 0.3) +
    ggplot2::scale_fill_manual(name = "Sample\nType", values = c("skyblue", "darkred")) +
    ggplot2::geom_jitter(ggplot2::aes(x = tumor_normal, y = Mapped, color = round(MappedProperFraction * 100, digits = 1)), alpha = 0.5, size = 3, width = 0.2) +
    ggplot2::scale_color_gradientn(name = "Percent\nMapped", colors = paletteer::paletteer_c("grDevices::Inferno", 10)) +
    ggplot2::scale_y_continuous(labels = scales::label_comma(scale = 1e-6),
                       limits = c(min(alfred_metrics$Mapped) - min(alfred_metrics$Mapped) * 0.10,
                                  max(alfred_metrics$Mapped) + max(alfred_metrics$Mapped) * 0.10),
                       expand = c(0.02,0.02)) +
    ggside::geom_xsidecol(data = fraction_fwd_rev_melt,
                          ggplot2::aes(x = tumor_normal, y = fraction, group = alignment_group),
                          position = "dodge", width = 0.5, just = 0.3,
                          fill = dplyr::case_when(fraction_fwd_rev_melt$alignment_group == "MappedForwardFraction" ~ "#009292",
                                           fraction_fwd_rev_melt$alignment_group == "MappedReverseFraction" ~ "#490092"), color = "black") +
    ggside::geom_xsidehline(yintercept = 0.45, color = "cyan") +
    ggside::scale_xsidey_continuous(labels = scales::label_percent()) +
    ggplot2::labs(x = NULL,
                  y = "Reads (millions)") +
    ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 0, vjust = 0.95, hjust = 0.5),
                   panel.border = ggplot2::element_rect(fill = NA),
                   ggside.panel.scale = .25) +
    ggplot2::annotate(geom = "text",
                      x = c(0.85, 1.15, 1.85, 2.15),
                      y = max(alfred_metrics$Mapped) + max(alfred_metrics$Mapped) * 0.10,
                      label = c("Fwd", "Rev", "Fwd", "Rev"),
                      color = c("#009292", "#490092","#009292", "#490092")) +
    ggplot2::annotate(geom = "text",
                      x = c(0.60, 2.40),
                      y = alfred_metrics %>%
                             dplyr::group_by(tumor_normal) %>%
                             dplyr::reframe(med_reads = stats::median(Mapped)) %>%
                             dplyr::select(med_reads) %>%
                             purrr::as_vector(),
                      label = round(alfred_metrics %>%
                                       dplyr::group_by(tumor_normal) %>%
                                       dplyr::reframe(med_reads = stats::median(Mapped)) %>%
                                       dplyr::select(med_reads) %>%
                                       purrr::as_vector() %>%
                                       as.numeric(),
                                    digits = -6) / 1e6)

  # boxplots of read fractions
  all_fractions <- data.table("group" = c("DuplicateFraction", "SecondaryAlignmentFraction", "SupplementaryAlignmentFraction", "UnmappedFraction"),
                              "Duplicate" = as.numeric(alfred_metrics$DuplicateFraction),
                              "Secondary" = as.numeric(alfred_metrics$SecondaryAlignmentFraction),
                              "Supplementary" = as.numeric(alfred_metrics$SupplementaryAlignmentFraction),
                              "Unmapped" = as.numeric(alfred_metrics$UnmappedFraction)) %>%
    reshape2::melt(id.vars = "group",
                   value.name = "fraction",
                   variable.name = "alignment_group")

  median_fractions_by_group <- all_fractions %>%
                                dplyr::group_by(alignment_group) %>%
                                dplyr::summarise(median_frac = stats::median(fraction))

  read_fracs_plt <- ggplot2::ggplot(data = all_fractions) +
    ggplot2::geom_boxplot(ggplot2::aes(x = alignment_group, y = fraction * 100, fill = alignment_group), alpha = 0.6, width = 0.4, outliers = F) +
    ggplot2::scale_fill_manual(name = "Alignment\nType", values = paletteer::paletteer_d("ggsci::hallmarks_light_cosmic")[1:5]) +
    ggplot2::geom_jitter(ggplot2::aes(x = alignment_group, y = fraction * 100, color = alignment_group), alpha = 0.4, size = 2.5, width = 0.3) +
    ggplot2::scale_color_manual(name = "Alignment\nType", values = paletteer::paletteer_d("ggsci::hallmarks_light_cosmic")[1:5]) +
    ggplot2::scale_y_continuous(expand = c(0.02,0.02)) +
    ggplot2::labs(x = NULL,
                  y = "Reads (%)") +
    ggplot2::theme(axis.text.x =  ggplot2::element_text(angle = 33, vjust = 0.60, hjust = 0.5, size = 9),
                    legend.position = "right",
                    panel.border =  ggplot2::element_rect(fill = NA))

  all_reads <- data.table("group" = c("DuplicateMarked", "SecondaryAlignments", "SupplementaryAlignments", "Unmapped"),
                          "Duplicate" = as.numeric(alfred_metrics$DuplicateMarked),
                          "Secondary" = as.numeric(alfred_metrics$SecondaryAlignments),
                          "Supplementary" = as.numeric(alfred_metrics$SupplementaryAlignments),
                          "Unmapped" = as.numeric(alfred_metrics$Unmapped)) %>%
    reshape2::melt(id.vars = "group",
                   value.name = "count",
                   variable.name = "alignment_group")

  median_fractions_by_group <- all_reads %>%
                                dplyr::group_by(alignment_group) %>%
                                dplyr::summarise(median_count = stats::median(as.numeric(count)))

  read_counts_plt <- ggplot2::ggplot(data = all_reads) +
    ggplot2::geom_col(data = median_fractions_by_group,
             ggplot2::aes(x = alignment_group, y = median_count, fill = alignment_group), alpha = 0.3, width = 0.4, color = "black") +
    ggplot2::scale_fill_manual(name = "Alignment\nType", values = paletteer::paletteer_d("ggsci::hallmarks_light_cosmic")[1:5]) +
    ggplot2::geom_jitter(ggplot2::aes(x = alignment_group, y = count, color = alignment_group), alpha = 0.4, size = 2.5, width = 0.3) +
    ggplot2::scale_color_manual(name = "Alignment\nType", values = paletteer::paletteer_d("ggsci::hallmarks_light_cosmic")[1:5]) +
    ggplot2::scale_y_reverse(labels = scales::label_comma(scale = 1e-6),expand = c(0.02,0.02)) +
    ggplot2::scale_x_discrete(position = "top") +
    ggplot2::labs(x = NULL,
                  y = "Reads (millions)") +
    ggplot2::theme(axis.text.x = ggplot2::element_blank(),
                   legend.position = "none",
                   panel.border = ggplot2::element_rect(fill = NA))

  # First combo plot of read metrics
  read_mets_plt <- patchwork::wrap_plots(list(read_fracs_plt, read_counts_plt), ncol = 1, guides = "collect")

  # Coverage
  coverage_dist_plt <- ggplot2::ggplot(alfred_metrics) +
    ggridges::stat_density_ridges(ggplot2::aes(x = MedianCoverage, y = tumor_normal, fill = 0.5 - abs(0.5 - ggplot2::after_stat(ecdf))),
                                  alpha = 0.5,
                                  calc_ecdf = TRUE,
                                  bandwidth = 3,
                                  geom = "density_ridges_gradient",
                                  scale = 2) +
    ggplot2::scale_fill_gradientn(name = "Tail prob.\nCoverage", colors = paletteer::paletteer_c("grDevices::Turku", n = 10)) +
    ggplot2::scale_x_continuous(expand = c(0.03,0.03), limits = c(min(alfred_metrics$MedianCoverage),max(alfred_metrics$MedianCoverage) + 5)) +
    ggside::geom_xsidepoint(ggplot2::aes(x = MedianCoverage, y = tumor_normal, color = tumor_normal),
                            position = "jitter", alpha = 0.5, show.legend = F, na.rm = T) +
    ggplot2::scale_color_manual(values = c("skyblue", "darkred")) +
    ggplot2::labs(x = "Coverage",
                  y = NULL) +
    ggplot2::theme(panel.border = ggplot2::element_rect(fill = NA))

  # Insert size distribution
  insert_dist_plt <- ggplot2::ggplot(alfred_metrics) +
    ggridges::stat_density_ridges(ggplot2::aes(x = MedianInsertSize, y = tumor_normal, fill = 0.5 - abs(0.5 - ggplot2::after_stat(ecdf))),
                                  alpha = 0.5,
                                  calc_ecdf = TRUE,
                                  bandwidth = 10,
                                  geom = "density_ridges_gradient",
                                  scale = 2) +
    ggplot2::scale_fill_gradientn(name = "Insert\nSize", colors = paletteer::paletteer_c("grDevices::Lajolla", n = 10)) +
    ggplot2::scale_x_continuous(expand = c(0.03,0.03), limits = c(min(alfred_metrics$MedianInsertSize),max(alfred_metrics$MedianInsertSize) + 5)) +
    ggside::geom_xsidepoint(ggplot2::aes(x = MedianInsertSize, y = tumor_normal, color = tumor_normal),
                            position = "jitter", alpha = 0.5, show.legend = F, na.rm = T) +
    ggplot2::scale_color_manual(values = c("skyblue", "darkred")) +
    ggplot2::labs(x = "Insert Size (bp)",
                  y = NULL) +
    ggplot2::theme(panel.border = ggplot2::element_rect(fill = NA),
                    axis.text.y = ggplot2::element_blank())

  # Second combo plot of coverage and insert size distribution
  cov_insrt_plt <- patchwork::wrap_plots(list(coverage_dist_plt, insert_dist_plt), ncol = 2, nrow = 1, guides = "collect")

  # Text table of summary metrics
  # TODO: add outlier sample flagging
  tumor_table_metrics <- alfred_metrics %>% dplyr::filter(tumor_normal == "Tumor")
  normal_table_metrics <- alfred_metrics %>% dplyr::filter(tumor_normal == "Normal")
  outtable <- data.table(placeholder = c("Tumor", "Normal"),
                         "Coverage" = c(stringr::str_c(round(mean(tumor_table_metrics$MedianCoverage), digits = 1), " (", range(tumor_table_metrics$MedianCoverage)[1], "-", range(tumor_table_metrics$MedianCoverage)[2], ")"),
                                        stringr::str_c(round(mean(normal_table_metrics$MedianCoverage), digits = 1), " (", range(normal_table_metrics$MedianCoverage)[1], "-", range(normal_table_metrics$MedianCoverage)[2], ")")),
                         "Insert Size" = c(stringr::str_c(round(mean(tumor_table_metrics$MedianInsertSize), digits = 1), " (", range(tumor_table_metrics$MedianInsertSize)[1], "-", range(tumor_table_metrics$MedianInsertSize)[2], ")"),
                                           stringr::str_c(round(mean(normal_table_metrics$MedianInsertSize), digits = 1), " (", range(normal_table_metrics$MedianInsertSize)[1], "-", range(normal_table_metrics$MedianInsertSize)[2], ")")),
                         "Read Length" = c(stringr::str_split(string = unique(tumor_table_metrics$MedianReadLength), pattern = ":",simplify = T)[,1],
                                           stringr::str_split(string = unique(normal_table_metrics$MedianReadLength), pattern = ":",simplify = T)[,1]))
  colnames(outtable)[1] <- paste0(seq_protocol, " mean(range)")
  metrics_summary_table <- ggpubr::ggtexttable(t(outtable), theme = ggpubr::ttheme("light"))

  # Histograms of target bed mapped fraction, insertion and deletion detection rate
  target_frac_plt <- ggplot2::ggplot(alfred_metrics) +
    ggplot2::geom_histogram(ggplot2::aes(x = FractionCovered, group = tumor_normal, fill = tumor_normal),
                            position = "dodge", binwidth = 0.05,  color = "black", alpha = 0.6) +
    ggplot2::scale_x_continuous(limits = c(0,1), expand = c(0.02,0.02), breaks = scales::breaks_width(width = 0.1)) +
    ggplot2::scale_y_continuous(expand = c(0.02,0.02)) +
    ggplot2::scale_fill_manual(values = c("skyblue", "darkred")) +
    ggplot2::labs(x = "Fraction of target covered",
                  y = "Count of samples per bin") +
    ggplot2::theme(panel.border = ggplot2::element_rect(fill = NA),
                   legend.position = "none")

  ins_rate_plt <- ggplot2::ggplot(alfred_metrics) +
    ggplot2::geom_histogram(ggplot2::aes(x = InsertionRate, group = tumor_normal, fill = tumor_normal),
                   position = "stack", binwidth = 0.000005, color = "black", alpha = 0.6) +
    ggplot2::scale_y_continuous(expand = c(0.02,0.02)) +
    ggplot2::scale_fill_manual(values = c("skyblue", "darkred")) +
    ggplot2::labs(x = "Insertion rate",
                  y = "Count of samples per bin") +
    ggplot2::theme(panel.border = ggplot2::element_rect(fill = NA),
                   legend.position = "none")

  del_rate_plt <- ggplot2::ggplot(alfred_metrics) +
    ggplot2::geom_histogram(ggplot2::aes(x = DeletionRate, group = tumor_normal, fill = tumor_normal),
                            position = "stack", binwidth = 0.000005, color = "black", alpha = 0.6) +
    ggplot2::scale_y_continuous(expand = c(0.02,0.02)) +
    ggplot2::scale_fill_manual(values = c("skyblue", "darkred")) +
    ggplot2::labs(x = "Deletion rate",
                  y = "Count of samples per bin") +
    ggplot2::theme(panel.border = ggplot2::element_rect(fill = NA),
                   legend.position = "none")

  # Third combo plot of histograms
  hist_combo_plot <- target_frac_plt / ins_rate_plt / del_rate_plt + patchwork::plot_layout(axes = "collect_y")

  # Final quilt plot of all QC plots
  read_combo_plt <- (patchwork::plot_spacer() + metrics_summary_table + patchwork::plot_spacer()) / (mapped_reads_plt + hist_combo_plot + read_mets_plt) / cov_insrt_plt + patchwork::plot_layout(ncol = 1, nrow = 3, heights = c(0.66, 1, 1))
  return(read_combo_plt)
}


#' @name get_qc_diagnostics_snvindel
#' @title Generate diagnostic plots for SNV & InDel variant calling QC checks
#'
#' @description
#' Single command to generate a comprehensive set of diagnostic plots that assist in
#' performing QC checks of SNVs & InDels called from MGP1000 using union consensus.
#' Can be used as both a first pass of unfiltered variants to see consensus skew as
#' well as used after filtering to show changes in calling metrics.
#'
#' @param path_to_snv_dir Path to directory of MGP1000 union consensus SNVs
#' @param path_to_indel_dir Path to directory of MGP1000 union consensus InDels
#' @param snv_indel_obj Data.table object with merged SNVs & InDels, used in place of paths to directories
#' @param plot_sample_names Output plots to include sample names on y-axis, default: TRUE
#' @param include_caveman Add caveman to consensus list if used in SNV variant calling, default: FALSE
#'
#' @return Patchwork 'quilt'-like plot of ggplots
#' @export
get_qc_diagnostics_snvindel <- function(path_to_snv_dir = NULL, path_to_indel_dir = NULL, snv_indel_obj = NULL, plot_sample_names = T, include_caveman = F) {

  # Set figure base theme
  ggplot2::theme_set(
    ggplot2::theme_gray() +
      ggplot2::theme(axis.line = ggplot2::element_line(linewidth = 0.5,  color = "black"),
                     panel.background = ggplot2::element_rect(fill = NA, linewidth = rel(14)),
                     panel.grid.minor = ggplot2::element_line(color = NA),
                     axis.text = ggplot2::element_text(size = 12,  color = "black"),
                     axis.title = ggplot2::element_text(size = 14),
                     axis.ticks = ggplot2::element_line(linewidth = 0.75),
                     title = ggplot2::element_text(size = 16)))

  # User provides either paths to directory with SNVs and InDel or a single DT obj with both SNV+InDels
  if(!is.null(path_to_snv_dir) & !is.null(path_to_indel_dir) & is.null(snv_indel_obj)) {
    # Aggregate all SNV and InDel union-consensus files
    message("Aggregate input mutations ...")
    snvs <- aggregate_these(path_to_files = path_to_snv_dir,
                            pattern_to_grab = "*.hq.union.consensus.somatic.snv.txt.gz",
                            delim = "\t",
                            has_header = T,
                            cpus = 1,
                            add_uniq_id = F)

    indels <- aggregate_these(path_to_files = path_to_indel_dir,
                              pattern_to_grab = "*.hq.union.consensus.somatic.indel.txt.gz",
                              delim = "\t",
                              has_header = T,
                              cpus = 1,
                              add_uniq_id = F)

    # If user already aggregated, split DT obj into SNVs and InDels
  } else if(is.null(path_to_snv_dir) & is.null(path_to_indel_dir) & !is.null(snv_indel_obj)) {
    # Aggregate all SNV and InDel union-consensus files
    message("Read in aggregated mutations ...")
    snvs <- snv_indel_obj %>% dplyr::filter(stringr::str_length(REF) == 1 & stringr::str_length(ALT) == 1)
    indels <- dplyr::setdiff(x = snv_indel_obj, y = snvs)

  } else {
    stop(message = "Must provide either path to directories of SNVs and InDels or SNV+InDel aggregated data.table ...")
  }

  # Get count of all SNVs and InDels per sample by caller
  message("Counting mutations per sample by caller ...")
  snvs_by_caller <- snvs %>%
    dplyr::group_by(SAMPLE) %>%
    dplyr::count(CALLER) %>%
    dplyr::ungroup() %>%
    dplyr::mutate(total_snvs = sum(n)) %>%
    dplyr::arrange(dplyr::desc(total_snvs))

  indels_by_caller <- indels %>%
    dplyr::group_by(SAMPLE) %>%
    dplyr::count(CALLER) %>%
    dplyr::ungroup() %>%
    dplyr::mutate(total_indels = sum(n)) %>%
    dplyr::arrange(dplyr::desc(total_indels))

  # Factor the caller list for consistent plotting
  if(include_caveman) {
    snv_caller_levels <- c("caveman","mutect","strelka","varscan",
                           "caveman,mutect","caveman,strelka","caveman,varscan",
                           "mutect,strelka","mutect,varscan","strelka,varscan",
                           "caveman,mutect,strelka","caveman,mutect,varscan",
                           "caveman,strelka,varscan","mutect,strelka,varscan",
                           "caveman,mutect,strelka,varscan")
  } else if(!include_caveman) {
    snv_caller_levels <- c("mutect","strelka","varscan",
                           "mutect,strelka", "mutect,varscan","strelka,varscan",
                           "mutect,strelka,varscan")
  }

  snvs_by_caller$CALLER <- factor(snvs_by_caller$CALLER,
                                  levels = snv_caller_levels)

  indels_by_caller$CALLER <- factor(indels_by_caller$CALLER,
                                    levels = c("mutect","strelka","svaba","varscan",
                                               "mutect,strelka","mutect,svaba","mutect,varscan",
                                               "strelka,svaba","strelka,varscan","svaba,varscan",
                                               "mutect,strelka,svaba","mutect,strelka,varscan","mutect,svaba,varscan",
                                               "strelka,svaba,varscan","mutect,strelka,svaba,varscan"))

  # Build SNVs per sample by caller plot
  message("Generating diagnostic plots ...")
  snvs_per_sample_by_caller <- ggplot2::ggplot(snvs_by_caller) +
    ggplot2::geom_col(ggplot2::aes(x = SAMPLE, y = n, fill = CALLER), position = "stack") +
    ggplot2::scale_fill_manual(name = "Callers", values = paletteer::paletteer_d("ggsci::default_jama")) +
    ggplot2::scale_y_reverse(expand = c(0.01,0.01), labels = scales::label_comma()) +
    ggplot2::scale_x_discrete(position = "top") +
    ggplot2::coord_flip() +
    ggplot2::labs(title = "SNVs",
         x = NULL,
         y = "Count") +
    ggplot2::theme(legend.position = "left",
                    plot.title = ggplot2::element_text(hjust = 0.5),
                    panel.border = ggplot2::element_rect(fill = NA),
                    legend.key.size = ggplot2::unit("1.5", "mm"),
                    legend.title = ggplot2::element_text(size = 11))
  # Sample names or not on Y axis
  if(plot_sample_names) {
    snvs_per_sample_by_caller <- snvs_per_sample_by_caller + ggplot2::theme(axis.text.y = element_text(size = 8))

  } else if(!plot_sample_names) {
    snvs_per_sample_by_caller <- snvs_per_sample_by_caller + ggplot2::theme(axis.text.y = element_blank())
  }

  # Build counts of total by caller
  caller_by_snvs <- ggplot2::ggplot(data = snvs_by_caller %>%
                                             dplyr::group_by(CALLER) %>%
                                             dplyr::summarise(total_per_caller = round((sum(n) / sum(snvs_by_caller$n)) * 100, digits = 1)),
                                    ggplot2::aes(x = CALLER, y = total_per_caller, fill = CALLER, label = total_per_caller)) +
                    ggplot2::geom_col() +
                    ggfittext::geom_bar_text(min.size = 1) +
                    ggplot2::scale_fill_manual(name = "Callers", values = paletteer::paletteer_d("ggsci::default_jama")) +
                    ggplot2::scale_y_reverse(expand = c(0.02,0.02), labels = scales::label_percent(scale = 1), position = "right") +
                    ggplot2::scale_x_discrete(position = "top") +
                    ggplot2::labs(x = "Percentage of\ncalled mutations",
                                  y = NULL) +
                    ggplot2::theme(axis.text.x = ggplot2::element_blank(),
                                    axis.ticks.x.top = ggplot2::element_blank(),
                                    legend.position = "none",
                                    panel.border = ggplot2::element_rect(fill = NA))

  # Build InDels per sample by caller plot
  indels_per_sample_by_caller <- ggplot2::ggplot(indels_by_caller) +
    ggplot2::geom_col(ggplot2::aes(x = SAMPLE, y = n, fill = CALLER), position = "stack") +
    ggplot2::scale_fill_manual(name = "Callers", values = paletteer_d("colorBlindness::paletteMartin")) +
    ggplot2::scale_y_continuous(expand = c(0.01,0.01), labels = scales::label_comma(), position = "left") +
    ggplot2::scale_x_discrete(position = "bottom") +
    ggplot2::coord_flip() +
    ggplot2::labs(title = "InDels",
                   x = NULL,
                   y = "Count") +
    ggplot2::theme(legend.position = "right",
                    plot.title = ggplot2::element_text(hjust = 0.5),
                    axis.text.y = ggplot2::element_blank(),
                    panel.border = ggplot2::element_rect(fill = NA),
                    legend.key.size = ggplot2::unit("1.5", "mm"),
                    legend.title = ggplot2::element_text(size = 11))

  # Build counts of total by caller
  caller_by_indels <- ggplot2::ggplot(data = indels_by_caller %>%
                                               dplyr::group_by(CALLER) %>%
                                               dplyr::summarise(total_per_caller = round((sum(n) / sum(indels_by_caller$n)) * 100, digits = 1)),
                                      ggplot2::aes(x = CALLER, y = total_per_caller, fill = CALLER, label = total_per_caller)) +
                        ggplot2::geom_col() +
                        ggfittext::geom_bar_text(min.size = 1) +
                        ggplot2::scale_fill_manual(name = "Callers", values = paletteer::paletteer_d("colorBlindness::paletteMartin")) +
                        ggplot2::scale_y_reverse(expand = c(0.02,0.02), labels = scales::label_percent(scale = 1), position = "left") +
                        ggplot2::scale_x_discrete(position = "top") +
                        ggplot2::labs(x = "Percentage of\ncalled mutations",
                                      y = NULL) +
                        ggplot2::theme(axis.text.x = ggplot2::element_blank(),
                                        axis.ticks.x.top = ggplot2::element_blank(),
                                        legend.position = "none",
                                        panel.border = ggplot2::element_rect(fill = NA))

  # Final combo QC diagnostic plot
  snvindel_qc_diagnostic_plot <- (snvs_per_sample_by_caller / caller_by_snvs) | (indels_per_sample_by_caller / caller_by_indels)
  return(snvindel_qc_diagnostic_plot)
}






#' @name get_vaf
#' @title Quick pull or explicitly calculate the VAF for mutation records of various flavors
#'
#' @description
#' Given a data.table or GRanges VCF object, quickly extract or explicitly calculate the VAF for all mutations.
#' For clarity, the read support for the VAF will be extracted as well.
#' Currently supports somatic SNV/InDel VCFs from Mutect, Strelka, Varscan, SvABA, CaVEMan.
#'
#' @param vcf_obj VCF file in data.table or GRanges format
#' @param caller Name of the caller that generated input VCF to be converted, supported: mutect, strelka, varscan, svaba, caveman
#' @param mut_type Type of mutations within VCF, supported: snv, indel
#'
#' @return data.table object with read support and VAF per record
#' @export
get_vaf <- function(vcf_obj, caller, mut_type) {

  # First, check the VCF object. If data.table, continue on. If not, convert
  if(!"data.table" %in% class(vcf_obj) & "GRanges" %in% class(vcf_obj)) {
    mut_records <- gUtils::gr2dt(vcf_obj)

  } else if("data.table" %in% class(vcf_obj)) {
    mut_records <- vcf_obj

  } else {
    # Problem if input VCF object is not correct class
    stop(message = "\nInput VCF object needs to be either data.table or GRanges class")
  }

  if(caller == "mutect") {
    # Mutect SNVs and InDels
    # VAF is reported as AF ["Allele fractions of alternate alleles in the tumor"]
    # ALT depth is reported as AD ["Allelic depths for the ref and alt alleles in the order listed"]
    # Total depth is reported as DP ["Approximate read depth (reads with MQ=255 or with bad mates are filtered)"]
    mut_alt_depth <- mut_records[, AD_ALT_TUMOR]
    mut_total_depth <- mut_records[, DP_TUMOR]
    mut_vaf <- round(mut_records[, AF_TUMOR], digits = 4)

  } else if(caller == "varscan") {
    # VarScan SNVs and InDels
    # VAF is reported as FREQ ["Variant allele frequency"]
    # ALT depth is reported as AD ["Depth of variant-supporting bases (reads2)"]
    # Total depth is reported as DP ["Read Depth"]
    mut_alt_depth <- mut_records[, AD_TUMOR]
    mut_total_depth <- mut_records[, DP_TUMOR]
    mut_vaf <- round(as.numeric(stringr::str_remove(string = mut_records[, FREQ_TUMOR], pattern = "%")) / 100, digits = 4)

  } else if(caller == "strelka" & mut_type == "snv") {
    # Strelka SNVs
    # Does not directly report VAF
    # ALT depth is reported as read support per nucleotide tier AU, CU, TU, GU ["Number of 'A/C/G/T' alleles used in tiers 1,2"]
    # Total depth is reported as depth DP ["Read depth for tier1 (used+filtered)"]
    # The VAF will be calculated as: [AU_TIER1, CU_TIER1, TU_TIER1, GU_TIER1] / DP

    # To get the correct ALT depth, need to loop through the records to build
    mut_alt_depth <- rep(NA, nrow(mut_records))
    mut_total_depth <- mut_records[, DP_TUMOR]
    mut_vaf <- rep(NA, nrow(mut_records))

    for(i in 1:nrow(mut_records)) {
      # Get the ALT depth
      mut_alt_depth[i] <- as.data.frame(mut_records[i,])[,colnames(mut_records[i,]) == paste0(mut_records$ALT[i], "U_TIER1_TUMOR")]

      # Calculate the VAF
      mut_vaf[i] <- round(mut_alt_depth[i] / mut_total_depth[i], digits = 4)
    }

  } else if(caller == "strelka" & mut_type == "indel") {
    # Strelka InDels
    # Does not directly report VAF
    # ALT depth is reported as indel tier read support TIR ["Reads strongly supporting indel allele for tiers 1,2"]
    # Total depth is reported as depth DP ["Read depth for tier1 (used+filtered)"]
    # The VAF will be calculated as: TIR_TIER1 / DP
    mut_alt_depth <- mut_records[, TIR_TIER1_TUMOR]
    mut_total_depth <- mut_records[, DP_TUMOR]
    mut_vaf <- round(mut_alt_depth / mut_total_depth, digits = 4)

  } else if(caller == "svaba" & mut_type == "indel") {
    # SvABA InDels
    # Does not directly report VAF
    # ALT depth is reported as allele depth AD ["Allele depth: Number of reads supporting the variant"]
    # Total depth is reported as depth DP ["Depth of coverage: Number of reads covering site."]
    # The VAF will be calculated as: AD / DP
    mut_alt_depth <- mut_records[, AD_TUMOR]
    mut_total_depth <- mut_records[, DP_TUMOR]
    mut_vaf <- round(mut_alt_depth / mut_total_depth, digits = 4)

  } else if(caller == "caveman" & mut_type == "snv") {
    # CaVEMan SNVs
    # VAF is reported as proportion of mut allele PM ["Proportion of mutant allele presenting reads (ALT field) seen by CaVEMan"]
    # ALT depth is reported as read support per nucleotide per strand FAZ, FCZ, FGZ, FTZ, RAZ, RCZ, RGZ, RTZ
    # Total depth is not directly reported

    # To get the correct ALT and total depth, need to loop through the records to build
    mut_alt_depth <- rep(NA, nrow(mut_records))
    mut_total_depth <- rep(NA, nrow(mut_records))
    mut_vaf <- mut_records[, PM_TUMOR]

    for(i in 1:nrow(mut_records)) {
      # Get all nucleotide read depth on both strands
      fwd_alt_depth <- as.data.frame(mut_records[i,])[,colnames(mut_records[i,]) == paste0("F", mut_records$ALT[i], "Z_TUMOR")]
      rev_alt_depth <- as.data.frame(mut_records[i,])[,colnames(mut_records[i,]) == paste0("R", mut_records$ALT[i], "Z_TUMOR")]
      fwd_ref_depth <- as.data.frame(mut_records[i,])[,colnames(mut_records[i,]) == paste0("F", mut_records$REF[i], "Z_TUMOR")]
      rev_ref_depth <- as.data.frame(mut_records[i,])[,colnames(mut_records[i,]) == paste0("R", mut_records$REF[i], "Z_TUMOR")]

      # Calculate the ALT and total read depth
      mut_alt_depth[i] <- sum(fwd_alt_depth, rev_alt_depth)
      mut_total_depth[i] <- sum(fwd_alt_depth, rev_alt_depth, fwd_ref_depth, rev_ref_depth)
    }

  } else {
    # Problem if there is no proper combo of caller and mut_type
    stop(message = "\ncaller and mut_type provided do not match possible combos. See function description")
  }

  # Create final DT of read depth and VAF for each mutation record
  mut_vaf_and_reads <- data.table(alt_depth = mut_alt_depth,
                                  total_depth = mut_total_depth,
                                  vaf = mut_vaf)

  # Output the VAF for the mutation record
  return(mut_vaf_and_reads)
}


#' @name get_maf_lite
#' @title Convert SNV & InDel mutation table to MAF-lite format
#'
#' @description
#' Read in multiple MGP1000 union consensus SNV & InDel mutation tables, filter based on consensus threshold
#' or sample/gene, merge all tables, calculate VAF, and prepare for downstream use in maf2maf or maf2vcf.
#' The bare minimum for a MAF is Chromosome, Start_Position, Reference_Allele, Tumor_Seq_Allele2, Tumor_Sample_Barcode
#' but will also include Matched_Norm_Sample_Barcode.
#'
#' @param path_to_snv_dir Path to directory of MGP1000 union consensus SNVs
#' @param path_to_indel_dir Path to directory of MGP1000 union consensus InDels
#' @param snv_consensus_filter Threshold consensus filter for SNVs
#' @param indel_consensus_filter Threshold consensus filter for InDels
#' @param strict_samples Samples that will be filtered with `*_consensus_filter``+1`
#' @param discovery_genes Gene set vector used for discovery with `*_consensus_filter``=0`
#' @param return_type Output either the converted maf-lite format table or data.table of standard format mutation table, default: maflite
#'
#' @return data.table like in either maf-lite or standard format
#' @export
get_maf_lite <- function(path_to_snv_dir, path_to_indel_dir, snv_consensus_filter = 2, indel_consensus_filter = 2,
                         strict_samples = NULL, discovery_genes = NULL, return_type = "maflite") {

  # Aggregate all SNV and InDel union-consensus files
  # Perform sanity checks on patients and samples
  message("Aggregate input mutations ...")
  snvs <- aggregate_these(path_to_files = path_to_snv_dir,
                          pattern_to_grab = "*.hq.union.consensus.somatic.snv.txt.gz",
                          delim = "\t",
                          has_header = T,
                          cpus = 1,
                          add_uniq_id = F)
  message(paste0("Found ", dplyr::n_distinct(snvs$SAMPLE), " samples from ", dplyr::n_distinct(snvs$PATIENT), " patients with SNVs ..."))

  indels <- aggregate_these(path_to_files = path_to_indel_dir,
                            pattern_to_grab = "*.hq.union.consensus.somatic.indel.txt.gz",
                            delim = "\t",
                            has_header = T,
                            cpus = 1,
                            add_uniq_id = F)
  message(paste0("Found ", dplyr::n_distinct(indels$SAMPLE), " samples from ", dplyr::n_distinct(indels$PATIENT), " patients with InDels ..."))

  # Sanity check if there is no overlap in samples/patients or if there is a missing sample/patient
  if(length(dplyr::setdiff(x = indels$SAMPLE, y = snvs$SAMPLE)) == 0) {
    message("No difference in set of samples between SNVs and InDels ...")

  } else if(length(dplyr::setdiff(x = indels$SAMPLE, y = snvs$SAMPLE)) > 0) {
    message(paste0("Warning: Detected ", length(dplyr::setdiff(x = indels$SAMPLE, y = snvs$SAMPLE)), " samples in InDel sample set NOT in SNV sample set ..."))
    setdiff_samples <- indels$SAMPLE[which(!indels$SAMPLE %in% unique(snvs$SAMPLE))]
    paint::paint(df = data.frame("Missing_Samples" = setdiff_samples))
    message("Recommend inspection ...")
  }

  # Now filter the data based on desired conditions
  message("Beginning filtering for high-quality variants ...")
  hq_snvs <- NULL
  hq_indels <- NULL

  # Standard consensus filtering, no special cases
  if(is.null(strict_samples) & is.null(discovery_genes)) {
    message(paste0("Maintaining SNVs with consensus >= ", snv_consensus_filter,  " ..."))
    message(paste0("Maintaining InDels with consensus >= ", indel_consensus_filter,  " ..."))

    hq_snvs <- snvs %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= snv_consensus_filter - 1)
    hq_indels <- indels %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= indel_consensus_filter - 1)

    # Standard consensus filtering, plus special case to keep all muts for genes of interest
  } else if(is.null(strict_samples) & !is.null(discovery_genes)) {
    message(paste0("Maintaining SNVs with consensus >= ", snv_consensus_filter,  " ..."))
    message(paste0("Maintaining InDels with consensus >= ", indel_consensus_filter,  " ..."))
    message(paste0("Special case filter to maintain all calls for genes of interest ..."))
    paint::paint(df = data.frame("Discovery_Genes" = discovery_genes))

    consensus_non_discovery_snvs <- snvs %>%
      dplyr::filter(!nearest_gene %in% discovery_genes) %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= snv_consensus_filter - 1)
    discovery_gene_snvs <- snvs %>%
      dplyr::filter(nearest_gene %in% discovery_genes)
    hq_snvs <- gUtils::rrbind(consensus_non_discovery_snvs, discovery_gene_snvs)

    consensus_non_discovery_indels <- indels %>%
      dplyr::filter(!nearest_gene %in% discovery_genes) %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= indel_consensus_filter - 1)
    discovery_gene_indels <- indels %>%
      dplyr::filter(nearest_gene %in% discovery_genes)
    hq_indels <- gUtils::rrbind(consensus_non_discovery_indels, discovery_gene_indels)

    # Standard consensus filtering, plus special case to strictly filter specific samples
  } else if(!is.null(strict_samples) & is.null(discovery_genes)) {
    message(paste0("Maintaining SNVs with consensus >= ", snv_consensus_filter,  " ..."))
    message(paste0("Maintaining InDels with consensus >= ", indel_consensus_filter,  " ..."))
    message(paste0("Special case filter to strictly filter specific samples with +1 to consensus filters ..."))
    paint::paint(df = data.frame("Strict_Samples" = strict_samples))

    consensus_non_strict_snvs <- snvs %>%
      dplyr::filter(!SAMPLE %in% strict_samples) %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= snv_consensus_filter - 1)
    strict_sample_snvs <- snvs %>%
      dplyr::filter(SAMPLE %in% strict_samples) %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= snv_consensus_filter)
    hq_snvs <- gUtils::rrbind(consensus_non_strict_snvs, strict_sample_snvs)

    consensus_non_strict_indels <- indels %>%
      dplyr::filter(!SAMPLE %in% strict_samples) %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= indel_consensus_filter - 1)
    strict_sample_indels <- indels %>%
      dplyr::filter(SAMPLE %in% strict_samples) %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= indel_consensus_filter)
    hq_indels <- gUtils::rrbind(consensus_non_strict_indels, strict_sample_indels)

    # Standard consensus filtering, plus special case to keep all muts for genes of interest and to strictly filter specific samples
  } else if(!is.null(strict_samples) & !is.null(discovery_genes)) {
    message(paste0("Maintaining SNVs with consensus >= ", snv_consensus_filter,  " ..."))
    message(paste0("Maintaining InDels with consensus >= ", indel_consensus_filter,  " ..."))
    message(paste0("Special case filter to maintain all calls for genes of interest ..."))
    paint::paint(df = data.frame("Discovery_Genes" = discovery_genes))
    message(paste0("Special case filter to strictly filter specific samples with +1 to consensus filters ..."))
    paint::paint(df = data.frame("Strict_Samples" = strict_samples))

    consensus_non_discovery_strict_snvs <- snvs %>%
      dplyr::filter(!SAMPLE %in% strict_samples) %>%
      dplyr::filter(!nearest_gene %in% discovery_genes) %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= snv_consensus_filter - 1)
    discovery_gene_snvs <- snvs %>%
      dplyr::filter(!SAMPLE %in% strict_samples) %>%
      dplyr::filter(nearest_gene %in% discovery_genes)
    strict_sample_snvs <- snvs %>%
      dplyr::filter(SAMPLE %in% strict_samples) %>%
      dplyr::filter(!nearest_gene %in% discovery_genes) %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= snv_consensus_filter)
    hq_snvs <- gUtils::rrbind(consensus_non_discovery_strict_snvs, discovery_gene_snvs, strict_sample_snvs)

    consensus_non_discovery_strict_indels <- indels %>%
      dplyr::filter(!SAMPLE %in% strict_samples) %>%
      dplyr::filter(!nearest_gene %in% discovery_genes) %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= indel_consensus_filter - 1)
    discovery_gene_indels <- indels %>%
      dplyr::filter(!SAMPLE %in% strict_samples) %>%
      dplyr::filter(nearest_gene %in% discovery_genes)
    strict_sample_indels <- indels %>%
      dplyr::filter(SAMPLE %in% strict_samples) %>%
      dplyr::filter(!nearest_gene %in% discovery_genes) %>%
      dplyr::filter(stringr::str_count(string = CALLER, pattern = ",") >= indel_consensus_filter)
    hq_indels <- gUtils::rrbind(consensus_non_discovery_strict_indels, discovery_gene_indels, strict_sample_indels)
  }

  # Combine HQ SNVs and InDels
  message("Filter complete, merging to single SNV+InDel DT ...")
  hq_muts <- gUtils::rrbind(hq_snvs, hq_indels)

  # Calculate the read depth information for the MAF-like file
  message("Calculate VAF for normal samples ...")

  normal_read_colnames <- which(c("MUTECT_DP_NORMAL", "STRELKA_DP_NORMAL", "VARSCAN_DP_NORMAL", "SVABA_DP_NORMAL") %in% colnames(hq_muts))
  normal_read_metrics <- hq_muts %>%
    dplyr::select(c("MUTECT_DP_NORMAL", "STRELKA_DP_NORMAL", "VARSCAN_DP_NORMAL", "SVABA_DP_NORMAL")[normal_read_colnames])
  dp_mean <- round(rowMeans(x = normal_read_metrics, na.rm = T), digits = 0)

  alt_read_colnames <- which(c("MUTECT_AD_ALT_NORMAL","STRELKA_alt_depth", "VARSCAN_AD_NORMAL", "SVABA_AD_NORMAL") %in% colnames(hq_muts))
  alt_read_metrics <- hq_muts %>%
    dplyr::select(c("MUTECT_AD_ALT_NORMAL","STRELKA_alt_depth", "VARSCAN_AD_NORMAL", "SVABA_AD_NORMAL")[alt_read_colnames])
  alt_mean <- round(rowMeans(x = alt_read_metrics, na.rm = T), digits = 0)

  ref_mean <- dp_mean - alt_mean

  # Now build the MAF-like DT for conversion with maftools
  hq_muts_maf_lite_dt <- data.table::data.table("Chromosome" = hq_muts$seqnames,
                                                "Start_Position" = hq_muts$start,
                                                "Reference_Allele" = hq_muts$REF,
                                                "Tumor_Seq_Allele2" = hq_muts$ALT,
                                                "Tumor_Sample_Barcode" = hq_muts$TUMOR,
                                                "Matched_Norm_Sample_Barcode" = hq_muts$NORMAL,
                                                "Tumor_Total_Read_Depth" = hq_muts$total_depth_mean,
                                                "Tumor_Variant_Allele_Depth" = hq_muts$alt_read_depth_mean,
                                                "Tumor_Reference_Allele_Depth" = hq_muts$total_depth_mean - hq_muts$alt_read_depth_mean,
                                                "Normal_Total_Read_Depth" = dp_mean,
                                                "Normal_Variant_Read_Depth" = alt_mean,
                                                "Normal_Reference_Allele_Depth" = ref_mean)
  # Final output
  if(return_type == "maf.lite") {
    message("MAF-lite generated ...")
    paint::paint(hq_muts_maf_lite_dt)
    return(hq_muts_maf_lite_dt)

    # return the non-transformed post-filtered mutation table for QC
  } else if(return_type == "data.table") {
    message("Mutation table generated ...")
    paint::paint(hq_muts)
    return(hq_muts)
  }
}


#' @name get_allele_counts
#' @title Read in a BAM file, collect read counts for alleles at set of mutation loci using alleleCounter, and convert to data.table object
#'
#' @description
#' Wrapper command to use alleleCounter to read in a BAM file and count all reads supporting each possible allele at set of mutation loci, then convert it to a data.table object with refactored seq details.
#' The process will be split across each chromosome and then merged for the final output.
#' Expects the first column to be chromosome name, and 3 other columns to exist in the mutation loci file: pos/start/end, ref/REF/Reference_Allele, alt/ALT/Tumor_Seq_Allele2.
#'
#' @param bam_file_path Path to BAM file
#' @param mut_loci_obj Mutation loci file in data.table or GRanges format, required columns: chrom, pos, ref, alt
#' @param min_base_qual Minimum base quality required for a read to be counted, default: 20
#' @param min_map_qual Minimum mapping quality required for a read to be counted, default: 35
#' @param threads Number of threads to use for parallel execution, default: 1
#'
#' @return data.table object with the columns: #CHR, POS, Count_A, Count_C, Count_G, Count_T, Good_depth
#' @export
get_allele_counts = function(bam_file_path, mut_loci_obj, min_base_qual = 20, min_map_qual = 35, threads = 1) {

  # Set parallel cores parameter
  message("Setting parallel cores to ", threads, " ...")
  doParallel::registerDoParallel(cores = threads)

  # First, check if BAM and index exist at the path given
  if(!file.exists(bam_file_path)) {
    stop(message = "\nInput BAM does not exist at the path given")
  }

  if(!file.exists(paste0(bam_file_path, ".bai")) & !file.exists(stringr::str_replace(string = bam_file_path, pattern = "\\.bam", replacement ="\\.bai"))) {
    stop(message = "\nInput BAM .bai index does not at the path given")
  }

  # Second, check the mutation loci object. If data.table, continue on. If not, convert
  if(!"data.table" %in% class(mut_loci_obj) & "GRanges" %in% class(mut_loci_obj)) {
    mut_loci <- gUtils::gr2dt(mut_loci_obj)

  } else if("data.table" %in% class(mut_loci_obj)) {
    mut_loci <- mut_loci_obj

  } else {
    # Problem if input VCF object is not correct class
    stop(message = "\nInput mutation loci object needs to be either data.table or GRanges class")
  }

  # Finally, check if alleleCounter is on the path
  if(class(system("alleleCounter -v", intern = TRUE)) != "character") {
    stop(message = "\nCannot find alleleCounter binary executable on path")
  }

  # Begin foreach construct to parallelize the alleleCounter command per chromosome and then stitch the results together in a GRanges object
  chrom_iter_list <- as.character(unique(mut_loci$seqnames))
  possible_col_names <- c("seqnames", "chrom", "start", "pos", "POS", "ref", "REF", "Reference_Allele", "alt", "ALT", "Tumor_Seq_Allele2")

  final_allele_counts <- foreach::foreach(x = 1:length(chrom_iter_list), .combine = rrbind, .packages = "gUtils") %dopar% {

    # Grab the mutation loci per chromosome and prep for use in alleleCounter
    which_col_names <- which(possible_col_names %in% colnames(mut_loci))
    mut_loci_per_chrom_dt <- mut_loci %>%
      dplyr::filter(seqnames == chrom_iter_list[x]) %>%
      dplyr::select(possible_col_names[which_col_names])

    # Now create temporary loci and output file that will be read in as an intermediate file
    temp_alleleCounter_outfile <- tempfile(pattern = stringr::str_remove(string = basename(bam_file_path), pattern = "\\.*\\.bam"),
                                           fileext = paste0(".temp.alleleCounter.", chrom_iter_list[x], ".out.txt"))

    temp_alleleCounter_locifile <- tempfile(pattern = stringr::str_remove(string = basename(bam_file_path), pattern = "\\.*\\.bam"),
                                            fileext = paste0(".temp.alleleCounter.", chrom_iter_list[x], ".loci.txt"))
    data.table::fwrite(x = mut_loci_per_chrom_dt,
                       file =  temp_alleleCounter_locifile,
                       row.names = FALSE,
                       col.names = FALSE,
                       sep = "\t",
                       quote = FALSE)

    # Execute command
    alleleCounter_exe <- paste("alleleCounter",
                               "-b", bam_file_path,
                               "-o", temp_alleleCounter_outfile,
                               "-l", temp_alleleCounter_locifile,
                               "-m", min_base_qual,
                               "-q", min_map_qual)
    system(command = alleleCounter_exe, wait = TRUE)

    # After execution of alleleCounter command, read in the temp output file
    system(command = "sleep 7", wait = TRUE)
    read_counts <- data.table::fread(file = temp_alleleCounter_outfile,
                                     sep = "\t")

    # Unlink temps
    unlink(temp_alleleCounter_outfile)
    unlink(temp_alleleCounter_locifile)

    # Return output of the foreach loops, each GR obj will be concatenated
    read_counts
  }

  # Return combined alleleCount output
  return(final_allele_counts)
}


#' @name get_corrected_cnv_profile
#' @title Read in CNV profile DT of various flavors and extract a corrected profile
#'
#' @description
#' Given a data.table or GRanges CNV object, extract the corrected CNV profile.
#' Any segment with a non-rounded value within 0.2 of the next integer value is rounded to that value.
#' The output will data.table will contain 6 columns: sample, seqnames, start, end, total, minor
#' The `sample` is either user-provided or row count placeholder
#' Currently supports CNV calls from Battenberg and FACETS
#'
#' @param cnv_obj CNV file in data.table or GRanges format
#' @param caller Name of caller that generated input CNV to be converted, supported: Battenberg and FACETS
#' @param sample_id Unique identifier to add to output, default: NULL
#'
#' @return data.table object with corrected CNV segments
#' @export
get_corrected_cnv_profile <- function(cnv_obj, caller, sample_id = NULL) {

  # First, check the CNV object. If data.table, continue on. If not, convert
  if(!"data.table" %in% class(cnv_obj) & "GRanges" %in% class(cnv_obj)) {
    cnv_dt <- gUtils::gr2dt(cnv_obj)

  } else if("data.table" %in% class(cnv_obj)) {
    cnv_dt <- cnv_obj

  } else {
    # Problem if input CNV object is not correct class
    stop(message = "\nInput CNV object needs to be either data.table or GRanges class")
  }

  # Create ID string for sample column
  sample_string <- dplyr::case_when(is.null(sample_id) ~ paste0("sample_X_", caller),
                                    !is.null(sample_id) ~ as.character(sample_id))

  # Case 1: FACETS directly reports total and minor copy number,
  #         only consideration is the occasional NA for minor allele as a result of low het count
  if(caller == "facets") {
    corrected_profile <- data.table::data.table("sample" = rep(sample_string, nrow(cnv_dt)),
                                                "seqnames" = cnv_dt$seqnames,
                                                "start" = cnv_dt$start,
                                                "end" = cnv_dt$end,
                                                "total" = cnv_dt$tcn.em,
                                                "minor" = dplyr::case_when(is.na(cnv_dt$lcn.em) ~ 0,
                                                                          !is.na(cnv_dt$lcn.em) ~ cnv_dt$lcn.em))

    # TODO: this will be depreciated when issues with Battenberg are addressed
    # Case 2: Battenberg (fit.cnv) reports both total and major/minor alleles in rounded and non-rounded format
  } else if(caller == "battenberg.fit") {

    # First, need to account for negative non-rounded values
    bb_cnv_dt <- cnv_dt

    # Get the correct value of the minor allele, is occasionally negative
    corrected_minor_allele <- pmax(bb_cnv_dt$minor_allele_nonrounded, 0)

    # Loop through the Battenberg minor allele segments
    rounded_bb_minor <- c()
    for(i in 1:length(corrected_minor_allele)) {
      # Gather clonally rounded minor alleles
      rounded_bb_minor[i] <- dplyr::case_when(corrected_minor_allele[i] < 0.2 ~ 0,
                                              between(x = corrected_minor_allele[i], left = 0.2, right = 0.8) ~ corrected_minor_allele[i],
                                              between(x = corrected_minor_allele[i], left = 0.8, right = 1.2) ~ 1,
                                              between(x = corrected_minor_allele[i], left = 1.2, right = 1.8) ~ corrected_minor_allele[i],
                                              between(x = corrected_minor_allele[i], left = 1.8, right = 2.2) ~ 2,
                                              between(x = corrected_minor_allele[i], left = 2.2, right = 2.8) ~ corrected_minor_allele[i],
                                              between(x = corrected_minor_allele[i], left = 2.8, right = 3.2) ~ 3,
                                              between(x = corrected_minor_allele[i], left = 3.2, right = 3.8) ~ corrected_minor_allele[i],
                                              between(x = corrected_minor_allele[i], left = 3.8, right = 4.2) ~ 4,
                                              between(x = corrected_minor_allele[i], left = 4.2, right = 4.8) ~ corrected_minor_allele[i],
                                              between(x = corrected_minor_allele[i], left = 4.8, right = 5.2) ~ 5,
                                              between(x = corrected_minor_allele[i], left = 5.2, right = 5.8) ~ corrected_minor_allele[i],
                                              between(x = corrected_minor_allele[i], left = 5.8, right = 6.2) ~ 6,
                                              between(x = corrected_minor_allele[i], left = 6.2, right = 6.8) ~ corrected_minor_allele[i],
                                              corrected_minor_allele[i] >= 6.8 ~ round(x = corrected_minor_allele[i], digits = 0))
    }

    # Get the correct value of the minor allele, is occasionally negative
    corrected_major_allele <- pmax(bb_cnv_dt$major_allele_nonrounded, 0)

    # Now calculate the correct non-rounded total copy number
    corrected_total_cn <- corrected_major_allele + corrected_minor_allele

    # Loop through the Battenberg total CN segments
    rounded_bb_total_cn <- c()
    for(i in 1:length(corrected_total_cn)) {
      # Gather clonally rounded minor alleles
      rounded_bb_total_cn[i] <- dplyr::case_when(corrected_total_cn[i] < 0.2 ~ 0,
                                                 between(x = corrected_total_cn[i], left = 0.2, right = 0.8) ~ corrected_total_cn[i],
                                                 between(x = corrected_total_cn[i], left = 0.8, right = 1.2) ~ 1,
                                                 between(x = corrected_total_cn[i], left = 1.2, right = 1.8) ~ corrected_total_cn[i],
                                                 between(x = corrected_total_cn[i], left = 1.8, right = 2.2) ~ 2,
                                                 between(x = corrected_total_cn[i], left = 2.2, right = 2.8) ~ corrected_total_cn[i],
                                                 between(x = corrected_total_cn[i], left = 2.8, right = 3.2) ~ 3,
                                                 between(x = corrected_total_cn[i], left = 3.2, right = 3.8) ~ corrected_total_cn[i],
                                                 between(x = corrected_total_cn[i], left = 3.8, right = 4.2) ~ 4,
                                                 between(x = corrected_total_cn[i], left = 4.2, right = 4.8) ~ corrected_total_cn[i],
                                                 between(x = corrected_total_cn[i], left = 4.8, right = 5.2) ~ 5,
                                                 between(x = corrected_total_cn[i], left = 5.2, right = 5.8) ~ corrected_total_cn[i],
                                                 between(x = corrected_total_cn[i], left = 5.8, right = 6.2) ~ 6,
                                                 between(x = corrected_total_cn[i], left = 6.2, right = 6.8) ~ corrected_total_cn[i],
                                                 corrected_total_cn[i] >= 6.8 ~ round(x = corrected_total_cn[i], digits = 0))
    }

    corrected_profile <- data.table::data.table("sample" = rep(sample_string, nrow(cnv_dt)),
                                                "seqnames" = cnv_dt$seqnames,
                                                "start" = cnv_dt$start,
                                                "end" = cnv_dt$end,
                                                "total" = rounded_bb_total_cn,
                                                "minor" = rounded_bb_minor)
    }

  # Return the final profile
  return(corrected_profile)
}













# }}}}------->>>
#
#  Reader functions
#
# }}}}------->>>

#' @name read_gtf_file
#' @title Read in a GTF file, such as one from Ensembl, and convert to GRanges object
#'
#' @description
#' Read in a GTF file which contains a number of columns and convert it to a GRanges object with refactored seq details.
#' The GTF file can be either zipped or unzipped.
#'
#' @param gtf_file_path Path to GTF file
#' @param seq_lengths Named vector object used as the template for new seq details, see `gUtils::hg_seqlengths()` for example
#'
#' @return GenomicRanges object with GTF columns and updated seqinfo, seqnames, seqlengths, seqlevels
#' @export
read_gtf_file <- function(gtf_file_path, seq_lengths = gUtils::hg_seqlengths()) {

  gtf_gr <- rtracklayer::import(gtf_file_path)

  # Sort out seqinfo/levels/lengths mess
  gtf_gr <- gr_refactor_seqs(input_gr = gtf_gr, new_levels = seq_lengths)
  return(gtf_gr)
}

#' @name get_genes_shortcut
#' @title Shortcut to get only protein coding genes from GTF file and convert to GRanges object
#'
#' @description
#' Read in a GTF file, subset to protein coding genes, and convert it to a GRanges object with refactored seq details.
#' The GTF file can be either zipped or unzipped.
#'
#' @param gtf_file_path Path to GTF file
#' @param seq_lengths Named vector object used as the template for new seq details, see `gUtils::hg_seqlengths()` for example
#'
#' @return GenomicRanges object with GTF columns and updated seqinfo, seqnames, seqlengths, seqlevels
#' @export
get_genes_shortcut <- function(gtf_file_path, seq_lengths = gUtils::hg_seqlengths()) {

  gtf_gr <- read_gtf_file(gtf_file_path = gtf_file_path, seq_lengths = seq_lengths)

  # Subset to protein coding biotype and non-NA gene symbols
  genes <- gtf_gr %Q% (gene_biotype == "protein_coding" & type == "gene" & !is.na(gene_name))
  return(genes)
}

#' @name read_maf_file
#' @title Read MAF file and convert to GRanges object
#'
#' @description
#' Read in a MAF file which contains a number of columns and convert it to a GRanges object with refactored seq details.
#' The MAF file can be either zipped or unzipped.
#' For more specific MAFtools operations, see `maftools::read.maf()`
#'
#' @param maf_file_path Path to MAF file
#' @param cpus number of cpus for reading in data, used by `data.table::fread()`, default: 2
#' @param seq_lengths Named vector object used as the template for new seq details, see `gUtils::hg_seqlengths()` for example
#'
#' @return GenomicRanges object with MAF columns and updated seqinfo, seqnames, seqlengths, seqlevels
#' @export
read_maf_file <- function(maf_file_path, cpus = 2, seq_lengths = gUtils::hg_seqlengths()) {

  # Set available threads
  doParallel::registerDoParallel(cores = cpus)

  # Read in MAF with extra speed
  maf_dt <- data.table::fread(input = maf_file_path,
                              sep = "\t",
                              header = TRUE,
                              stringsAsFactors = FALSE,
                              nThread = cpus)
  maf_gr <- gUtils::dt2gr(maf_dt)

  # Sort out seqinfo/levels/lengths mess
  maf_gr <- gr_refactor_seqs(input_gr = maf_gr, new_levels = seq_lengths)
  return(maf_gr)
}

#' @name read_bed_file
#' @title Read in a BED file, with or without header, and convert to GRanges object
#'
#' @description
#' Read in a BED file and convert it to a GRanges object with refactored seq details.
#' Expects the first 3 columns as chromosome, start, end; However column names are not necessary
#' The BED file can be either zipped or unzipped.
#'
#' @param bed_file_path Path to BED file
#' @param has_header Does BED file have header line
#' @param additional_col_names Names for additional columns in BED file, beyond first three
#' @param cpus number of cpus for reading in data, used by `data.table::fread()`, default: 1
#' @param seq_lengths Named vector object used as the template for new seq details, see `gUtils::hg_seqlengths()` for example
#'
#' @return GenomicRanges object with BED columns, if present, and updated seqinfo, seqnames, seqlengths, seqlevels
#' @export
read_bed_file <- function(bed_file_path, has_header = FALSE, additional_col_names = NULL, cpus = 1, seq_lengths = gUtils::hg_seqlengths()) {

  # Set available threads
  doParallel::registerDoParallel(cores = cpus)

  # Read in file with options to account for various combinations of header/columns
  # Case 1: no header
  if(has_header == F) {
    bed_dt <- data.table::fread(input = bed_file_path,
                                sep = "\t",
                                header = has_header,
                                stringsAsFactors = FALSE,
                                nThread = cpus)

    # Subcase condition 1: only 3 columns
    if(ncol(bed_dt) == 3 & is.null(additional_col_names)) {
      colnames(bed_dt) <- c("chr", "start", "end")
    # Subcase condition 2: more than 3 columns, no additional names given
    } else if(ncol(bed_dt) > 3 & is.null(additional_col_names)) {
      colnames(bed_dt)[1:3] <- c("chr", "start", "end")
    # Subcase condition 3: more than 3 columns, additional names given
    } else if(ncol(bed_dt) > 3 & !is.null(additional_col_names)) {
      colnames(bed_dt) <- c("chr", "start", "end", additional_col_names)
    }

  # Case 2: has a header
  } else if(has_header == T) {
    bed_dt <- data.table::fread(input = bed_file_path,
                                sep = "\t",
                                header = has_header,
                                stringsAsFactors = FALSE,
                                nThread = cpus)

    # Subcase condition 1: only 3 columns
    if(ncol(bed_dt) == 3 & is.null(additional_col_names)) {
      colnames(bed_dt) <- c("chr", "start", "end")
      # Subcase condition 2: more than 3 columns
    } else if(ncol(bed_dt) > 3 & is.null(additional_col_names)) {
      colnames(bed_dt)[1:3] <- c("chr", "start", "end")
    }
  }

  # Edge Case: Check for use of 23/24 for chrX/chrY
  chromosome_set <- unique(bed_dt$chr)
  if(23 %in% chromosome_set) {
    message("Chromosome `23` detected ...\nConverting to `chrX` ...")
    bed_dt$chr <- dplyr::recode(bed_dt$chr, `23` = "X", .default = as.character(bed_dt$chr))
  }
  if(24 %in% chromosome_set) {
    message("Chromosome `24` detected ...\nConverting to `chrY` ...")
    bed_dt$chr <- dplyr::recode(bed_dt$chr, `24` = "Y", .default = as.character(bed_dt$chr))
  }

  bed_gr <- gUtils::dt2gr(bed_dt)

  # Sort out seqinfo/levels/lengths mess
  bed_gr <- gr_refactor_seqs(input_gr = bed_gr, new_levels = seq_lengths)
  return(bed_gr)
}

#' @name read_vcf_file
#' @title Read in a VCF file and convert to GRanges object
#'
#' @description
#' Read in a VCF file and convert it to a GRanges object with refactored seq details.
#' Currently supports conversion of somatic SNV/InDel VCFs from Mutect, Strelka, Varscan, SvABA, CaVEMan.
#' Also supports conversion of germline SNP/InDel VCF from DeepVariant.
#' The VCF file can be either zipped or unzipped.
#'
#' @param vcf_file_path Path to VCF file
#' @param tumor_sample Name of tumor sample as reported in VCF
#' @param normal_sample Name of normal sample as reported in VCF
#' @param caller Name of the caller that generated input VCF to be converted, supported: mutect, strelka, varscan, svaba, caveman, deepvariant
#' @param mut_type Type of mutations within VCF, supported: snv, indel, snp
#' @param seq_lengths Named vector object used as the template for new seq details, see `gUtils::hg_seqlengths()` for example
#'
#' @return GenomicRanges object with VCF FILTER/INFO/FORMAT columns, if present, and updated seqinfo, seqnames, seqlengths, seqlevels
#' @export
read_vcf_file <- function(vcf_file_path, tumor_sample = NULL, normal_sample = NULL,
                          caller = NULL, mut_type = NULL, seq_lengths = gUtils::hg_seqlengths()) {

  # Read in VCF into VA VCF obj
  vcf_va <- VariantAnnotation::readVcf(file = vcf_file_path)

  # Build the GRanges obj from VCF obj
  # Start by setting the GRanges base and exclude the paramRangesID column
  vcf_gr_base <- vcf_va@rowRanges[,-1]

  # remove names of range rows
  names(vcf_gr_base) <- NULL

  # Have user provide tumor_sample and normal_sample
  # Create metadata column with patient and sample name
  vcf_query_ids <- vcf_va@metadata$header@samples

  # Edge case: SvABA uses BAM name for SAMPLE columns in VCF
  if(caller %in% c("svaba")) {
    vcf_query_ids <- stringr::str_remove(string = vcf_query_ids, pattern = "\\..+\\.bam$")
  }

  # Add column for name of caller
  vcf_gr_base$CALLER <- caller

  # Sanity Check: Do VCF query IDs match user-provided tumor/normal parameters?
  # Check if germline first then somatic
  # DeepVariant only uses normal sample for germline
  if(caller == "deepvariant" & is.null(tumor_sample) & !is.null(normal_sample)) {
    vcf_normal_sample_index <- 1

    vcf_gr_base$PATIENT <- normal_sample
    vcf_gr_base$NORMAL <- normal_sample

  } else if(caller %in% c("mutect", "svaba") & tumor_sample %in% vcf_query_ids & normal_sample %in% vcf_query_ids) {
    vcf_tumor_sample_index <- which(tumor_sample == vcf_query_ids)
    vcf_normal_sample_index <- which(normal_sample == vcf_query_ids)

    vcf_gr_base$TUMOR <- vcf_query_ids[vcf_tumor_sample_index]
    vcf_gr_base$NORMAL <- vcf_query_ids[vcf_normal_sample_index]

    vcf_gr_base$SAMPLE <- vcf_query_ids[vcf_tumor_sample_index]
    vcf_gr_base$PATIENT <- vcf_query_ids[vcf_normal_sample_index]

    # Strelka, VarScan, CaVEMan uses generic NORMAL and TUMOR/TUMOUR as name of SAMPLE columns instead of sample ID/BAM basename
  } else if(caller %in% c("strelka", "varscan", "caveman") & !is.null(tumor_sample) & !is.null(normal_sample)) {

    vcf_tumor_sample_index <- which(vcf_query_ids %in% c("TUMOR", "TUMOUR"))
    vcf_normal_sample_index <- which(vcf_query_ids == "NORMAL")

    vcf_gr_base$SAMPLE <- tumor_sample
    vcf_gr_base$TUMOR <- tumor_sample

    vcf_gr_base$PATIENT <- normal_sample
    vcf_gr_base$NORMAL <- normal_sample

  } else {
    # Problem if there is no proper combo of samples and caller
    stop(message = "\nTumor/Normal sample names provided NOT FOUND in VCF")
  }

  # Now form the final GRanges obj by grabbing the REF, ALT, QUAL, FILTER, and all INFO columns
  vcf_gr <- vcf_gr_base
  S4Vectors::mcols(vcf_gr) <- c(S4Vectors::mcols(vcf_gr_base), vcf_va@fixed, vcf_va@info)

  # Convert the REF/ALT field from DNA Biostring to character
  # ALT
  if(!is.character(vcf_gr$ALT)) {
    vcf_gr$ALT <- as.character(unlist(vcf_va@fixed$ALT))  # Needed for SNVs primarily but not exclusively
  }
  # REF
  if(!is.character(vcf_gr$REF)) {
    vcf_gr$REF <- unlist(stringr::str_split(string = Biostrings::toString(vcf_va@fixed$REF), pattern = ", "))  # Needed for InDels
  }

  # Add tumor and normal specific DP field
  if(caller %in% c("mutect", "varscan", "strelka", "caveman")) {
    vcf_gr$DP_TUMOR <- vcf_va@assays@data@listData$DP[,vcf_tumor_sample_index]
    vcf_gr$DP_NORMAL <- vcf_va@assays@data@listData$DP[,vcf_normal_sample_index]

  } else if(caller == "deepvariant") {
    vcf_gr$DP_NORMAL <- vcf_va@assays@data@listData$DP[,vcf_normal_sample_index]
  }

  if(caller == "mutect") {
    # FORMAT fields are stored in list of lists, need to properly extract tumor AD, AF and normal AD
    # When unlisting the AD/AF fields, the allele depth is split into REF and ALT columns
    # so easily grab with even (ALT) and odd (REF) vector index
    vcf_tumor_allele_depth <- unlist(vcf_va@assays@data@listData$AD[,vcf_tumor_sample_index])
    odd_even_index <- seq_len(length(vcf_tumor_allele_depth)) %% 2

    vcf_gr$AD_REF_TUMOR <- vcf_tumor_allele_depth[odd_even_index == 1]
    vcf_gr$AD_ALT_TUMOR <- vcf_tumor_allele_depth[odd_even_index == 0]

    vcf_gr$AF_TUMOR <- unlist(vcf_va@assays@data@listData$AF[,vcf_tumor_sample_index])
    vcf_gr$GT_TUMOR <- vcf_va@assays@data@listData$GT[,vcf_tumor_sample_index]

    vcf_normal_allele_depth <- unlist(vcf_va@assays@data@listData$AD[,vcf_normal_sample_index])
    vcf_gr$AD_REF_NORMAL <- vcf_normal_allele_depth[odd_even_index == 1]
    vcf_gr$AD_ALT_NORMAL <- vcf_normal_allele_depth[odd_even_index == 0]

    vcf_gr$GT_NORMAL <- vcf_va@assays@data@listData$GT[,vcf_normal_sample_index]

    # Some INFO metrics need to be reformatted from complex to simple (i.e. list to vector)
    vcf_gr$AS_FilterStatus <- unlist(vcf_gr$AS_FilterStatus)
    vcf_gr$AS_UNIQ_ALT_READ_COUNT <- unlist(vcf_gr$AS_UNIQ_ALT_READ_COUNT)

    MBQ_1 <- unlist(vcf_gr$MBQ)[odd_even_index == 1]
    MBQ_2 <- unlist(vcf_gr$MBQ)[odd_even_index == 0]
    vcf_gr$MBQ <- stringr::str_c(MBQ_1, MBQ_2, sep = ",")

    MFRL_1 <- unlist(vcf_gr$MFRL)[odd_even_index == 1]
    MFRL_2 <- unlist(vcf_gr$MFRL)[odd_even_index == 0]
    vcf_gr$MFRL <- stringr::str_c(MFRL_1, MFRL_2, sep = ",")

    MMQ_1 <- unlist(vcf_gr$MMQ)[odd_even_index == 1]
    MMQ_2 <- unlist(vcf_gr$MMQ)[odd_even_index == 0]
    vcf_gr$MMQ <- stringr::str_c(MMQ_1, MMQ_2, sep = ",")

    vcf_gr$MPOS <- unlist(vcf_gr$MPOS)
    vcf_gr$NALOD <- unlist(vcf_gr$NALOD)
    vcf_gr$NLOD <- unlist(vcf_gr$NLOD)
    vcf_gr$POPAF <- unlist(vcf_gr$POPAF)

    RPA_1 <- unlist(vcf_gr$RPA)[odd_even_index == 1]
    RPA_2 <- unlist(vcf_gr$RPA)[odd_even_index == 0]
    vcf_gr$RPA <- stringr::str_c(RPA_1, RPA_2, sep = ",")

    vcf_gr$TLOD <- unlist(vcf_gr$TLOD)

  } else if(caller == "strelka" & mut_type == "snv") {
    # Strelka VCF breaks down reads by nucleotide, then by tier
    vcf_gr$AU_TIER1_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$AU)[,vcf_tumor_sample_index]
    vcf_gr$AU_TIER2_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$AU)[,vcf_tumor_sample_index + 2]

    vcf_gr$CU_TIER1_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$CU)[,vcf_tumor_sample_index]
    vcf_gr$CU_TIER2_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$CU)[,vcf_tumor_sample_index + 2]

    vcf_gr$GU_TIER1_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$GU)[,vcf_tumor_sample_index]
    vcf_gr$GU_TIER2_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$GU)[,vcf_tumor_sample_index + 2]

    vcf_gr$TU_TIER1_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$TU)[,vcf_tumor_sample_index]
    vcf_gr$TU_TIER2_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$TU)[,vcf_tumor_sample_index + 2]

    vcf_gr$AU_TIER1_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$AU)[,vcf_normal_sample_index]
    vcf_gr$AU_TIER2_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$AU)[,vcf_normal_sample_index + 2]

    vcf_gr$CU_TIER1_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$CU)[,vcf_normal_sample_index]
    vcf_gr$CU_TIER2_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$CU)[,vcf_normal_sample_index + 2]

    vcf_gr$GU_TIER1_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$GU)[,vcf_normal_sample_index]
    vcf_gr$GU_TIER2_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$GU)[,vcf_normal_sample_index + 2]

    vcf_gr$TU_TIER1_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$TU)[,vcf_normal_sample_index]
    vcf_gr$TU_TIER2_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$TU)[,vcf_normal_sample_index + 2]

  } else if(caller == "strelka" & mut_type == "indel") {
    # Strelka has different FORMAT fields for indel VCF, most relevant is TIR (Reads strongly supporting indel allele for tiers 1,2)
    vcf_gr$TIR_TIER1_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$TIR)[,vcf_tumor_sample_index]
    vcf_gr$TIR_TIER2_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$TIR)[,vcf_tumor_sample_index + 2]

    vcf_gr$TIR_TIER1_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$TIR)[,vcf_normal_sample_index]
    vcf_gr$TIR_TIER2_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$TIR)[,vcf_normal_sample_index + 2]

  } else if(caller == "varscan") {
    # Varscan breaks down the read depth into 2 separate fields as ref read depth and variant read depth
    vcf_gr$RD_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$RD)[,vcf_tumor_sample_index]
    vcf_gr$AD_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$AD)[,vcf_tumor_sample_index]

    vcf_gr$FREQ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$FREQ)[,vcf_tumor_sample_index]
    vcf_gr$GT_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$GT)[,vcf_tumor_sample_index]

    vcf_gr$RD_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$RD)[,vcf_normal_sample_index]
    vcf_gr$AD_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$AD)[,vcf_normal_sample_index]

    vcf_gr$FREQ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$FREQ)[,vcf_normal_sample_index]
    vcf_gr$GT_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$GT)[,vcf_normal_sample_index]

  } else if(caller == "svaba") {
    # SvABA also provides the SR FORMAT field for number of spanning reads for the variants
    vcf_gr$AD_TUMOR <- vcf_va@assays@data@listData$AD[,vcf_tumor_sample_index]
    vcf_gr$SR_TUMOR <- vcf_va@assays@data@listData$SR[,vcf_tumor_sample_index]
    vcf_gr$GT_TUMOR <- vcf_va@assays@data@listData$GT[,vcf_tumor_sample_index]

    vcf_gr$AD_NORMAL <- vcf_va@assays@data@listData$AD[,vcf_normal_sample_index]
    vcf_gr$SR_NORMAL <- vcf_va@assays@data@listData$SR[,vcf_normal_sample_index]
    vcf_gr$GT_NORMAL <- vcf_va@assays@data@listData$GT[,vcf_normal_sample_index]

    # Some INFO metrics are complex format but empty, remove them here
    vcf_gr <- vcf_gr[,!colnames(S4Vectors::mcols(vcf_gr)) %in% c("READNAMES", "BX")]

  } else if(caller == "caveman") {
    # CaVEMan provides a format field for each nucleotide type per forward and reverse strand reads at the variant
    # The DS metric is complex format but empty/redundant, remove them here
    vcf_gr <- vcf_gr[,!colnames(S4Vectors::mcols(vcf_gr)) == "DS"]

    vcf_gr$FAZ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$FAZ)[,vcf_tumor_sample_index]
    vcf_gr$FCZ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$FCZ)[,vcf_tumor_sample_index]
    vcf_gr$FGZ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$FGZ)[,vcf_tumor_sample_index]
    vcf_gr$FTZ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$FTZ)[,vcf_tumor_sample_index]
    vcf_gr$RAZ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$RAZ)[,vcf_tumor_sample_index]
    vcf_gr$RCZ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$RCZ)[,vcf_tumor_sample_index]
    vcf_gr$RGZ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$RGZ)[,vcf_tumor_sample_index]
    vcf_gr$RTZ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$RTZ)[,vcf_tumor_sample_index]
    vcf_gr$PM_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$PM)[,vcf_tumor_sample_index]
    vcf_gr$GT_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$GT)[,vcf_tumor_sample_index]

    vcf_gr$FAZ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$FAZ)[,vcf_normal_sample_index]
    vcf_gr$FCZ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$FCZ)[,vcf_normal_sample_index]
    vcf_gr$FGZ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$FGZ)[,vcf_normal_sample_index]
    vcf_gr$FTZ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$FTZ)[,vcf_normal_sample_index]
    vcf_gr$RAZ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$RAZ)[,vcf_normal_sample_index]
    vcf_gr$RCZ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$RCZ)[,vcf_normal_sample_index]
    vcf_gr$RGZ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$RGZ)[,vcf_normal_sample_index]
    vcf_gr$RTZ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$RTZ)[,vcf_normal_sample_index]
    vcf_gr$PM_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$PM)[,vcf_normal_sample_index]
    vcf_gr$GT_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$GT)[,vcf_normal_sample_index]

  } else if(caller == "deepvariant") {

    vcf_gr$REF_AD_NORMAL <- as.vector(unlist(as.data.frame(vcf_va@assays@data@listData$AD[,])[1,]))
    vcf_gr$ALT_AD_NORMAL <- as.vector(unlist(as.data.frame(vcf_va@assays@data@listData$AD[,])[2,]))
    vcf_gr$VAF_NORMAL <- as.vector(unlist(as.data.frame(vcf_va@assays@data@listData$VAF[,])[1,]))
    vcf_gr$GT_NORMAL <- vcf_va@assays@data@listData$GT[,]

    # Remove some populated columns
    GenomicRanges::mcols(vcf_gr) <- GenomicRanges::mcols(vcf_gr)[,-c(8:12)]
  }

  # Sort out seqinfo/levels/lengths mess
  vcf_gr <- gr_refactor_seqs(input_gr = vcf_gr, new_levels = seq_lengths)
  return(vcf_gr)
}











#' @name aggregate_these
#' @title Read in all data files of a specific grep pattern, aggregate them into a single data.table
#'
#' @description
#' Collect all files that match a specific `ls`-style pattern at a specific path, read them into a data.table, then aggregate
#' all into single data.table. Best suited for genomic data formats such as SNV/InDel mutation table, CNV BED, or SV BEDPE.
#'
#' @param path_to_files path to location of files to be aggregated
#' @param pattern_to_grab `ls`-style pattern used to identify files
#' @param delim delimiter used in files to be aggregated, expected to be same in all files
#' @param has_header indicate if files have a header line, expected to be same in all files
#' @param cpus number of cpus for reading in data, used by `data.table::fread()`
#' @param add_uniq_id indicate if the output data.table should include a unique identifier column, derived from input file basename
#'
#' @return data.table object with all data under preserved column construct
#' @export
aggregate_these <- function(path_to_files, pattern_to_grab, delim = "\t", has_header = TRUE,
                            cpus = 1, add_uniq_id = FALSE) {

  # Set available threads
  doParallel::registerDoParallel(cores = cpus)

  # Find all files at the provided path that match the provided pattern
  input_files_to_aggregate <- list.files(path = path_to_files,
                                         pattern = pattern_to_grab)

  # Create output DT to fill with aggregated data
  aggregate_dt <- data.table::data.table()
  for(i in 1:length(input_files_to_aggregate)) {

    # Read in single file
    dt_to_add <- data.table::fread(input = paste0(path_to_files, input_files_to_aggregate[i]),
                                   sep = delim,
                                   header = has_header,
                                   stringsAsFactors = F,
                                   nThread = cpus)

    # Some file formats do not explicitly have a patient/sample column or any unique identifier
    # Let's add one derived from the input file name, if needed
    if(add_uniq_id) {
      uniq_id <- str_remove(string = input_files_to_aggregate[i], pattern = "\\..*$")
      dt_to_add$id <- uniq_id
    }

    # Add to aggregate DT
    aggregate_dt <- gUtils::rrbind(aggregate_dt, dt_to_add, as.data.table = T)
  }

  # TODO: The sort functionality is bugged, aggregated file has some sort of mix-and-match of columns
  # sort_output = TRUE,
  # #' @param sort_output indicate if the output data.table should be sorted by genomic coordinate, BEDPE not supported yet
  # Sort the output by genomic coordinate if desired
  #if(sort_output) {
  #
  #  # TODO: BEDPE files don't translate from DT to GR with standard header, likely need gGnome junctions
  #  # Convert to GR to run foolproof sorting
  #  aggregate_gr <- gr_refactor_seqs(input_gr = gUtils::dt2gr(aggregate_dt))
  #  aggregate_dt <- gUtils::gr2dt(x = aggregate_gr)
  #}
  return(aggregate_dt)
}




