######################################################################################
#                         ___   ___        ____   ____                               #
#                          | | |     |   /  |     |   | |   |                        #
# }}}}------->>>           + | |-+-  |  +   | +-  |-+-  |   |         <<<-------{{{{ #
#                          | | |     | /    |   | |  \  |   |                        #
#                         ---   ---   /      ---      \  ---                         #
# ▒▓▓▒▒▒▒▒▒▒▒▓▓▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▓▒▒▒▒▒▒▒▒▒▒▒▒
# ▒▒▒▒▒░▒▒▒▒▓▓▒▒▒▒░░░░░░░░░░░░░░░░░░▒▒░░░░░░░░▒░░░░░░░▒░░░░░░░░░░░░░░░░░░▒▒▒▓▓▓▒▒▒▒▒▒▒
# ▒▒▒▒▒░░░░▒▒▒▒▒░░░░░░░░░░░░░░░░░░░░░▒▒▒▒▒▒▒▒▒▒▒▒▒▒░░░░░░░░░░░▒▒▒▒▒░░░░░░░░▒▒▒▓▓▒▒▒▒▒▒
# ▒▒▒▒▒░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░▒▓▓▓▓▓▓▓▒▒▒▒▒░░░░░░░░░▒▒▒▒▓▓▓▓▒░░░░░░░▒▒▓▓▓▒▒▒▓▓
# ▒▒▒▒▒░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░▒▒▒▓▒▓▓▓▓▓▓▓▓▒▒▒░░░░░░▒▓▓▓▒▒▒▓▓▓▒░░░░░░░▒▒▓▓▓▒▒▒▒
# ▒▒▒▒▒▒░░░░░░░▒▒░░░░░░░░░░░░░░░▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░░░░░▒▓▒░░░░▒▒▓▓▒░░░░░░░░▒▒▒▒▒▒▒
# ▒▒▒▒▒▒░░░░░▒▒▒▒▓▒░░░░░░░░░░░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░▒▒▒░░░░░░▒▓▓▒░░░░░░░░░▒▒▒▒▒▒
# ▒▒▒▒▒░░░░░░▒▓▓▓▓▓▒░░░░░▒▒▒▒░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░░░░░░░░░░░▒▓▓▒░░░░░░░░░▒▒▒▒▒▒
# ▒▒▒▒▒░░░░░░▒▓▓▓▓▓▓░░░░░▒▒▓▓▒▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░░░░░░░▒▒▒▒▓▒░░░░░░░░░░▒▒▒▒▒░
# ▒▒▒▒▒▒▒░░░░░░▒▓▓▓▒▒░░░░░░▒▒▒▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░░▒▒▒▒▓▓▓▓▓▒▒░░░░░░░░░▒▒▒▒▒░
# ▒▒▒▒▒▒▒░░░░░░▒▓▓▓▓▓▒░░░░░░░░░░░▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░░░░░▒▓▓▓▓▓▓▒▒░░░░░░░░░░░▒▒▒▒▒░
# ▒▒▒▒▒▒▒░░░░▒▒▓▓▓▓▓▓▓▒░░░░░░░░░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒▒▒░░░░░░▒▒▓▓▓▓▒▒░░░░░░░░░░░░▒▒▓▒▒▒▒
# ▒▒▒▒▒▒▒░░░▒▒▒▓▓▓▓▓▓▓▓▓▒░░░░░░░░▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░▒▒▓▓▓▓▒▒░░░░░░░░░░▒▒▒▒▓▒▒▒▒
# ▒▒▒▒▒▒▒░░░░░░░░░░▒▒▓▓▓▓▓▒▒▒▒▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▓▒░░░░░░░░░▒▒▓▓▓▒▒░░░░░░░░░▒▒▓▓▓▓▓▒▒▒
# ▒▒▒▒▒▒▒░░░░░░░░░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░░░░░░▒▓▓▓▒░░░░░░░░░░░▒▒▓▓▓▓▒▒
# ▒▒▒▒▒▒▒▒░░░░░░░░░░░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░░░░░░▒▒▓▓▓▒░░░░░░░░░░░░▒▓▓█▒▒
# ▒▒▒▒▒▒▒▒░░░░░░░░░░░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░▒▒░░░░░░░░░░░▒▓▓▒░░░░░░░░░░░▒▓▓▓▒▒
# ▒▒▒▒▒▒▒▒░░░░░░░░░░░░▒▒▒▒░▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒▒▒░░░░░░░░░░░▒▒▓▒▒░░░░░░░░░▒▓▓▓▒▒
# ▒▒▒▒▓▒▒▒░░░░░░░░░░░░░░░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒▒░░░░░░░░░░░░░▒▓▓▒▒░░░░░░░▒▓▓▓▒▒
# ▒▓▒▓▒▒▒▒▒▒▒▒░░░░░░░░░▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░░░░░░▒▓▓▒░░░░░░░▒▓▓▒▒▒▒
# ▒▒▒▒▒▒▒▒▒▓▓▓▓▒░░░░░░▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░░░░░░░░░▒▓▓▒▒░░░░░░▒▒▓▓▒▒
# ▒▒▒▒▓▒▒▒▒▓▓█▓▓▒▒░▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒▒▒▒▒▒▒▒▒▓▓▓▒▒░░░░░▒▒▓▓▒▒▒
# ▒▒▒▓▓▒▒░▒▒▒▓█▓▓▓▓▓▓██▓▓▓▓▓▓▓▓▓▓▒▒▒▒▒▒▒▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░░░░░▒▒▓▒▒▒
# ▒▒▒▒▓▒▒░░▒▒▓▓██████▓▓▓▒▒▒▒▒▒▒▒▒░░░░░░░░░▒▒▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░░░░░░▒▓▓▒▒▒
# ▒▒▒▒▓▒▒▒▒▒▒▓▓██▓▓▓▒▒░░░░░░░░░░░░░░░░▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░░░░▒▒▓▒▒▒
# ▒▒▒▒▓▒▒▒▒▒▓▓▓▓▓▒▒▒░░░░░░░░░░░░░░░░▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓█▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░░░░░▒▒▒▒▒▒
# ▓▓▒▒▓▓▓▒▒▒▒▒▒▒▒▒░░░░░░░░░░░░░░░░░░▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░░▒▒▒▒▓▒▒▒
# ▒▒▒▒▒▓▓▒▒▒▒▒░░▒░░░░░░░░░░░░░░░░░░░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒▒░░░░░▒▓▒▓▓▒▒
# ▒▒▒▒▒▓▓▓▓▒▒▒░░░░░░░░░░░░░░░░░▒▒▒▒░░▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░▒▒▓▓▒▒
# ▒▒▒▒▒▓▒▒▒▓▒▒▒░░░░░░░░░░░░░░▒▒▓▓▓▓▓▒▒░░░▒▒▒▓▓▓▓▓▓▓▓▒▒▒░░░░░▒▒▒▓▓▓▓▓▓▓▓▓▓▓▒▒░░░▒▒▒▓▒▒▒
# ▓▒▒▒▓▓▓▒▒▓▒▒▒▒░░▒░░░░░░░░░░▒▒▒▓▓▓▓▓▓▒▒▒▒▒▒▒▒▓▓▓▓▓▓▓▓▒▒░░░░░░░░▒▒▓▓▓▓▓▓▓▒▒▓▒░░░▒▒▓▓▒▒
# ▓▒▒▒▓▓▒▒▓▓▒▒▒▒▒▒▒▒░░░░░░░░░░▒▒▒▒▒▓▓▓▓▓▓▓▓▓▒▓▓▓▓▓▓▓▓▒▒▒░░░░░░░░░░▒▒▓▓▓▓▓▓▒░░░░░▒▒▒▒▒▒
# ▓▒▒▒▓▓▒▒▓▓▓▒▒▒▒▒▒▒▒▒▒▒░░░░░▒▒▒▒▒▒▒▒▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▒░░░░░░▒▒▒░░░▒▒▒▓▓▓▓▒▒░░░░▒▒▒▒▒▒
# ▓▒▒▒▓▓▓▒▓▓▒▒▒▒▓▒▒▒▒▒▒▒▒▒░░░▒▒▓▓▒▒▒▒▒▓▓▓▒▒▒▒▒▒▒▓▓▓▓▓▓▒░░░░░░▒▒▒░▒▒▒▒▒▓▓▓▓▓▓▒▒▒░▒▒▒▒▒▒
# ▓▒▒▒▒▓▓▓▓▓▓▓▒▒▓▒▒▒▒▒▒▒▒▒░░░▒░▒▒▒▒▒▒▒▒▒▒▒░░░░░░▒▒▒▓▒▒▒░░░░░░░░░▒▒▒▓▓▓▓▓▓▓▓▓▓▓▒▒▒▒▒▒▒▒
# ▒▓▒▒▒▓▓▓▓▒▒▓▓▓▓▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒░░▒▒░░░░░░░░░░░░░░░▒░▒▒▒▒▒▒▓▓▓▓▓▓▓▒▓▓▓▓▓▓▓▒▒▒▒▒
# ▒▒▒▒▒▓▓▓▓▓▓▓▓▓▓▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒░▒▒▒▒▒▒▒▒▒▒▒░░░░░▒░░░░░░░▒▒▒▒▓▓▓▓▓▒▒▒▒▒▒░▒▒▓▓▓▓▒▒▒▒▒
# ▒▒▒▒▒▒▒▓▓▓▓▓▒▒▒▓▒▓▓▓▓▓▓▒▒▒▓▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒░░░░░░▒▒▒░░░░▒▒▒▒▓▓▒▓▒▒▓▓▓▓▒▒▒▒▒▓▒▒▓▒▒▒▒▒▒
# ▓▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▓▓▓▒▓▓▓▓▒▒▒▓▓▓▓▓▓▒▒▒▒▓▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒
#                                                                                    #
# }}}}------->>>                                                      <<<-------{{{{ #

#' @import gUtils
#' @import GenomicRanges
#' @import GenomeInfoDb
#' @import data.table
#' @import VariantAnnotation
#' @import stringr

#' @importFrom librarian shelf
#' @importFrom BSgenome.Hsapiens.UCSC.hg38 Hsapiens
#' @importFrom dplyr sample_n
#' @importFrom rtracklayer import
#' @importFrom readr read_delim
#' @importFrom S4Vectors mcols
#' @importFrom Biostrings toString
#' @importFrom doParallel registerDoParallel
#' @importFrom foreach foreach
#' @importFrom foreach `%dopar%`


## appease R CMD CHECK misunderstanding of data.table syntax by declaring these global variables
gene_biotype=type=gene_name=AD_ALT_TUMOR=AD_TUMOR=AF_TUMOR=DP_TUMOR=FREQ_TUMOR=PM_TUMOR=TIR_TIER1_TUMOR=x=NULL

# Set up the global default genome and number display
.onLoad <- function(libname, pkgname) {
  op <- options()
  op.devgru <- list(
  	devgru.ref_genome = "hg38"
  )
  toset <- !(names(op.devgru) %in% names(op))
  if (any(toset)) options(op.devgru[toset])

  Sys.setenv(DEFAULT_BSGENOME = 'BSgenome.Hsapiens.UCSC.hg38::Hsapiens')
  Sys.setenv(DEFAULT_GENOME = 'BSgenome.Hsapiens.UCSC.hg38::Hsapiens')
  options(scipen = 999)

  invisible()
}


#' @name kit_loadout
#' @title Build the devgru environment by installing/loading packages
#'
#' @description
#' Single command to install, if needed, and load all packages used in the devgru kit.
#'
#' @param update_kit Update all packages even if already installed, default: TRUE
#'
#' @export
kit_loadout <- function(update_kit = T) {

  logo_viz <- "
#                   ___   ___        ____   ____                          #
#                    | | |     |   /  |     |   | |   |                   #
# }}}}------->>>     + | |-+-  |  +   | +-  |-+-  |   |    <<<-------{{{{ #
#                    | | |     | /    |   | |  \\  |   |                   #
#                   ---   ---   /      ---      \\  ---                    #
"

  # Packages for loadout
  loadout <- c("BSgenome.Hsapiens.UCSC.hg38", "GenomicRanges", "GenomeInfoDb",
               "data.table", "mskilab-org/gUtils", "VariantAnnotation",
               "rtracklayer", "Biostrings", "S4Vectors", "dplyr",
               "stringr", "readr", "ggplot2", "ggsci", "paletteer", "scico",
               "flextable", "mclust", "parallel", "doParallel", "foreach",
               "R.utils")

  loadout_string <- "
  ### GenomicRanges Core ###

  BSgenome.Hsapiens.UCSC.hg38
  GenomicRanges
  GenomeInfoDb
  data.table
  mskilab-org/gUtils
  VariantAnnotation
  rtracklayer
  Biostrings
  S4Vectors

  ### Utility Core ###

  dplyr
  stringr
  readr
  ggplot2
  ggsci
  paletteer
  scico
  flextable
  mclust
  parallel
  doParallel
  foreach
  R.utils
  "
  message(logo_viz)
  message("Building the devgru kit ...")
  message("Loadout currently includes:\n\t", loadout_string)
  librarian::shelf(loadout, update_all = update_kit, quiet = T)
  message("D O N E ...")
}

# }}}}------->>>
#
#  Tools for surveying the GenomicRanges
#
# }}}}------->>>

#' @name gr_refactor_seqs
#' @title Refactor seqinfo, seqnames, seqlengths, seqlevels of GRanges object for easy harmony
#'
#' @description
#' Single command to refactor all seq details of a GRanges object to easily harmonize with any other GRanges object.
#' By default, this package uses the autosome (1-22) and sex chromosomes (X,Y) of hg38, see `gUtils::hg_seqlengths()`
#' Users can adjust this using the `new_levels` parameter.
#'
#' @param input_gr GenomicRanges object to refactor
#' @param new_levels Named vector object used as the template for new seq details, see `gUtils::hg_seqlengths()` for example
#'
#' @return GenomicRanges object with updated seqinfo, seqnames, seqlengths, seqlevels
#' @export
gr_refactor_seqs <- function(input_gr, new_levels = gUtils::hg_seqlengths()) {

  # First, make sure we match input GR 'chr' notation with the desired seqs
  if(length(grep(x = names(new_levels), pattern = "^chr")) > 0) {

    gr <- gUtils::gr.chr(input_gr)
  } else {
    gr <- gUtils::gr.nochr(input_gr)
  }

  # Now start to reset seqnames
  gr@seqnames@values <- factor(x = gr@seqnames@values,
                               levels = names(new_levels)[1:24])

  # Clean up any NAs left in the seqname values
  rando_seqname_replacements <- dplyr::sample_n(tbl = as.data.frame(levels(gr@seqnames@values)),
                                                size = sum(is.na(gr@seqnames@values)))
  colnames(rando_seqname_replacements) <- "replacements"

  gr@seqnames@values[is.na(gr@seqnames@values)] <- rando_seqname_replacements$replacements

  # Sort the new seqinfo
  gr@seqinfo <- GenomeInfoDb::sortSeqlevels(gr@seqinfo, X.is.sexchrom = T)

  # Now ensure seqinfo matches seqnames
  gr@seqinfo <- GenomeInfoDb::Seqinfo(seqnames = names(new_levels)[1:24],
                                      seqlengths = new_levels[1:24])

  # Final sort to ensure ranges are properly sorted by genomic coordinate
  gr <- GenomicRanges::sort.GenomicRanges(gr, ignore.strand = TRUE)
  return(gr)
}





#' @name get_vaf
#' @title Quick pull or explicitly calculate the VAF for mutation records of various flavors
#'
#' @description
#' Given a data.table or GRanges VCF object, quickly extract or explicitly calculate the VAF for all mutations.
#' For clarity, the read support for the VAF will be extracted as well.
#' Currently supports somatic SNV/InDel VCFs from Mutect, Strelka, Varscan, SvABA, CaVEMan.
#'
#' @param vcf_obj VCF file in data.table or GRanges format
#' @param caller Name of the caller that generated input VCF to be converted, supported: mutect, strelka, varscan, svaba, caveman
#' @param mut_type Type of mutations within VCF, supported: snv, indel
#'
#' @return data.table object with read support and VAF per record
#' @export
get_vaf <- function(vcf_obj, caller, mut_type) {

  # First, check the VCF object. If data.table, continue on. If not, convert
  if(!"data.table" %in% class(vcf_obj) & "GRanges" %in% class(vcf_obj)) {
    mut_records <- gUtils::gr2dt(vcf_obj)

  } else if("data.table" %in% class(vcf_obj)) {
    mut_records <- vcf_obj

  } else {
    # Problem if input VCF object is not correct class
    stop(message = "\nInput VCF object needs to be either data.table or GRanges class")
  }

  if(caller == "mutect") {
    # Mutect SNVs and InDels
    # VAF is reported as AF ["Allele fractions of alternate alleles in the tumor"]
    # ALT depth is reported as AD ["Allelic depths for the ref and alt alleles in the order listed"]
    # Total depth is reported as DP ["Approximate read depth (reads with MQ=255 or with bad mates are filtered)"]
    mut_alt_depth <- mut_records[, AD_ALT_TUMOR]
    mut_total_depth <- mut_records[, DP_TUMOR]
    mut_vaf <- round(mut_records[, AF_TUMOR], digits = 4)

  } else if(caller == "varscan") {
    # VarScan SNVs and InDels
    # VAF is reported as FREQ ["Variant allele frequency"]
    # ALT depth is reported as AD ["Depth of variant-supporting bases (reads2)"]
    # Total depth is reported as DP ["Read Depth"]
    mut_alt_depth <- mut_records[, AD_TUMOR]
    mut_total_depth <- mut_records[, DP_TUMOR]
    mut_vaf <- round(as.numeric(stringr::str_remove(string = mut_records[, FREQ_TUMOR], pattern = "%")) / 100, digits = 4)

  } else if(caller == "strelka" & mut_type == "snv") {
    # Strelka SNVs
    # Does not directly report VAF
    # ALT depth is reported as read support per nucleotide tier AU, CU, TU, GU ["Number of 'A/C/G/T' alleles used in tiers 1,2"]
    # Total depth is reported as depth DP ["Read depth for tier1 (used+filtered)"]
    # The VAF will be calculated as: [AU_TIER1, CU_TIER1, TU_TIER1, GU_TIER1] / DP

    # To get the correct ALT depth, need to loop through the records to build
    mut_alt_depth <- rep(NA, nrow(mut_records))
    mut_total_depth <- mut_records[, DP_TUMOR]
    mut_vaf <- rep(NA, nrow(mut_records))

    for(i in 1:nrow(mut_records)) {
      # Get the ALT depth
      mut_alt_depth[i] <- as.data.frame(mut_records[i,])[,colnames(mut_records[i,]) == paste0(mut_records$ALT[i], "U_TIER1_TUMOR")]

      # Calculate the VAF
      mut_vaf[i] <- round(mut_alt_depth[i] / mut_total_depth[i], digits = 4)
    }

  } else if(caller == "strelka" & mut_type == "indel") {
    # Strelka InDels
    # Does not directly report VAF
    # ALT depth is reported as indel tier read support TIR ["Reads strongly supporting indel allele for tiers 1,2"]
    # Total depth is reported as depth DP ["Read depth for tier1 (used+filtered)"]
    # The VAF will be calculated as: TIR_TIER1 / DP
    mut_alt_depth <- mut_records[, TIR_TIER1_TUMOR]
    mut_total_depth <- mut_records[, DP_TUMOR]
    mut_vaf <- round(mut_alt_depth / mut_total_depth, digits = 4)

  } else if(caller == "svaba" & mut_type == "indel") {
    # SvABA InDels
    # Does not directly report VAF
    # ALT depth is reported as allele depth AD ["Allele depth: Number of reads supporting the variant"]
    # Total depth is reported as depth DP ["Depth of coverage: Number of reads covering site."]
    # The VAF will be calculated as: AD / DP
    mut_alt_depth <- mut_records[, AD_TUMOR]
    mut_total_depth <- mut_records[, DP_TUMOR]
    mut_vaf <- round(mut_alt_depth / mut_total_depth, digits = 4)

  } else if(caller == "caveman" & mut_type == "snv") {
    # CaVEMan SNVs
    # VAF is reported as proportion of mut allele PM ["Proportion of mutant allele presenting reads (ALT field) seen by CaVEMan"]
    # ALT depth is reported as read support per nucleotide per strand FAZ, FCZ, FGZ, FTZ, RAZ, RCZ, RGZ, RTZ
    # Total depth is not directly reported

    # To get the correct ALT and total depth, need to loop through the records to build
    mut_alt_depth <- rep(NA, nrow(mut_records))
    mut_total_depth <- rep(NA, nrow(mut_records))
    mut_vaf <- mut_records[, PM_TUMOR]

    for(i in 1:nrow(mut_records)) {
      # Get all nucleotide read depth on both strands
      fwd_alt_depth <- as.data.frame(mut_records[i,])[,colnames(mut_records[i,]) == paste0("F", mut_records$ALT[i], "Z_TUMOR")]
      rev_alt_depth <- as.data.frame(mut_records[i,])[,colnames(mut_records[i,]) == paste0("R", mut_records$ALT[i], "Z_TUMOR")]
      fwd_ref_depth <- as.data.frame(mut_records[i,])[,colnames(mut_records[i,]) == paste0("F", mut_records$REF[i], "Z_TUMOR")]
      rev_ref_depth <- as.data.frame(mut_records[i,])[,colnames(mut_records[i,]) == paste0("R", mut_records$REF[i], "Z_TUMOR")]

      # Calculate the ALT and total read depth
      mut_alt_depth[i] <- sum(fwd_alt_depth, rev_alt_depth)
      mut_total_depth[i] <- sum(fwd_alt_depth, rev_alt_depth, fwd_ref_depth, rev_ref_depth)
    }

  } else {
    # Problem if there is no proper combo of caller and mut_type
    stop(message = "\ncaller and mut_type provided do not match possible combos. See function description")
  }

  # Create final DT of read depth and VAF for each mutation record
  mut_vaf_and_reads <- data.table(alt_depth = mut_alt_depth,
                                  total_depth = mut_total_depth,
                                  vaf = mut_vaf)

  # Output the VAF for the mutation record
  return(mut_vaf_and_reads)
}

# TODO: try to create Rsamtools RSeqLib bamUtils alternative to stay in R
#' @name get_allele_counts
#' @title Read in a BAM file, collect read counts for alleles at set of mutation loci using alleleCounter, and convert to data.table object
#'
#' @description
#' Wrapper command to use alleleCounter to read in a BAM file and count all reads supporting each possible allele at set of mutation loci, then convert it to a data.table object with refactored seq details.
#' The process will be split across each chromosome and then merged for the final output.
#' Expects the first column to be chromosome name, and 3 other columns to exist in the mutation loci file: pos/start/end, ref/REF/Reference_Allele, alt/ALT/Tumor_Seq_Allele2.
#'
#' @param bam_file_path Path to BAM file
#' @param mut_loci_obj Mutation loci file in data.table or GRanges format, required columns: chrom, pos, ref, alt
#' @param min_base_qual Minimum base quality required for a read to be counted, default: 20
#' @param min_map_qual Minimum mapping quality required for a read to be counted, default: 35
#' @param threads Number of threads to use for parallel execution, default: 1
#'
#' @return data.table object with the columns: #CHR, POS, Count_A, Count_C, Count_G, Count_T, Good_depth
#' @export
get_allele_counts = function(bam_file_path, mut_loci_obj, min_base_qual = 20, min_map_qual = 35, threads = 1) {

  # Set parallel cores parameter
  message("Setting parallel cores to ", threads, " ...")
  doParallel::registerDoParallel(cores = threads)

  # First, check if BAM and index exist at the path given
  if(!file.exists(bam_file_path)) {
    stop(message = "\nInput BAM does not exist at the path given")
  }

  if(!file.exists(paste0(bam_file_path, ".bai")) & !file.exists(stringr::str_replace(string = bam_file_path, pattern = "\\.bam", replacement ="\\.bai"))) {
    stop(message = "\nInput BAM .bai index does not at the path given")
  }

  # Second, check the mutation loci object. If data.table, continue on. If not, convert
  if(!"data.table" %in% class(mut_loci_obj) & "GRanges" %in% class(mut_loci_obj)) {
    mut_loci <- gUtils::gr2dt(mut_loci_obj)

  } else if("data.table" %in% class(mut_loci_obj)) {
    mut_loci <- mut_loci_obj

  } else {
    # Problem if input VCF object is not correct class
    stop(message = "\nInput mutation loci object needs to be either data.table or GRanges class")
  }

  # Finally, check if alleleCounter is on the path
  if(class(system("alleleCounter -v", intern = TRUE)) != "character") {
    stop(message = "\nCannot find alleleCounter binary executable on path")
  }

  # Begin foreach construct to parallelize the alleleCounter command per chromosome and then stitch the results together in a GRanges object
  chrom_iter_list <- as.character(unique(mut_loci$seqnames))
  possible_col_names <- c("seqnames", "chrom", "start", "pos", "POS", "ref", "REF", "Reference_Allele", "alt", "ALT", "Tumor_Seq_Allele2")

  final_allele_counts <- foreach::foreach(x = 1:length(chrom_iter_list), .combine = rrbind, .packages = "gUtils") %dopar% {

    # Grab the mutation loci per chromosome and prep for use in alleleCounter
    which_col_names <- which(possible_col_names %in% colnames(mut_loci))
    mut_loci_per_chrom_dt <- mut_loci %>%
      dplyr::filter(seqnames == chrom_iter_list[x]) %>%
      dplyr::select(possible_col_names[which_col_names])

    # Now create temporary loci and output file that will be read in as an intermediate file
    temp_alleleCounter_outfile <- tempfile(pattern = stringr::str_remove(string = basename(bam_file_path), pattern = "\\.*\\.bam"),
                                           fileext = paste0(".temp.alleleCounter.", chrom_iter_list[x], ".out.txt"))

    temp_alleleCounter_locifile <- tempfile(pattern = stringr::str_remove(string = basename(bam_file_path), pattern = "\\.*\\.bam"),
                                            fileext = paste0(".temp.alleleCounter.", chrom_iter_list[x], ".loci.txt"))
    data.table::fwrite(x = mut_loci_per_chrom_dt,
                       file =  temp_alleleCounter_locifile,
                       row.names = FALSE,
                       col.names = FALSE,
                       sep = "\t",
                       quote = FALSE)

    # Execute command
    alleleCounter_exe <- paste("alleleCounter",
                               "-b", bam_file_path,
                               "-o", temp_alleleCounter_outfile,
                               "-l", temp_alleleCounter_locifile,
                               "-m", min_base_qual,
                               "-q", min_map_qual)
    system(command = alleleCounter_exe, wait = TRUE)

    # After execution of alleleCounter command, read in the temp output file
    system(command = "sleep 7", wait = TRUE)
    read_counts <- data.table::fread(file = temp_alleleCounter_outfile,
                                     sep = "\t")

    # Unlink temps
    unlink(temp_alleleCounter_outfile)
    unlink(temp_alleleCounter_locifile)

    # Return output of the foreach loops, each GR obj will be concatenated
    read_counts
  }

  # Return combined alleleCount output
  return(final_allele_counts)
}


#' @name get_clonal_cnv_profile
#' @title Read in CNV profile DT of various flavors and extract a simplified clonal profile
#'
#' @description
#' Given a data.table or GRanges CNV object, extract the clonal CNV profile.
#' Any segment with a non-rounded value within 0.2 of the next integer value is rounded to that value.
#' The output will data.table will contain 6 columns: sample, seqnames, start, end, total, minor
#' The `sample` is either user-provided or row count placeholder
#' Currently supports CNV calls from Battenberg and FACETS
#'
#' @param cnv_obj CNV file in data.table or GRanges format
#' @param caller Name of caller that generated input CNV to be converted, supported: Battenberg and FACETS
#' @param sample_id Unique identifier to add to output, default: NULL
#'
#' @return ata.table object with rounded clonal CNV segments
get_clonal_cnv_profile <- function(cnv_obj, caller, sample_id = NULL) {

  # First, check the CNV object. If data.table, continue on. If not, convert
  if(!"data.table" %in% class(cnv_obj) & "GRanges" %in% class(cnv_obj)) {
    cnv_dt <- gUtils::gr2dt(cnv_obj)

  } else if("data.table" %in% class(cnv_obj)) {
    cnv_dt <- cnv_obj

  } else {
    # Problem if input CNV object is not correct class
    stop(message = "\nInput CNV object needs to be either data.table or GRanges class")
  }

  # Create ID string for sample column
  sample_string <- dplyr::case_when(is.null(sample_id) ~ paste0("sample_X_", caller),
                                    !is.null(sample_id) ~ as.character(sample_id))

  # Case 1: FACETS directly reports total and minor copy number,
  #         only consideration is the occasional NA for minor allele as a result of low het count
  if(caller == "facets") {
    clonal_profile <- data.table::data.table("sample" = rep(sample_string, nrow(cnv_dt)),
                                             "seqnames" = cnv_dt$seqnames,
                                             "start" = cnv_dt$start,
                                             "end" = cnv_dt$end,
                                             "total" = cnv_dt$tcn.em,
                                             "minor" = dplyr::case_when(is.na(cnv_dt$lcn.em) ~ 0,
                                                                        !is.na(cnv_dt$lcn.em) ~ cnv_dt$lcn.em))

    # TODO: this will be depreciated when issues with Battenberg are addressed
    # Case 2: Battenberg (fit.cnv) reports both total and major/minor alleles in rounded and non-rounded format
  } else if(caller == "battenberg.fit") {

    # First, need to account for negative non-rounded values
    bb_cnv_dt <- cnv_dt

    # Get the correct value of the minor allele, is occasionally negative
    corrected_minor_allele <- pmax(bb_cnv_dt$minor_allele_nonrounded, 0)

    # Loop through the Battenberg minor allele segments
    rounded_bb_minor <- c()
    for(i in 1:length(corrected_minor_allele)) {
      # Gather clonally rounded minor alleles
      rounded_bb_minor[i] <- dplyr::case_when(corrected_minor_allele[i] < 0.2 ~ 0,
                                              between(x = corrected_minor_allele[i], lower = 0.2, upper = 0.8) ~ corrected_minor_allele[i],
                                              between(x = corrected_minor_allele[i], lower = 0.8, upper = 1.2) ~ 1,
                                              between(x = corrected_minor_allele[i], lower = 1.2, upper = 1.8) ~ corrected_minor_allele[i],
                                              between(x = corrected_minor_allele[i], lower = 1.8, upper = 2.2) ~ 2,
                                              between(x = corrected_minor_allele[i], lower = 2.2, upper = 2.8) ~ corrected_minor_allele[i],
                                              between(x = corrected_minor_allele[i], lower = 2.8, upper = 3.2) ~ 3,
                                              between(x = corrected_minor_allele[i], lower = 3.2, upper = 3.8) ~ corrected_minor_allele[i],
                                              between(x = corrected_minor_allele[i], lower = 3.8, upper = 4.2) ~ 4,
                                              between(x = corrected_minor_allele[i], lower = 4.2, upper = 4.8) ~ corrected_minor_allele[i],
                                              between(x = corrected_minor_allele[i], lower = 4.8, upper = 5.2) ~ 5,
                                              between(x = corrected_minor_allele[i], lower = 5.2, upper = 5.8) ~ corrected_minor_allele[i],
                                              between(x = corrected_minor_allele[i], lower = 5.8, upper = 6.2) ~ 6,
                                              between(x = corrected_minor_allele[i], lower = 6.2, upper = 6.8) ~ corrected_minor_allele[i],
                                              corrected_minor_allele[i] > 7 ~ round(x = corrected_minor_allele[i], digits = 0))
    }

    # Get the correct value of the minor allele, is occasionally negative
    corrected_major_allele <- pmax(bb_cnv_dt$major_allele_nonrounded, 0)

    # Now calculate the correct non-rounded total copy number
    corrected_total_cn <- corrected_major_allele + corrected_minor_allele

    # Loop through the Battenberg total CN segments
    rounded_bb_total_cn <- c()
    for(i in 1:length(corrected_total_cn)) {
      # Gather clonally rounded minor alleles
      rounded_bb_total_cn[i] <- dplyr::case_when(corrected_total_cn[i] < 0.2 ~ 0,
                                                 between(x = corrected_total_cn[i], lower = 0.2, upper = 0.8) ~ corrected_total_cn[i],
                                                 between(x = corrected_total_cn[i], lower = 0.8, upper = 1.2) ~ 1,
                                                 between(x = corrected_total_cn[i], lower = 1.2, upper = 1.8) ~ corrected_total_cn[i],
                                                 between(x = corrected_total_cn[i], lower = 1.8, upper = 2.2) ~ 2,
                                                 between(x = corrected_total_cn[i], lower = 2.2, upper = 2.8) ~ corrected_total_cn[i],
                                                 between(x = corrected_total_cn[i], lower = 2.8, upper = 3.2) ~ 3,
                                                 between(x = corrected_total_cn[i], lower = 3.2, upper = 3.8) ~ corrected_total_cn[i],
                                                 between(x = corrected_total_cn[i], lower = 3.8, upper = 4.2) ~ 4,
                                                 between(x = corrected_total_cn[i], lower = 4.2, upper = 4.8) ~ corrected_total_cn[i],
                                                 between(x = corrected_total_cn[i], lower = 4.8, upper = 5.2) ~ 5,
                                                 between(x = corrected_total_cn[i], lower = 5.2, upper = 5.8) ~ corrected_total_cn[i],
                                                 between(x = corrected_total_cn[i], lower = 5.8, upper = 6.2) ~ 6,
                                                 between(x = corrected_total_cn[i], lower = 6.2, upper = 6.8) ~ corrected_total_cn[i],
                                                 corrected_total_cn[i] > 7 ~ round(x = corrected_total_cn[i], digits = 0))
    }

    clonal_profile <- data.table::data.table("sample" = rep(sample_string, nrow(cnv_dt)),
                                             "seqnames" = cnv_dt$seqnames,
                                             "start" = cnv_dt$start,
                                             "end" = cnv_dt$end,
                                             "total" = rounded_bb_total_cn,
                                             "minor" = rounded_bb_minor)
  }

  # Return the final profile
  return(clonal_profile)
}













# }}}}------->>>
#
#  Reader functions
#
# }}}}------->>>

#' @name read_gtf_file
#' @title Read in a GTF file, such as one from Ensembl, and convert to GRanges object
#'
#' @description
#' Read in a GTF file which contains a number of columns and convert it to a GRanges object with refactored seq details.
#' The GTF file can be either zipped or unzipped.
#'
#' @param gtf_file_path Path to GTF file
#' @param seq_lengths Named vector object used as the template for new seq details, see `gUtils::hg_seqlengths()` for example
#'
#' @return GenomicRanges object with GTF columns and updated seqinfo, seqnames, seqlengths, seqlevels
#' @export
read_gtf_file <- function(gtf_file_path, seq_lengths = gUtils::hg_seqlengths()) {

  gtf_gr <- rtracklayer::import(gtf_file_path)

  # Sort out seqinfo/levels/lengths mess
  gtf_gr <- gr_refactor_seqs(input_gr = gtf_gr, new_levels = seq_lengths)
  return(gtf_gr)
}

#' @name get_genes_shortcut
#' @title Shortcut to get only protein coding genes from GTF file and convert to GRanges object
#'
#' @description
#' Read in a GTF file, subset to protein coding genes, and convert it to a GRanges object with refactored seq details.
#' The GTF file can be either zipped or unzipped.
#'
#' @param gtf_file_path Path to GTF file
#' @param seq_lengths Named vector object used as the template for new seq details, see `gUtils::hg_seqlengths()` for example
#'
#' @return GenomicRanges object with GTF columns and updated seqinfo, seqnames, seqlengths, seqlevels
#' @export
get_genes_shortcut <- function(gtf_file_path, seq_lengths = gUtils::hg_seqlengths()) {

  gtf_gr <- read_gtf_file(gtf_file_path = gtf_file_path, seq_lengths = seq_lengths)

  # Subset to protein coding biotype and non-NA gene symbols
  genes <- gtf_gr %Q% (gene_biotype == "protein_coding" & type == "gene" & !is.na(gene_name))
  return(genes)
}

#' @name read_maf_file
#' @title Read MAF file and convert to GRanges object
#'
#' @description
#' Read in a MAF file which contains a number of columns and convert it to a GRanges object with refactored seq details.
#' The MAF file can be either zipped or unzipped.
#' For more specific MAFtools operations, see `maftools::read.maf()`
#'
#' @param maf_file_path Path to MAF file
#' @param seq_lengths Named vector object used as the template for new seq details, see `gUtils::hg_seqlengths()` for example
#'
#' @return GenomicRanges object with MAF columns and updated seqinfo, seqnames, seqlengths, seqlevels
#' @export
read_maf_file <- function(maf_file_path, seq_lengths = gUtils::hg_seqlengths()) {

  maf_dt <- data.table::fread(maf_file_path)
  maf_gr <- gUtils::dt2gr(maf_dt)

  # Sort out seqinfo/levels/lengths mess
  maf_gr <- gr_refactor_seqs(input_gr = maf_gr, new_levels = seq_lengths)
  return(maf_gr)
}

#' @name read_bed_file
#' @title Read in a BED file, with or without header, and convert to GRanges object
#'
#' @description
#' Read in a BED file and convert it to a GRanges object with refactored seq details.
#' Expects the first 3 columns as chromosome, start, end; However column names are not necessary
#' The BED file can be either zipped or unzipped.
#'
#' @param bed_file_path Path to BED file
#' @param has_header Indicate if files have a header line, expected to be same in all files
#' @param col_names Names for columns in BED file
#' @param seq_lengths Named vector object used as the template for new seq details, see `gUtils::hg_seqlengths()` for example
#'
#' @return GenomicRanges object with BED columns, if present, and updated seqinfo, seqnames, seqlengths, seqlevels
#' @export
read_bed_file <- function(bed_file_path, has_header = TRUE, col_names = NULL, seq_lengths = gUtils::hg_seqlengths()) {

  # Read in file with options around header/column names
  if(!is.null(col_names)) {
    bed_dt <- data.table::fread(bed_file_path,
                                sep = "\t",
                                header = has_header,
                                col.names = col_names)
  } else {
    bed_dt <- data.table::fread(bed_file_path,
                                sep = "\t",
                                header = has_header)
  }
  bed_gr <- gUtils::dt2gr(bed_dt)

  # Sort out seqinfo/levels/lengths mess
  bed_gr <- gr_refactor_seqs(input_gr = bed_gr, new_levels = seq_lengths)
  return(bed_gr)
}

#' @name read_vcf_file
#' @title Read in a VCF file and convert to GRanges object
#'
#' @description
#' Read in a VCF file and convert it to a GRanges object with refactored seq details.
#' Currently supports conversion of somatic SNV/InDel VCFs from Mutect, Strelka, Varscan, SvABA, CaVEMan.
#' The VCF file can be either zipped or unzipped.
#'
#' @param vcf_file_path Path to VCF file
#' @param tumor_sample Name of tumor sample as reported in VCF
#' @param normal_sample Name of normal sample as reported in VCF
#' @param caller Name of the caller that generated input VCF to be converted, supported: mutect, strelka, varscan, svaba, caveman
#' @param mut_type Type of mutations within VCF, supported: snv, indel
#' @param seq_lengths Named vector object used as the template for new seq details, see `gUtils::hg_seqlengths()` for example
#'
#' @return GenomicRanges object with VCF FILTER/INFO/FORMAT columns, if present, and updated seqinfo, seqnames, seqlengths, seqlevels
#' @export
read_vcf_file <- function(vcf_file_path, tumor_sample = NULL, normal_sample = NULL,
                          caller = NULL, mut_type = NULL, seq_lengths = gUtils::hg_seqlengths()) {

  # Read in VCF into VA VCF obj
  vcf_va <- VariantAnnotation::readVcf(file = vcf_file_path)

  # Build the GRanges obj from VCF obj
  # Start by setting the GRanges base and exclude the paramRangesID column
  vcf_gr_base <- vcf_va@rowRanges[,-1]

  # remove names of range rows
  names(vcf_gr_base) <- NULL

  # TODO: parametrize this step to distinguish somatic vs germline input i.e. 2 sample columns vs 1
  # Have user provide tumor_sample and normal_sample
  # Create metadata column with patient and sample name
  vcf_query_ids <- vcf_va@metadata$header@samples

  # Edge case: SvABA uses BAM name for SAMPLE columns in VCF
  if(caller %in% c("svaba")) {
    vcf_query_ids <- stringr::str_remove(string = vcf_query_ids, pattern = "\\..+\\.bam$")
  }

  # Add column for name of caller
  vcf_gr_base$CALLER <- caller

  # TODO: Sanity Check: Do VCF query IDs match user-provided tumor/normal parameters?
  # in germline only 1 so length should be 1 and only normal_sample should be given
  if(caller %in% c("mutect", "svaba") & tumor_sample %in% vcf_query_ids & normal_sample %in% vcf_query_ids) {
    vcf_tumor_sample_index <- which(tumor_sample == vcf_query_ids)
    vcf_normal_sample_index <- which(normal_sample == vcf_query_ids)

    vcf_gr_base$TUMOR <- vcf_query_ids[vcf_tumor_sample_index]
    vcf_gr_base$NORMAL <- vcf_query_ids[vcf_normal_sample_index]

    vcf_gr_base$SAMPLE <- vcf_query_ids[vcf_tumor_sample_index]
    vcf_gr_base$PATIENT <- vcf_query_ids[vcf_normal_sample_index]

    # Strelka, VarScan, CaVEMan uses generic NORMAL and TUMOR/TUMOUR as name of SAMPLE columns instead of sample ID/BAM basename
  } else if(caller %in% c("strelka", "varscan", "caveman") & !is.null(tumor_sample) & !is.null(normal_sample)) {

    vcf_tumor_sample_index <- which(vcf_query_ids %in% c("TUMOR", "TUMOUR"))
    vcf_normal_sample_index <- which(vcf_query_ids == "NORMAL")

    vcf_gr_base$SAMPLE <- tumor_sample
    vcf_gr_base$TUMOR <- tumor_sample

    vcf_gr_base$PATIENT <- normal_sample
    vcf_gr_base$NORMAL <- normal_sample

  } else {
    # Problem if there is no proper combo of samples and caller
    stop(message = "\nTumor/Normal sample names provided NOT FOUND in VCF")
  }

  # Now form the final GRanges obj by grabbing the REF, ALT, QUAL, FILTER, and all INFO columns
  vcf_gr <- vcf_gr_base
  S4Vectors::mcols(vcf_gr) <- c(S4Vectors::mcols(vcf_gr_base), vcf_va@fixed, vcf_va@info)

  # Convert the REF/ALT field from DNA Biostring to character
  # ALT
  if(!is.character(vcf_gr$ALT)) {
    vcf_gr$ALT <- as.character(unlist(vcf_va@fixed$ALT))  # Needed for SNVs primarily but not exclusively
  }
  # REF
  if(mut_type == "indel" & !is.character(vcf_gr$REF)) {
    vcf_gr$REF <- unlist(stringr::str_split(string = Biostrings::toString(vcf_va@fixed$REF), pattern = ", "))  # Needed for InDels
  }

  # Add tumor and normal specific DP field
  vcf_gr$DP_TUMOR <- vcf_va@assays@data@listData$DP[,vcf_tumor_sample_index]
  vcf_gr$DP_NORMAL <- vcf_va@assays@data@listData$DP[,vcf_normal_sample_index]

  if(caller == "mutect") {
    # FORMAT fields are stored in list of lists, need to properly extract tumor AD, AF and normal AD
    # When unlisting the AD/AF fields, the allele depth is split into REF and ALT columns
    # so easily grab with even (ALT) and odd (REF) vector index
    vcf_tumor_allele_depth <- unlist(vcf_va@assays@data@listData$AD[,vcf_tumor_sample_index])
    odd_even_index <- seq_len(length(vcf_tumor_allele_depth)) %% 2

    vcf_gr$AD_REF_TUMOR <- vcf_tumor_allele_depth[odd_even_index == 1]
    vcf_gr$AD_ALT_TUMOR <- vcf_tumor_allele_depth[odd_even_index == 0]

    vcf_gr$AF_TUMOR <- unlist(vcf_va@assays@data@listData$AF[,vcf_tumor_sample_index])
    vcf_gr$GT_TUMOR <- vcf_va@assays@data@listData$GT[,vcf_tumor_sample_index]

    vcf_normal_allele_depth <- unlist(vcf_va@assays@data@listData$AD[,vcf_normal_sample_index])
    vcf_gr$AD_REF_NORMAL <- vcf_normal_allele_depth[odd_even_index == 1]
    vcf_gr$AD_ALT_NORMAL <- vcf_normal_allele_depth[odd_even_index == 0]

    vcf_gr$GT_NORMAL <- vcf_va@assays@data@listData$GT[,vcf_normal_sample_index]

    # Some INFO metrics need to be reformatted from complex to simple (i.e. list to vector)
    vcf_gr$AS_FilterStatus <- unlist(vcf_gr$AS_FilterStatus)
    vcf_gr$AS_UNIQ_ALT_READ_COUNT <- unlist(vcf_gr$AS_UNIQ_ALT_READ_COUNT)

    MBQ_1 <- unlist(vcf_gr$MBQ)[odd_even_index == 1]
    MBQ_2 <- unlist(vcf_gr$MBQ)[odd_even_index == 0]
    vcf_gr$MBQ <- stringr::str_c(MBQ_1, MBQ_2, sep = ",")

    MFRL_1 <- unlist(vcf_gr$MFRL)[odd_even_index == 1]
    MFRL_2 <- unlist(vcf_gr$MFRL)[odd_even_index == 0]
    vcf_gr$MFRL <- stringr::str_c(MFRL_1, MFRL_2, sep = ",")

    MMQ_1 <- unlist(vcf_gr$MMQ)[odd_even_index == 1]
    MMQ_2 <- unlist(vcf_gr$MMQ)[odd_even_index == 0]
    vcf_gr$MMQ <- stringr::str_c(MMQ_1, MMQ_2, sep = ",")

    vcf_gr$MPOS <- unlist(vcf_gr$MPOS)
    vcf_gr$NALOD <- unlist(vcf_gr$NALOD)
    vcf_gr$NLOD <- unlist(vcf_gr$NLOD)
    vcf_gr$POPAF <- unlist(vcf_gr$POPAF)

    RPA_1 <- unlist(vcf_gr$RPA)[odd_even_index == 1]
    RPA_2 <- unlist(vcf_gr$RPA)[odd_even_index == 0]
    vcf_gr$RPA <- stringr::str_c(RPA_1, RPA_2, sep = ",")

    vcf_gr$TLOD <- unlist(vcf_gr$TLOD)

  } else if(caller == "strelka" & mut_type == "snv") {
    # Strelka VCF breaks down reads by nucleotide, then by tier
    vcf_gr$AU_TIER1_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$AU)[,vcf_tumor_sample_index]
    vcf_gr$AU_TIER2_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$AU)[,vcf_tumor_sample_index + 2]

    vcf_gr$CU_TIER1_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$CU)[,vcf_tumor_sample_index]
    vcf_gr$CU_TIER2_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$CU)[,vcf_tumor_sample_index + 2]

    vcf_gr$GU_TIER1_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$GU)[,vcf_tumor_sample_index]
    vcf_gr$GU_TIER2_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$GU)[,vcf_tumor_sample_index + 2]

    vcf_gr$TU_TIER1_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$TU)[,vcf_tumor_sample_index]
    vcf_gr$TU_TIER2_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$TU)[,vcf_tumor_sample_index + 2]

    vcf_gr$AU_TIER1_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$AU)[,vcf_normal_sample_index]
    vcf_gr$AU_TIER2_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$AU)[,vcf_normal_sample_index + 2]

    vcf_gr$CU_TIER1_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$CU)[,vcf_normal_sample_index]
    vcf_gr$CU_TIER2_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$CU)[,vcf_normal_sample_index + 2]

    vcf_gr$GU_TIER1_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$GU)[,vcf_normal_sample_index]
    vcf_gr$GU_TIER2_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$GU)[,vcf_normal_sample_index + 2]

    vcf_gr$TU_TIER1_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$TU)[,vcf_normal_sample_index]
    vcf_gr$TU_TIER2_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$TU)[,vcf_normal_sample_index + 2]

  } else if(caller == "strelka" & mut_type == "indel") {
    # Strelka has different FORMAT fields for indel VCF, most relevant is TIR (Reads strongly supporting indel allele for tiers 1,2)
    vcf_gr$TIR_TIER1_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$TIR)[,vcf_tumor_sample_index]
    vcf_gr$TIR_TIER2_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$TIR)[,vcf_tumor_sample_index + 2]

    vcf_gr$TIR_TIER1_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$TIR)[,vcf_normal_sample_index]
    vcf_gr$TIR_TIER2_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$TIR)[,vcf_normal_sample_index + 2]

  } else if(caller == "varscan") {
    # Varscan breaks down the read depth into 2 separate fields as ref read depth and variant read depth
    vcf_gr$RD_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$RD)[,vcf_tumor_sample_index]
    vcf_gr$AD_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$AD)[,vcf_tumor_sample_index]

    vcf_gr$FREQ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$FREQ)[,vcf_tumor_sample_index]
    vcf_gr$GT_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$GT)[,vcf_tumor_sample_index]

    vcf_gr$RD_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$RD)[,vcf_normal_sample_index]
    vcf_gr$AD_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$AD)[,vcf_normal_sample_index]

    vcf_gr$FREQ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$FREQ)[,vcf_normal_sample_index]
    vcf_gr$GT_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$GT)[,vcf_normal_sample_index]

  } else if(caller == "svaba") {
    # SvABA also provides the SR FORMAT field for number of spanning reads for the variants
    vcf_gr$AD_TUMOR <- vcf_va@assays@data@listData$AD[,vcf_tumor_sample_index]
    vcf_gr$SR_TUMOR <- vcf_va@assays@data@listData$SR[,vcf_tumor_sample_index]
    vcf_gr$GT_TUMOR <- vcf_va@assays@data@listData$GT[,vcf_tumor_sample_index]

    vcf_gr$AD_NORMAL <- vcf_va@assays@data@listData$AD[,vcf_normal_sample_index]
    vcf_gr$SR_NORMAL <- vcf_va@assays@data@listData$SR[,vcf_normal_sample_index]
    vcf_gr$GT_NORMAL <- vcf_va@assays@data@listData$GT[,vcf_normal_sample_index]

    # Some INFO metrics are complex format but empty, remove them here
    vcf_gr <- vcf_gr[,!colnames(S4Vectors::mcols(vcf_gr)) %in% c("READNAMES", "BX")]

  } else if(caller == "caveman") {
    # CaVEMan provides a format field for each nucleotide type per forward and reverse strand reads at the variant
    # The DS metric is complex format but empty/redundant, remove them here
    vcf_gr <- vcf_gr[,!colnames(S4Vectors::mcols(vcf_gr)) == "DS"]

    vcf_gr$FAZ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$FAZ)[,vcf_tumor_sample_index]
    vcf_gr$FCZ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$FCZ)[,vcf_tumor_sample_index]
    vcf_gr$FGZ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$FGZ)[,vcf_tumor_sample_index]
    vcf_gr$FTZ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$FTZ)[,vcf_tumor_sample_index]
    vcf_gr$RAZ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$RAZ)[,vcf_tumor_sample_index]
    vcf_gr$RCZ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$RCZ)[,vcf_tumor_sample_index]
    vcf_gr$RGZ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$RGZ)[,vcf_tumor_sample_index]
    vcf_gr$RTZ_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$RTZ)[,vcf_tumor_sample_index]
    vcf_gr$PM_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$PM)[,vcf_tumor_sample_index]
    vcf_gr$GT_TUMOR <- as.data.frame(VariantAnnotation::geno(vcf_va)$GT)[,vcf_tumor_sample_index]

    vcf_gr$FAZ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$FAZ)[,vcf_normal_sample_index]
    vcf_gr$FCZ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$FCZ)[,vcf_normal_sample_index]
    vcf_gr$FGZ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$FGZ)[,vcf_normal_sample_index]
    vcf_gr$FTZ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$FTZ)[,vcf_normal_sample_index]
    vcf_gr$RAZ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$RAZ)[,vcf_normal_sample_index]
    vcf_gr$RCZ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$RCZ)[,vcf_normal_sample_index]
    vcf_gr$RGZ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$RGZ)[,vcf_normal_sample_index]
    vcf_gr$RTZ_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$RTZ)[,vcf_normal_sample_index]
    vcf_gr$PM_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$PM)[,vcf_normal_sample_index]
    vcf_gr$GT_NORMAL <- as.data.frame(VariantAnnotation::geno(vcf_va)$GT)[,vcf_normal_sample_index]
  }

  # Sort out seqinfo/levels/lengths mess
  vcf_gr <- gr_refactor_seqs(input_gr = vcf_gr, new_levels = seq_lengths)
  return(vcf_gr)
}











#' @name aggregate_these
#' @title Read in all data files of a specific grep pattern, aggregate them into a single data.table
#'
#' @description
#' Collect all files that match a specific `ls`-style pattern at a specific path, read them into a data.table, then aggregate
#' all into single data.table. Best suited for genomic data formats such as SNV/InDel mutation table, CNV BED, or SV BEDPE.
#'
#' @param path_to_files path to location of files to be aggregated
#' @param pattern_to_grab `ls`-style pattern used to identify files
#' @param delim delimiter used in files to be aggregated, expected to be same in all files
#' @param has_header indicate if files have a header line, expected to be same in all files
#' @param cpus number of cpus for reading in data, used by `data.table::fread()`
#' @param add_uniq_id indicate if the output data.table should include a unique identifier column, derived from input file basename
#'
#' @return data.table object with all data under preserved column construct
#' @export
aggregate_these <- function(path_to_files, pattern_to_grab, delim = "\t", has_header = TRUE,
                            cpus = 1, add_uniq_id = FALSE) {

  # Find all files at the provided path that match the provided pattern
  input_files_to_aggregate <- list.files(path = path_to_files,
                                         pattern = pattern_to_grab)

  # Create output DT to fill with aggregated data
  aggregate_dt <- data.table::data.table()
  for(i in 1:length(input_files_to_aggregate)) {

    # Read in single file
    dt_to_add <- data.table::fread(input = paste0(path_to_files, input_files_to_aggregate[i]),
                                   sep = delim,
                                   header = has_header,
                                   stringsAsFactors = F,
                                   nThread = cpus)

    # Some file formats do not explicitly have a patient/sample column or any unique identifier
    # Let's add one derived from the input file name, if needed
    if(add_uniq_id) {
      uniq_id <- str_remove(string = input_files_to_aggregate[i], pattern = "\\..*$")
      dt_to_add$id <- uniq_id
    }

    # Add to aggregate DT
    aggregate_dt <- gUtils::rrbind(aggregate_dt, dt_to_add, as.data.table = T)
  }

  # TODO: The sort functionality is bugged, aggregated file has some sort of mix-and-match of columns
  # sort_output = TRUE,
  # #' @param sort_output indicate if the output data.table should be sorted by genomic coordinate, BEDPE not supported yet
  # Sort the output by genomic coordinate if desired
  #if(sort_output) {
  #
  #  # TODO: BEDPE files don't translate from DT to GR with standard header, likely need gGnome junctions
  #  # Convert to GR to run foolproof sorting
  #  aggregate_gr <- gr_refactor_seqs(input_gr = gUtils::dt2gr(aggregate_dt))
  #  aggregate_dt <- gUtils::gr2dt(x = aggregate_gr)
  #}
  return(aggregate_dt)
}




